{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "945f9adf-0027-4add-825a-21b520b80d35",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Tabular Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740a3ec7-2bb6-4df1-9b14-0a8fb818d77e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Tidy Data from Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb51395-1700-4967-ba54-a9235bbac053",
   "metadata": {},
   "source": [
    "An Excel spreadsheet with some brief information on awards given to movies is available at:\n",
    "\n",
    "> https://www.gnosis.cx/cleaning/Film_Awards.xlsx\n",
    "\n",
    "In a more fleshed out case, we might have data for many more years, more types of awards, more associations that grant awards, and so on.  While the organization of this spreadsheet is much like a great many you will encounter \"in the wild,\" it is very little like the tidy data we would rather work with.  In the simple example, only 63 data values occur, and you could probably enter them into the desired structure by hand as quickly as coding the transformations.  However, the point of this exercise is to write programming code that could generalize to larger data sets of similar structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4a7b14-1755-4996-815a-ccc52f5ca3fd",
   "metadata": {},
   "source": [
    "<img src=\"img/Film_Awards.png\" alt=\"Film Awards\"/>\n",
    "\n",
    "__Image: Film Awards Spreadsheet__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0a9a8a-37a6-40c8-a448-c61d6eb5bc5a",
   "metadata": {},
   "source": [
    "Your task in this exercise is to read this data into a single well-normalized data frame, using whichever language and library you are most comfortable with.  Along the way, you will need to remediate whatever data integrity problems you detect.  As examples of issues to look out for:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21690088-d166-44cf-b635-b7874a48f1b3",
   "metadata": {},
   "source": [
    "* The film _1917_ was stored as a number not a string when naïvely entered into a cell.\n",
    "* The spelling of some values is inconsistent.  Olivia Colman's name is incorrectly transcribed as 'Coleman' in one occurrence.  There is a spacing issue in one value you will need to identify.\n",
    "* Structurally, an apparent parallel is not really so.  Person names are sometimes listed under the name of the association, but elsewhere under another column.  Film names are sometimes listed under association, other times elsewhere.\n",
    "* Some column names occur multiple times in the same tabular area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a6bcf7-a605-45f7-9c24-d85f6a84c593",
   "metadata": {},
   "source": [
    "In thinking about a good data frame organization, think of what the independent and dependent variables are.  In each year, each association awards for each category. These are independent dimensions.  A person name and a film name are slightly tricky since they are not exactly independent, but at the same time some awards are to a film and others to a person.  Moreover, one actor might appear in multiple films in a year (not in this sample data; but do not rule it out).  Likewise, at times multiple films have used the same name at times in film history. Some persons are both director and actor (in either the same or different films)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e28898-2820-4688-b565-ceec459672e0",
   "metadata": {},
   "source": [
    "Once you have a useful data frame, use it to answer these questions in summary reports:\n",
    "\n",
    "* For each film involved in multiple awards, list the award and year it is associated with.\n",
    "* For each actor/actress winning multiple awards, list the film and award they are associated with.\n",
    "* While not occurring in this small data set, sometimes actors/actresses win awards for multiple films (usually in different years).  Make sure your code will handle that situation.\n",
    "* It is manual work, but you may want to research and add awards given in other years; in particular, adding some data will show actors with awards for multiple films.  Do your other reports correctly summarize the larger data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3360c680-2a0f-42b9-a873-7b9ec7156648",
   "metadata": {},
   "source": [
    "### Tidy Data from SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59db58cd-080f-4bee-949a-54f87484c2c7",
   "metadata": {},
   "source": [
    "An SQLite database with roughly the same brief information as in the prior spreadsheet is available at:\n",
    "\n",
    "> https://www.gnosis.cx/cleaning/Film_Awards.sqlite\n",
    "\n",
    "However, the information in the database version is relatively well normalized and typed.  Also, additional information has been included on a variety of entities included in the spreadsheet.  Only slightly more information is included in this schema than in the spreadsheet, but it should be able to accommodate a large amount of data on films, actors, directors, and awards, and the relationships among those data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868d014f-0a24-4914-8e5d-5e30c5c20e41",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> .tables\n",
    "actor     award     director  org_name\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c497f33-235f-46dc-b217-66d4a1082aa8",
   "metadata": {},
   "source": [
    "As was mentioned in the prior exercise, the same name for a film can be used more than once, even by the same director.  For example  Abel Gance, used the title _J'accuse!_ for both his 1919 and 1938 films with connected subject matter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36568c3-f289-42e0-aa12-96b81f8fa4b9",
   "metadata": {},
   "source": [
    "```\n",
    "sqlite> SELECT * FROM director WHERE year < 1950;\n",
    "Abel Gance|J'accuse!|1919\n",
    "Abel Gance|J'accuse!|1938\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84835ef-3cfe-48a0-9231-42c4df80db8e",
   "metadata": {},
   "source": [
    "Let us look at a selection from the `actor` table, for example.  In this table we have a column `gender` to differentiate beyond name. As of this writing, no transgender actor has been nominated for a major award both before and after a change in gender identity, but this schema allows for that possibility.  In any case, we can use this field to differentiate the \"actor\" versus \"actress\" awards that many organizations grant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c699497c-20a4-4534-9f8d-4cc8b95c5e63",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> .schema actor\n",
    "CREATE TABLE actor (name TEXT, film TEXT, year INTEGER, gender CHAR(1));\n",
    "\n",
    "sqlite> SELECT * FROM actor WHERE name=\"Joaquin Phoenix\";\n",
    "Joaquin Phoenix|Joker|2019|M\n",
    "Joaquin Phoenix|Walk the Line|2006|M\n",
    "Joaquin Phoenix|Hotel Rwanda|2004|M\n",
    "Joaquin Phoenix|Her|2013|M\n",
    "Joaquin Phoenix|The Master|2013|M\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eb4d9c-ffd5-480b-938f-f3def00d15b8",
   "metadata": {},
   "source": [
    "The goal in this exercise is to create the same tidy data frame that you created in the prior exercise, and answer the same questions that were asked there.  If some questions can be answered directly with SQL, feel free to take that approach instead.  For this exercise, only consider awards for the years 2017, 2018, and 2019.  Some others are included in an incomplete way, but your reports are for those years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7040ef9-b557-457c-8a79-46f1bf8519a7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "```sql\n",
    "sqlite> SELECT * FROM award WHERE winner=\"Frances McDormand\";\n",
    "Oscar|Best Actress|2017|Frances McDormand\n",
    "GG|Actress/Drama|2017|Frances McDormand\n",
    "Oscar|Best Actress|1997|Frances McDormand\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35975e99-d14a-4004-af9d-2cba2ab25d27",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Anomoly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d251fb4-28e9-4edd-85ea-7724d3bac2ce",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The two exercises in this chapter ask you to look for anomalies first in quantitative data, then in categorical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767a3177-b4d0-4c44-9c47-57c123715c0b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### A Famous Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1224668b-806e-4dbe-b3a9-905428ffbe4a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The Michelson–Morley experiment was an attempt in the late 19th century to detect the existence of the *luminiferous aether*, a widely assumed medium that would carry light waves.  This was the most famous \"failed experiment\" in the history of physics in that it did not detect what it was looking for—something we now know not to exist at all.  The general idea was to measure the speed of light under different orientations of the equipment relative to the direction of movement of the earth, since relative movement of the ether medium would add or subtract from the speed of the wave.  Yes, it does not work that way under the theory of relativity, but it was a reasonable guess 150 years ago."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555009ac-07f1-477e-b8f3-e1ec8cd0dc7f",
   "metadata": {},
   "source": [
    "Apart from the physics questions, the data set derived by the Michelson-Morley experiment is widely available, including as a sample built into R.  The same data is available at:\n",
    "\n",
    "> https://www.gnosis.cx/cleaning/morley.dat\n",
    "\n",
    "Figuring out the format, which is not complex, is a good first step of this exercise (and typical of real data science work)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4985dd5-c897-4b4f-8909-4047dbc5bb1b",
   "metadata": {},
   "source": [
    "The specific numbers in this data are measurements of the speed of light in km/s with a zero point of 299,000.  So, for example, the mean measurement in experiment 1 was 299,909 km/s.  Let us look at the data in the R bundle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aab0005b-c665-4a88-8721-eefafb2d1116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`summarise()` ungrouping output (override with `.groups` argument)\n",
      "\u001b[90m# A tibble: 5 x 3\u001b[39m\n",
      "   Expt  Mean Count\n",
      "  \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m     1  909     20\n",
      "\u001b[90m2\u001b[39m     2  856     20\n",
      "\u001b[90m3\u001b[39m     3  845     20\n",
      "\u001b[90m4\u001b[39m     4  820.    20\n",
      "\u001b[90m5\u001b[39m     5  832.    20\n"
     ]
    }
   ],
   "source": [
    "%%R -o morley\n",
    "data(morley)\n",
    "morley %>%\n",
    "    group_by(`Expt`) %>%\n",
    "    summarize(Mean = mean(Speed), Count = max(Run))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a2f9b0-6b0d-41e8-b835-14b35efa5f5e",
   "metadata": {},
   "source": [
    "In the summary, we just look at the number of runs of each experimental setup, and the mean across that setup.  The raw data has 20 measurements within each setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6c4744-9fa3-49c5-8c35-187c769160e5",
   "metadata": {},
   "source": [
    "Using whatever programming language and tools you prefer, identify the outliers first within each setup (defined by an `Expt` number) and then within the data collection as a whole.  The hope in the original experiment was that each setup would show a significant difference in central tendency, and indeed their means are somewhat different.  This book and chapter does not explore confidence levels and null hypotheses in any detail, but create a visualization that aids you in gaining visual insight into how much apparent difference exists between the several setups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff91b0e-304b-4b6e-bf50-3c8168bf1fa2",
   "metadata": {},
   "source": [
    "If you discard the outliers within each setup, are the differences between setups increased or decreased? Answer with either a visualization or by looking at statistics on the reduced groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdf372e-b596-4dd6-a66a-91b3307cd7a3",
   "metadata": {},
   "source": [
    "### Misspelled Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead31e27-9448-4214-a3b1-e39068b1d546",
   "metadata": {},
   "source": [
    "For this exercise we return to the 25,000 human measurements we have used to illustrate a number of concepts.  However, in this variation of the data set, each row has a person's first name (pulled from the US Social Security Agency list of common first names over the last century; apologies that the names lean Anglocentric because of the past history of US population and immigration trends)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e669d7d-5206-4efa-8de8-29ed754cdc2a",
   "metadata": {},
   "source": [
    "The data set for this exercise can be found at:\n",
    "\n",
    "> https://www.gnosis.cx/cleaning/humans-names.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7810e827-22d0-47c5-b9b9-86ca5b262a4b",
   "metadata": {},
   "source": [
    "Unfortunately, our hypothetical data collectors for this data set are simply terrible typists, and they make typos when entering names with alarming frequency.  There are some number of intended names in this data set, but quite a few simple miscodings of those names as well.  The problem is: how do we tell a real name from a typo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da4a531-2987-43d5-ae77-207559256800",
   "metadata": {},
   "source": [
    "There are a number of ways to measure the similarity of strings, and that provide a clue as to likely typos.  One general class of approach is in terms of *edit distance* between strings. The R package **stringdist**, for example provides Damerau-Levenshtein, Hamming, Levenshtein, and optimal sting alignment, as measures of edit distance.  Less edit-specific fuzzy matching techniques utilize a \"bag of n-grams\" approach, and include q-gram, cosine distance, and Jaccard distance. Some heuristic metrics like Jaro and Jaro-Winkler are also included in `stringdist` along with the other measures mentioned.  Soundex, soundex variants, and metaphone look for similarity of the sounds of words as pronounced, but are therefore specific to language and even regional dialect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782bd7de-fd36-49ac-8a0f-caa90a1932e2",
   "metadata": {},
   "source": [
    "In a reversal of the more common pattern of Python versus R libraries, Python is the one that scatters string similarity measures over numerous libraries, each including just a few measures.  However, **python-Levenshtein** is a very nice package including most of these measures.  If you want cosine similarity, you may have to use `sklearn.metrics.pairwise` or another module.  For phonetic comparisons, **fonetika** and **soundex** both support multiple languages (but different languages for each; English is in common for almost all packages)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563b19c7-9d6c-448c-a318-f61bf9a058ae",
   "metadata": {},
   "source": [
    "On my personal system, I have a command-line utility called `similarity` that I use to measure how close strings are to each other.  This particular few line script measures Levenshtein distance, but also normalizes it to the length of the longer string.  A short name will have a small numeric measure of distance, even betweeen dissimilar strings, while long strings that are close overall can have a larger measure before normalization (depending on what measure is chosen, but for most of them).  A few examples show this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d919f49a-4c9b-4c7b-a4fa-56b025d1a07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein distance: 1\n",
      "Similarity ratio: 0.8\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "similarity David Davin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c547558-8d01-4aaf-b5a9-291444f5e140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein distance: 3\n",
      "Similarity ratio: 0.4\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "similarity David Maven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4eb71bc6-d887-44eb-9e03-f0a6525e97fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein distance: 5\n",
      "Similarity ratio: 0.814814814815\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "similarity \"the quick brown fox jumped\" \\\n",
    "           \"thee quikc brown fax jumbed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b405d0-8106-44bd-93d5-9bcea99fc242",
   "metadata": {},
   "source": [
    "For this exercise, your goal is to identify every *genuine* name, and correct all the misspelled ones to the correct canonical spelling.  Keep in mind that sometimes multiple legitimate names are actually close to each other in terms of similarity measures.  However, it is probably reasonable to assume that *rare* spellings are typos, at least if they are also relatively similar to common spellings.  You may use whatever programming language, library, and metric you feel is the most useful for the task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cb7f74-41c7-4a30-881e-5786de22cbc3",
   "metadata": {},
   "source": [
    "Reading in the data, we see it is similar to the human measures we have seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02e08706-afc8-4765-bbde-a0efd9c72390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James</td>\n",
       "      <td>167.089607</td>\n",
       "      <td>64.806216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>David</td>\n",
       "      <td>181.648633</td>\n",
       "      <td>78.281527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barbara</td>\n",
       "      <td>176.272800</td>\n",
       "      <td>87.767722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John</td>\n",
       "      <td>173.270164</td>\n",
       "      <td>81.635672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michael</td>\n",
       "      <td>172.181037</td>\n",
       "      <td>82.760794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name      Height     Weight\n",
       "0    James  167.089607  64.806216\n",
       "1    David  181.648633  78.281527\n",
       "2  Barbara  176.272800  87.767722\n",
       "3     John  173.270164  81.635672\n",
       "4  Michael  172.181037  82.760794"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = pd.read_csv('data/humans-names.csv')\n",
    "names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb87eb2-dea6-433b-8b20-e5ce5bdbd410",
   "metadata": {},
   "source": [
    "It is easy to see that some \"names\" occur very frequently and others only rarely.  Look at the middling values as well in working on this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "25363352-8691-4991-b73e-3a6ec9cdec13",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elizabeth    1581\n",
       "Barbara      1568\n",
       "Jessica      1547\n",
       "Jennifer     1534\n",
       "             ... \n",
       "Josep           1\n",
       "iWlliam         1\n",
       "Joseeph         1\n",
       "eJennifer       1\n",
       "Name: Name, Length: 249, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.Name.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
