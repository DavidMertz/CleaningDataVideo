{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion – Tabular Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tidy datasets are all alike, but every messy dataset is messy in its own way.<br/>\n",
    "–Hadley Wickham (cf. Leo Tolstoy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A great deal of data both does and should live in tabular formats; to put it flatly, this means formats that have rows and columns.  In a theoretical sense, it is possible to represent *every* collection of *structured data* in terms of multiple \"flat\" or \"tabular\" collections if we also have a concept of *relations*.  Relational database management systems (RDBMS) have had a great deal of success since 1970, and a very large part of all the world's data lives in RDBMS's.  Another large share lives in formats that are not relational as such, but that are nonetheless tabular, wherein relationships may be *imputed* in an ad hoc, but uncumbersome, way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Preface mentioned, the data ingestion chapters will concern themselves chiefly with structural or mechanical problems that make data dirty.  Later in the book we will focus more on content or numerical issues in data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter discusses tabular formats including CSV, spreadsheets, SQL databases, and scientific array storage formats.  The last sections look at some general concepts around data frames, which will typically be how data scientists manipulate tabular data. Much of this chapter is concerned with the actual mechanics of ingesting and working with a variety of data formats, using several different tools and programming languages. The Preface discusses why I wish to remain language agnostic—or multilingual—in my choices.  Where each format is prone to particular kinds of data integrity problems, special attention is drawn to that.  Actually *remediating* those characteristic problems is largely left until later chapters; detecting them is the focus of our attention here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As _The Hitchhiker's Guide to the Galaxy_ is humorously inscribed: \"Don't Panic!\" We will explain in much more detail the concepts mentioned here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We run the setup code that will be standard throughout this book.  As the Preface mentions, each chapter can be run in full, assuming available configuration files have been utilized.  The prompts you see throughout this book, such as `In [1]:` and `Out[4]` are those used by Jupyter notebooks.  Although it is not usually best practice in Python to use `import *`, we do so here to bring in many names without a long block of imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.setup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in library(tidyverse) : there is no package called ‘tidyverse’\n"
     ]
    },
    {
     "ename": "RInterpreterError",
     "evalue": "Failed to parse and evaluate line 'library(tidyverse)\\n'.\nR error message: 'Error in library(tidyverse) : there is no package called ‘tidyverse’'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:385\u001b[0m, in \u001b[0;36mRMagics.eval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# Need the newline in case the last line in code is a comment.\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     value, visible \u001b[38;5;241m=\u001b[39m \u001b[43mro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwithVisible(\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m})\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ri\u001b[38;5;241m.\u001b[39membedded\u001b[38;5;241m.\u001b[39mRRuntimeError, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m# Otherwise next return seems to have copy of error.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/robjects/__init__.py:459\u001b[0m, in \u001b[0;36mR.__call__\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    458\u001b[0m p \u001b[38;5;241m=\u001b[39m rinterface\u001b[38;5;241m.\u001b[39mparse(string)\n\u001b[0;32m--> 459\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mget_conversion()\u001b[38;5;241m.\u001b[39mrpy2py(res)\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/robjects/functions.py:208\u001b[0m, in \u001b[0;36mSignatureTranslatedFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         kwargs[r_k] \u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSignatureTranslatedFunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/robjects/functions.py:131\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         new_kwargs[k] \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mpy2rpy(v)\n\u001b[0;32m--> 131\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m res \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mrpy2py(res)\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/rinterface_lib/conversion.py:45\u001b[0m, in \u001b[0;36m_cdata_res_to_rinterface.<locals>._\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 45\u001b[0m     cdata \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# TODO: test cdata is of the expected CType\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/rinterface.py:817\u001b[0m, in \u001b[0;36mSexpClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error_occured[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 817\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m embedded\u001b[38;5;241m.\u001b[39mRRuntimeError(_rinterface\u001b[38;5;241m.\u001b[39m_geterrmessage())\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[0;31mRRuntimeError\u001b[0m: Error in library(tidyverse) : there is no package called ‘tidyverse’\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRInterpreterError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlibrary(tidyverse)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:943\u001b[0m, in \u001b[0;36mRMagics.R\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m e\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mendswith(e\u001b[38;5;241m.\u001b[39merr):\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;28mprint\u001b[39m(e\u001b[38;5;241m.\u001b[39merr)\n\u001b[0;32m--> 943\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01min\u001b[39;00m DEVICES_STATIC:\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:923\u001b[0m, in \u001b[0;36mRMagics.R\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    921\u001b[0m         return_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 923\u001b[0m     text_result, result, visible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    924\u001b[0m     text_output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m text_result\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m visible:\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:389\u001b[0m, in \u001b[0;36mRMagics.eval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ri\u001b[38;5;241m.\u001b[39membedded\u001b[38;5;241m.\u001b[39mRRuntimeError, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m# Otherwise next return seems to have copy of error.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     warning_or_other_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RInterpreterError(code, \u001b[38;5;28mstr\u001b[39m(exception),\n\u001b[1;32m    390\u001b[0m                             warning_or_other_msg)\n\u001b[1;32m    391\u001b[0m text_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text_output, value, visible[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mRInterpreterError\u001b[0m: Failed to parse and evaluate line 'library(tidyverse)\\n'.\nR error message: 'Error in library(tidyverse) : there is no package called ‘tidyverse’'"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout err\n",
    "%%R\n",
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our various Python and R libraries now available, let us utilize them to start cleaning data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidying Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> After every war someone has to tidy up.<br/>–Maria Wisława Anna Szymborska"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concepts**: \n",
    "\n",
    "* Tidyness and database normalization\n",
    "* Rows versus columns\n",
    "* Labels versus values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hadley Wickham and Garrett Grolemund, in their excellent and freely available book, <u>[R for Data Science](https://r4ds.had.co.nz/)</u>, promote the concept of \"tidy data.\" The Tidyverse collection of R packages attempt to realize this concept in concrete libraries.  Wickham and Grolemund's idea of tidy data has a very close intellectual forebearer in the concept of database normalization, which is a large topic addressed in depth neither by them nor in this current book.  The canonical reference on database normalization is C. J. Date's <u>An Introduction to Database Systems</u> (Addison Wesley; 1975 and numerous subsequent editions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In brief, tidy data carefully separates variables (the columns of a table; also called features or fields) from observations (the rows of a table; also called samples).  At the intersection of these two, we find values, one data item (datum) in each cell.  Unfortunately, the data we encounter is often not arranged in this useful way, and it requires *normalization*.  In particular, what are really values are often represented either as columns or as rows instead. To demonstrate what this means, let us consider an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returning to the small elementary school class we presented in the Preface, we might encounter data looking like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Last Name</th>\n",
       "      <th>First Name</th>\n",
       "      <th>4th Grade</th>\n",
       "      <th>5th Grade</th>\n",
       "      <th>6th Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Johnson</td>\n",
       "      <td>Mia</td>\n",
       "      <td>A</td>\n",
       "      <td>B+</td>\n",
       "      <td>A-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lopez</td>\n",
       "      <td>Liam</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lee</td>\n",
       "      <td>Isabella</td>\n",
       "      <td>C</td>\n",
       "      <td>C-</td>\n",
       "      <td>B-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fisher</td>\n",
       "      <td>Mason</td>\n",
       "      <td>B</td>\n",
       "      <td>B-</td>\n",
       "      <td>C+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gupta</td>\n",
       "      <td>Olivia</td>\n",
       "      <td>B</td>\n",
       "      <td>A+</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Robinson</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>A+</td>\n",
       "      <td>B-</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Last Name First Name 4th Grade 5th Grade 6th Grade\n",
       "0   Johnson        Mia         A        B+        A-\n",
       "1     Lopez       Liam         B         B        A+\n",
       "2       Lee   Isabella         C        C-        B-\n",
       "3    Fisher      Mason         B        B-        C+\n",
       "4     Gupta     Olivia         B        A+         A\n",
       "5  Robinson     Sophia        A+        B-         A"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students = pd.read_csv('data/students-scores.csv')\n",
    "students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This view of the data is easy for humans to read.  We can see trends in the scores each student received over several years of education.  Moreover, this format might lend itself to useful visualizations fairly easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic conversion of letter grades to numbers\n",
    "def num_score(x):\n",
    "    to_num = {'A+': 4.3, 'A': 4, 'A-': 3.7,\n",
    "              'B+': 3.3, 'B': 3, 'B-': 2.7,\n",
    "              'C+': 2.3, 'C': 2, 'C-': 1.7}\n",
    "    return x.map(lambda x: to_num.get(x, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell uses a \"fluent\" programming style that may look unfamiliar to some Python programmers.  I discuss this style in the section below on data frames.  The fluent style is used in many data science tools and languages. For example, this is typical Pandas code that plots the students' scores by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApsAAAGzCAYAAABghdyiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC1l0lEQVR4nOzdd1iT5/c/8Hcg7L2XgKiIWxAXoHXvrThwT2i1aqu1/ahttdqqtbbV1mrB1r1Fxb1nBQXcijgYyt6bQEKS+/cHP56vMaAyk8B5XVcu5eHOkxMCeU7udXiMMQZCCCGEEEJqgZqiAyCEEEIIIfUXJZuEEEIIIaTWULJJCCGEEEJqDSWbhBBCCCGk1lCySQghhBBCag0lm4QQQgghpNZQskkIIYQQQmoNJZuEEEIIIaTWULJJCCGEEEJqDSWbhCg5Ho+HlStXKjqMeonH4+Hzzz9XdBiEEFKvUbJJyHs8efIE3t7ecHR0hLa2Nuzs7NCvXz/8+eefMu3WrFmDoKAgxQRZA/bv34+NGzcqOgxCCCH1ECWbhFQgJCQEHTt2xKNHjzBnzhxs3rwZs2fPhpqaGjZt2iTTlpJNQgghpHx8RQdAiLL66aefYGRkhPDwcBgbG8t8Ly0tTTFBEQCAVCqFSCSCtra2okNRKWKxGFKpFJqamooOhRDSgFDPJiEViI6ORuvWreUSTQCwtLTk/s/j8VBYWIhdu3aBx+OBx+Nh+vTpAIDp06ejcePGcvdfuXIleDyezDGhUIgvv/wSFhYWMDAwwPDhw5GQkFBubImJiZg5cyasrKygpaWF1q1bY/v27TJtrl+/Dh6Ph8OHD+Onn35Co0aNoK2tjT59+iAqKopr17NnT5w5cwZv3rzh4i8v5rddunQJ3bp1g7GxMfT19eHi4oJly5bJtCkuLsbKlSvRvHlzaGtrw8bGBqNHj0Z0dDTXprCwEIsXL4a9vT20tLTg4uKCDRs2gDEmc66yuZX79u1D69atoaWlhfPnz3/0z+JD9u3bBxcXF2hra8Pd3R03b97kvnft2jXweDwcP35c7n779+8Hj8fD7du3yz1vTEwMeDwefv/9d7nvhYSEgMfj4cCBA9yxj3kuIpEI33//Pdzd3WFkZAQ9PT10794d165dk2n3+vVr8Hg8bNiwARs3bkTTpk2hpaWFZ8+eVepnQwgh1UU9m4RUwNHREbdv38bTp0/Rpk2bCtvt2bMHs2fPRufOneHr6wsAaNq0aaUfb/bs2di7dy8mTpwIT09PXL16FUOGDJFrl5qaiq5du3IJmIWFBc6dO4dZs2YhLy8PX3zxhUz7devWQU1NDV999RVyc3Oxfv16TJo0CaGhoQCA5cuXIzc3FwkJCVxSpK+vX2GcERERGDp0KNq1a4dVq1ZBS0sLUVFRCA4O5tpIJBIMHToUV65cwYQJE7Bw4ULk5+fj0qVLePr0KZo2bQrGGIYPH45r165h1qxZcHV1xYULF7BkyRIkJibKJWhXr17F4cOH8fnnn8Pc3ByNGzeu9M+iPDdu3MChQ4ewYMECaGlpYcuWLRg4cCDCwsLQpk0b9OzZE/b29ti3bx9GjRolc999+/ahadOm8PDwKPfcTZo0gZeXF/bt24cvv/xS7r4GBgYYMWIEgI9/XfPy8vDPP//Ax8cHc+bMQX5+Pv79918MGDAAYWFhcHV1lXmcHTt2oLi4GL6+vtDS0oKpqekHfyaEEFKjGCGkXBcvXmTq6upMXV2deXh4sK+//ppduHCBiUQiubZ6enps2rRpcsenTZvGHB0d5Y6vWLGCvf3n9/DhQwaAzZ07V6bdxIkTGQC2YsUK7tisWbOYjY0Ny8jIkGk7YcIEZmRkxAQCAWOMsWvXrjEArGXLlkwoFHLtNm3axACwJ0+ecMeGDBlSbpzl+f333xkAlp6eXmGb7du3MwDst99+k/ueVCpljDEWFBTEALAff/xR5vve3t6Mx+OxqKgo7hgApqamxiIiImTafuzPoiIAGAB29+5d7tibN2+YtrY2GzVqFHds6dKlTEtLi+Xk5HDH0tLSGJ/Pl3ltyuPv788AsMjISO6YSCRi5ubmMr8zH/tcxGKxzOvJGGPZ2dnMysqKzZw5kzsWGxvLADBDQ0OWlpb23hgJIaQ20TA6IRXo168fbt++jeHDh+PRo0dYv349BgwYADs7O5w8ebJGH+vs2bMAgAULFsgcf7dnjjGGo0ePYtiwYWCMISMjg7sNGDAAubm5uH//vsx9ZsyYITNHr3v37gBKh3iromxawYkTJyCVSsttc/ToUZibm2P+/Ply3yubPnD27Fmoq6vLPefFixeDMYZz587JHO/RowdatWrFfV2Vn0V5PDw84O7uzn3t4OCAESNG4MKFC5BIJACAqVOnQigUIjAwkGt36NAhiMViTJ48+b3nHzduHLS1tbFv3z7u2IULF5CRkcHdtzLPRV1dnXs9pVIpsrKyIBaL0bFjx3Kf75gxY2BhYfHBnwMhhNQWSjYJeY9OnTrh2LFjyM7ORlhYGJYuXYr8/Hx4e3vX6Ny3N2/eQE1NTW743cXFRebr9PR05OTkICAgABYWFjK3GTNmAJBfvOTg4CDztYmJCQAgOzu7SrGOHz8eXl5emD17NqysrDBhwgQcPnxYJvGMjo6Gi4sL+PyKZ+q8efMGtra2MDAwkDnesmVL7vtvc3Jykvm6Kj+L8jg7O8sda968OQQCAdLT0wEALVq0QKdOnWQSxn379qFr165o1qzZe89vbGyMYcOGYf/+/TL3tbOzQ+/evav0XHbt2oV27dpBW1sbZmZmsLCwwJkzZ5Cbmyv3+O/+3AghpK7RnE1CPoKmpiY6deqETp06oXnz5pgxYwaOHDmCFStWvPd+7y4CKlPWY1ZZZQnd5MmTMW3atHLbtGvXTuZrdXX1ctuxdxbhfCwdHR3cvHkT165dw5kzZ3D+/HkcOnQIvXv3xsWLFyt8vOrS0dGR+boqP4vqmDp1KhYuXIiEhAQIhULcuXMHmzdv/uj7HjlyBCEhIWjbti1OnjyJuXPnQk2t9PN+ZZ7L3r17MX36dIwcORJLliyBpaUl1NXVsXbtWpnFV2Xe/bkRQkhdo2STkErq2LEjACA5OZk7VlFSaWJigpycHLnj7/baOTo6QiqVcj2CZV68eCHTrmylukQiQd++fav6FORUFH9F1NTU0KdPH/Tp0we//fYb1qxZg+XLl+PatWvo27cvmjZtitDQUJSUlEBDQ6Pcczg6OuLy5cvIz8+X6d18/vw59/33qamfxatXr+SOvXz5Erq6ujLDzxMmTMCiRYtw4MABFBUVQUNDA+PHj/+oxxg4cCAsLCywb98+dOnSBQKBAFOmTKnScwkMDESTJk1w7NgxmdftQx98CCFEUWgYnZAKXLt2rdzev7L5lW8nhXp6euUmlU2bNkVubi4eP37MHUtOTpbbRmfQoEEAgD/++EPm+Lsbraurq2PMmDE4evQonj59Kvd4ZcO+laWnp1fuEGx5srKy5I6VrYAWCoUASucJZmRklNvzV/YzHTx4MCQSiVyb33//HTwej/uZVKSmfha3b9+WmesYHx+PEydOoH///jK9tObm5hg0aBD27t2Lffv2YeDAgTA3N/+ox+Dz+fDx8cHhw4exc+dOtG3bVqbXtTLPpSymt383Q0NDK9x+iRBCFI16NgmpwPz58yEQCDBq1Ci0aNECIpEIISEhOHToEBo3bszNpQMAd3d3XL58Gb/99htsbW3h5OSELl26YMKECfjmm28watQoLFiwAAKBAFu3bkXz5s1lEhxXV1f4+Phgy5YtyM3NhaenJ65cuSKzH2aZdevW4dq1a+jSpQvmzJmDVq1aISsrC/fv38fly5fLTQY/xN3dHYcOHcKiRYvQqVMn6OvrY9iwYeW2XbVqFW7evIkhQ4bA0dERaWlp2LJlCxo1aoRu3boBKB023r17NxYtWoSwsDB0794dhYWFuHz5MubOnYsRI0Zg2LBh6NWrF5YvX47Xr1+jffv2uHjxIk6cOIEvvvjio7aPqomfRZs2bTBgwACZrY8A4IcffpBrO3XqVHh7ewMAVq9e/cFzv3vfP/74A9euXcPPP/9c5ecydOhQHDt2DKNGjcKQIUMQGxuLv//+G61atUJBQUGlYiKEkDqhoFXwhCi9c+fOsZkzZ7IWLVowfX19pqmpyZo1a8bmz5/PUlNTZdo+f/6cffLJJ0xHR4cBkNnS5uLFi6xNmzZMU1OTubi4sL1798ptfcQYY0VFRWzBggXMzMyM6enpsWHDhrH4+Hi5rY8YYyw1NZXNmzeP2dvbMw0NDWZtbc369OnDAgICuDZlWx8dOXJE5r5lW+Ls2LGDO1ZQUMAmTpzIjI2NGYD3boN05coVNmLECGZra8s0NTWZra0t8/HxYS9fvpRpJxAI2PLly5mTkxMXo7e3N4uOjuba5Ofnsy+//JLZ2toyDQ0N5uzszH755Rdue6QyANi8efPKjedjfhYVKTvv3r17mbOzM9PS0mJubm7s2rVr5bYXCoXMxMSEGRkZsaKiog+e/12tW7dmampqLCEhocrPRSqVsjVr1jBHR0cu3tOnT8tts1X2Ov/yyy+VjpMQQmoSj7EqrhIghJAGRiwWw9bWFsOGDcO///5b6fu7ubnB1NQUV65cqYXoCCFEOdGcTUII+UhBQUFIT0/H1KlTK33fu3fv4uHDh1W6LyGEqDLq2SSEkA8IDQ3F48ePsXr1apibm3/UZvFlnj59inv37uHXX39FRkYGYmJioK2tXYvREkKIcqGeTUII+YCtW7fis88+g6WlJXbv3l2p+wYGBmLGjBkoKSnBgQMHKNEkhDQ41LNJCCGEEEJqDfVsEkIIIYSQWkPJJiGEEEIIqTUqsam7VCpFUlISDAwMKl1WjxBCCCGKwRhDfn4+bG1toaZG/VsNlUokm0lJSbC3t1d0GIQQQgipgvj4eDRq1EjRYRAFUYlk08DAAEDpL6uhoaGCoyGEEELIx8jLy4O9vT13HScNk0okm2VD54aGhpRsEkIIISqGpsA1bDSBghBCCCGE1BpKNgkhhBBCSK2hZJMQQgghhNQaSjYJIYQQQkitoWSTEEIIIYTUGko2CSGEEEJIraFkkxBCCCGE1BpKNgkhhBBCSK2hZJMQQgghhNQaSjYJIYQQQkitoWSTEEIIIYTUGko2CSGEEEJIrWnwyaZAIIBUKlV0GIQ0aJGRkYiNjYVIJFJ0KIQQQmpYg042i4qKsGvXLhw5cgRisVjR4RDSYJ09exa7d+9GWloadywuLg737t1DfHw8hEKhAqMjpH6iD3ekrvAVHYAipaSkIDMzEwKBAIWFhTAyMlJ0SITUe1KpFOHh4XB3dwefz4dEIoGdnR3S0tJgYWHBtXv69CnCw8O5r42MjGBpaQkLCwtYWlpy/+fzG/TbGCFVcvfuXUyYMAGbN2/GwIEDFR0Oqed4jDGm6CA+JC8vD0ZGRsjNzYWhoWGNnjs2Nha6urqwsrKq0fMSQuTl5eXh6NGjiIuLQ6dOnTB48OAK2969exfPnz9HWloa8vPzy23D4/FgamrKJZ+Ojo5wcnKqrfAJqTcWLFiAP//8E506dUJoaCh4PF6tPE5tXr+J6mjwXQLvXpiSk5Oho6MDY2NjxQRESD316tUrHD9+HEVFRdDU1ISDg8N723fs2BEdO3YEUDrlJT09HWlpaTK3oqIiZGZmIjMzE5GRkXBzc+P+psViMU6ePAkLCwt4enpCXV291p8jIapi/fr10NHRwdKlS2st0SSkTINPNt+WmZmJvXv3Qk1NDdOmTYO5ubmiQyJE5UkkEly9ehUhISEAABsbG3h7e8PU1PSjz6GjowMHBweZBJUxhsLCQpnks0mTJtz3MzMz8eTJE2hra6Nbt27c8cuXL6OwsJDrDbWysoKenh5dcEm9dufOHWzZsgU7duyAuro6tLW18fPPPys6LNJAULL5Fk1NTejr60NdXR0GBgaKDocQlZebm4vAwEAkJCQAADp37ox+/frVyDxLHo8HfX196OvryySZZXR0dNC7d29IJBKZRDIyMhJZWVlybcuSz7fng+ro6FQ7TkIUSSqV4tdff8WyZcsgFovh6uqKRYsWKTos0sA0+Dmb7yoqKoJUKoWenl6tPg4h9d2LFy8QFBSE4uJiaGlpYcSIEWjZsqWiw8KzZ8+QmprKDctnZWWhordBAwMDWFpaomvXrmjWrFkdR0pI9WRkZGD69Ok4c+YMAGDcuHHYtm1bnc6dpDmbBKCeTTnv9mRERERALBajffv2CoqIENUikUhw6dIlhIaGAgBsbW3h7e0NExMTBUdWqlWrVmjVqhX3dUlJCTIyMrih+LIkNDc3F/n5+cjPz0eHDh249lFRUTh79iyaN28us4pXKpVCTa1B7yZHlMitW7cwYcIEJCYmQktLC5s2bYKvry9NFyEKQcnme6SmpuLYsWOQSqUwMDAod6iOEPJ/srOzERgYiKSkJABA165d0bdvX6VenKOhoQEbGxvY2NjIHC8uLuYST3t7e+54amoqsrOzUVhYyB1jjGH9+vUwNDSUG443NjamJJTUGalUip9//hnfffcdJBIJmjdvjsOHD1OHCVEoSjbfw9LSEp07d0ZeXh4aN26s6HAIUXonTpxAUlIStLW1MXLkSLi4uCg6pCrT1taGvb29TKIJAB06dICtrS00NTW5Y9nZ2RAKhUhPT0d6ejoiIiK47/H5fJm9QctuBgYG1MtEalRaWhqmTJmCixcvAgAmTZqErVu30hoEonA0Z/MDGGNgjHE9E+9+TQj5P5mZmTh37hyGDh3aoLYPY4whLy9Pbmum9PR0SCSScu+jpaWFmTNnwtLSEgBQUFAANTU16Orq1mXopJ64fv06Jk6cyG3ft3nzZsyYMUPhH2hoziYBqGfzg3g8nswf640bN5CWlobRo0dT5RLS4GVlZeH169fcnEYzMzNMnjxZwVHVPR6PByMjIxgZGcHZ2Zk7LpVKkZ2dLZeEZmZmQigUylQt+++//xAWFoZPPvkEvXr1AlBaTrCsspKWlladPy+i/CQSCX766Sf88MMPkEqlaNmyJQ4fPow2bdooOjRCOJQtVUJ2djZu3boFiUSCV69eKcXKWkIUJTc3F/7+/igpKYGpqSlNNSmHmpoazMzMYGZmJvN+IRaLkZWVJZNACgQCAJBZSJWcnIydO3cCAIyNjeXKdZqbm9OH3gZOIBBg9+7dkEqlmD59OjZv3ky7qRClQ8PolRQbG4vExESZTaIJaahOnDiBrKwsjBkzRuF/m/WBSCQCAG4+6IsXL3D69GkUFBSU257H48HMzEwuCTUzM1P48CmpO/fu3UNERASmTp2q6FDkKNP1mygOJZvVJBaLIRAIlC4uQmpDRkYGdHR0uJ4TsVgMNTU1msNcywQCQbnlOouLi+Xaamlp4ZtvvuGSzcjISKirq8Pe3p42qa8HxGIxVq1aBWtra8ydO1fR4XyQMl+/Sd2h8ZdqkEqlOH78OOLj4zF58mRuoj8h9dHjx49x+vRpODo6YuLEieDxeDSEW0d0dXXh6OgIR0dH7hhjDAUFBXIJqLa2tkyv5uXLl5GVlYUpU6Zw27clJCQgISGB6wnV19ev8+dEqiYwMBCrV6+GpqYmhg4dKlPClRBlRVeKaiguLkZGRgYEAgEKCgoo2ST1UklJCc6ePYuHDx8CKO1ZEQqF0NbWVmxgDRyPx4OBgQEMDAzQtGnTctswxmBnZwc+ny/z/vT8+XMEBwdzX+vq6soNxVtaWtJrrITGjx+Ps2fPYtCgQZRoEpVBw+jVVFRUhKSkpArf7AlRZenp6Thy5AjS09MBAD169MAnn3xCw+Yq7smTJ3j27BlXrrMiZZvUW1hYwNHRUaX3TVVVJSUl+O233zB37lyV3C9Tma/fpO5Qz2Y16ejoyCSahYWFiIuLo5XqRKUxxvDw4UOcPXsWYrEY+vr6GD16NJycnBQdGqkBbdu2Rdu2bQHIl+ssu+Xl5XG3qKgo5OXlcckmYwxHjx6FqakpunXrJrPBPak5cXFx8PHxQUhICB49eoT9+/crOiRCqoSSzRokEomwb98+JCcnY/jw4XBzc1N0SIRUmkgkwpkzZ/D48WMAQJMmTTBq1Cia11dPva9c59vJp52dHfe9nJwcREREQF1dHT179uSOX716FdnZ2XLlOmllfOWdOnUK06dPR1ZWFgwNDTF69GhFh0RIlVGyWYM0NDRgb2+P3NxcmktDVFJqaiqOHDmCzMxM8Hg89OrVC926daNkoQHS1taGg4NDue9lWlpaGDBgAIqLi2WmVLx69QopKSkybTU0NMot16mvr0+/V+UQiURYunQpfvvtNwBAx44dcejQIW5xFyGqiOZs1rCyFaKqOLeGNFyMMdy/fx/nz5+HWCyGgYEBxowZI7P6mZAPiY6ORkpKykeV69TW1oalpSW6dOmCVq1aASj9PWzICWhsbCwmTJiAsLAwAMDChQvx888/q3T1KFW6fpPaQz2bNaxshWiZ1NRU3LlzB0OGDKFtYojSCg0NxYULFwAAzZo1w6hRo6hGN6m0pk2bysxhl0qlyMrKkkk+y8p1FhcXIy4uDq6urlz7uLg4BAYGomnTphg5ciR3XCwW1/v3z+PHj2PGjBnIzc2FsbExduzYIfMzIESV1e+/XgWTSCQ4ePAgcnJyoKOjg/79+ys6JELK1b59e4SFhcHd3R2enp4NuneJ1Bw1NTWYm5vD3Nyc670ESpPHskVJbw/Tp6WloaCggCvdWWbjxo3Q0NCQG4o3MzNT+SRUKBRiyZIl+PPPPwEAXbp0waFDh2hUgdQrNIxey2JiYnD9+nX4+PhQ9Q6iNBhjiImJQZMmTbjEsiH0HhHlJhKJkJaWBh6Pxy1IKiwsxIYNG8pt/3a5zrdvJiYmKrE9V3R0NMaPH4979+4BAL766iusWbMGGhoaCo6s5qjy9ZvUHEo268C785Dook4UiTGGY8eO4enTpxg2bBg6dOig6JAIeS+BQCCzMj49PR2pqakQCoXltufz+Zg6dSrs7e0BAPn5+ZBKpTA0NFSqXvthw4bh9OnTMDU1xe7duzFkyBBFh1TjVP36TWoGZTx14O03txcvXuDcuXOYOHEiVRwiCsHj8WBlZYVnz55BLBYrOhxCPkhXVxeNGzdG48aNuWOMMeTn58sloOnp6RCLxTA2NubahoWF4datW+jUqRMGDx4MoPRDf3x8PCwtLaGnp1fHz6jU33//jXnz5uHPP//kEmNC6iNKNusQYww3b95Ebm4u7t27h0GDBik6JNJAMMZQVFTELfrx8vKCi4sLLCwsFBwZIVXD4/FgaGgIQ0NDNGvWjDsulUqRk5Mjsy+sUCiEmpoazMzMuGPp6enYvXs3AEBPT6/ccp01vQr85cuXOHPmDL788ksAgJ2dHYKCgmr0MQhRRjSMXseKiooQEhKCXr16qcScIqL6ioqKcOLECWRlZWHOnDn1aj4YIR9LIpFAKpVyv/+xsbE4ffr0e8t1GhkZySWhVlZWVXrvTk1NhbOzM/Lz8xEUFIQRI0ZU+bmokvp0/SZVR8mmgjHGkJKSIle9g5CakJCQgMDAQOTm5kJdXR0TJ06kzaEJeUtJSQm3JdPbt/z8fLm2ampqWLZsGdTV1QEAkZGRkEqlcHR0/KgKW0uWLMHdu3exb98+2Nra1vhzUUb1+fpNPh4NoytYcHAwrly5goEDB6JLly6KDofUE4wxhISE4OrVq5BKpTAxMcHYsWPpQw0h79DQ0ICtra1c8ldUVCSXhALgEk0A+O+//5CcnIxx48ahZcuWAICkpCRER0fD0tISeXl5sLCw4OaarlmzBmpqajLnIKQhoGRTgcomuAOosMoGIZUlEAgQFBSEV69eAQBat26NYcOGqXQVEkLqmo6OToXlOss0atQIampqsLKy4o5FR0fj6tWr3NdisRgODg5UrpM0aJRsKhCPx8PAgQPh4uJCQ5ukRrx58wZHjx5Ffn4+1NXVMWjQIHTo0IEuaoTUgrKV7W8zMDBAfn4+CgsLYW5uDj6fj6SkJCQlJcm009HR4eaD2tvbo127dnUVNiF1jpJNBePxeDKJpkQiwZ07d9ClSxfai5N8NMYYbt26hWvXroExBjMzM4wdO1amx4UQUruePHkCHx8fPH/+HGpqavjhhx8wZ84crlpS2bB8VlYWioqK8ObNG7x58wY5OTkyyWZgYCAMDAzQvXt3KhtL6gXKZpTM6dOn8fDhQ8THx2PChAmKDoeogMLCQhw/fhzR0dEAgHbt2mHIkCHQ1NRUcGSENAyMMfz777+YP38+iouLYWtriwMHDuCTTz4BAFhZWaF169Zc+7fLdaalpclsyVRYWIiIiAgAQK9evbjjN27cQHJyMiwsLGBlZcWV66T5n0QVVCvZXLduHZYuXYqFCxdi48aNFbY7cuQIvvvuO7x+/RrOzs74+eefyx1+IEDbtm3x/PlzuLu7KzoUogIyMjKwa9cuFBQUgM/nY/DgwXB1daVhc0LqSH5+Pj799FPs378fADBw4EDs3r37vXvY8vl8WFtbw9raWu576urqGDp0KPLz82U+MMbGxuLNmzd48eIFd6xs79B354MaGxvT1npEqVQ52QwPD4e/v/8H55mEhITAx8cHa9euxdChQ7F//36MHDkS9+/fR5s2bar68PVWkyZNsHDhQmhrays6FKICTExMYGRkBB0dHXh7e1NVKkLq0MOHDzFu3Di8evUK6urq+Omnn7BkyZJqJXra2trldjb07t0bycnJMsPxQqEQ6enpSE9P53pDgdJk1sLCAp06dYKbmxuA0t5XAPRBlChElfbZLCgoQIcOHbBlyxb8+OOPcHV1rbBnc/z48SgsLMTp06e5Y127doWrqyv+/vvvj3q82tqnq6SkROk3uBYIBDh27BgGDBhA1V4IgNK/Px0dHW74LD8/H1paWjRsTkgdYYzh77//xpdffgmhUAh7e3scPHgQnp6edRpDXl6eTLnOsn/LytC+vaVeSkoKdu7cCUdHR/j4+HDnEYlEtfreQftsEqCKPZvz5s3DkCFD0LdvX/z444/vbXv79m0sWrRI5tiAAQPeW6JLKBRCKBRyX+fl5VUlzA8aP3488vLy4Ovri5EjRyrlxfrixYuIjo7G0aNH4efnR59KG7iYmBgcO3YMrq6u6Nu3L4DS1a+EkLrj7++PuXPnAgCGDRuGHTt2yMy7rAs8Hg9GRkYwMjKCs7Mzd1wqlSI7OxtpaWkyw/RlPaFvX1sBYOvWrSgqKoKfnx9MTEzqLH7SsFQ62Tx48CDu37+P8PDwj2qfkpIityLWysoKKSkpFd5n7dq1+OGHHyobWqVkZ2fjzJkzEIlEuHLlCiwtLTFjxgzMmTMHTZs2rdXHroz+/ftDIBCgX79+lGgSFBcXo7CwEFFRUejZsyftWECIAkyZMgV///03pk6dii+//FKp3pvL5nG+m/y2atUKVlZWMns6i0Qi5OTkAACysrIo2SS1plITS+Lj47Fw4ULs27evVucULl26FLm5udwtPj6+xh/DxMQEL1++xLfffgsbGxukpaXh559/RrNmzdCvXz8EBgaipKSkxh+3snR1dTFx4kSZIfTi4mIFRkTq2tszXVq1aoUxY8Zg1qxZlGgSUkcYYzh+/DikUikAQE9PD+Hh4Vi0aJFSJZrvw+fzYWVlJVMpSVNTE8OHD4eenp5SjuyR+qNSyea9e/eQlpaGDh06gM/ng8/n48aNG/jjjz/A5/PLrYJjbW2N1NRUmWOpqanlrsIro6WlBUNDQ5lbbXB0dMTq1asRFxeH48ePY+DAgeDxeLh8+TLGjh0Le3t7LFu2DDExMbXy+FWRnp6OP//8E6GhoYoOhdSBV69eYcuWLTJ1mtu0aaP0c40JqU8mT56M0aNHY8OGDdwxVf0bLC4uRnZ2Nve1m5sbFixYAHt7ewVGReq7SiWbffr0wZMnT/Dw4UPu1rFjR0yaNAkPHz4sd78vDw8PXLlyRebYpUuX4OHhUb3IaxCfz8fIkSNx7tw5xMTEYPny5VySvHbtWjRt2hQDBgzAsWPHFN7bGRERAYFAgCdPnlCJy3pMIpHg0qVL2L9/PzIyMnDz5k1Fh0RIg9WzZ09oampCX19f0aFUS1paGgICAnDw4EGZaxn1apLaVqXV6G/r2bOnzGr0qVOnws7ODmvXrgVQuvVRjx49sG7dOgwZMgQHDx7EmjVrKrX1kSJWs5WUlODUqVMICAjAxYsXuaFMa2trzJw5E3PmzEHjxo3rJJa3McYQHh6ONm3aUGWJeio3NxeBgYFISEgAAHTq1An9+/enYXNC6ohUKkVycjLs7OwAlL7vxsTEKNV8/qooKCjA33//DT6fjylTptTJoiZajU6AWkg2e/bsicaNG2Pnzp1cmyNHjuDbb7/lNnVfv359pTZ1V/Qva2xsLLZt24bt27dzUwJ4PB4GDBgAX19fDB06VKFDKm/evIGdnR0lI/XAixcvEBQUhOLiYmhpaWH48OFo1aqVosMipMHIzMzEtGnT8PTpUzx48EDlF81IpVKZfT+TkpJgYmICHR2dOnl8RV+/iXKodrJZF5Tll7WkpAQnT56Ev78/Ll26xB23sbHBrFmzMHv2bDg6OtZpTFFRUThw4AAaN26MCRMmqOw8ooZOIpHg8uXLuHPnDgDA1tYW3t7eKn+hI0SVBAcHY8KECUhISICWlhaCgoIwcOBARYdVZQkJCTh+/DhGjhypsDmZynL9JopF9awqQUNDA2PGjMHFixcRFRWF//3vf7C0tERycjJ+/PFHODk5YfDgwThx4gS3qW5tU1NTg7q6OnR1dalnU0VlZ2djx44dXKLZpUsXzJw5kxJNQuqIVCrFunXr0KNHDyQkJKB58+YIDQ1V6UQTKK30l5WVhatXryo6FNLAUc9mNYlEIpw4cQL+/v4yC6FsbW253k4HB4dajSEtLQ1mZmblLtAiyi0yMhInTpyAUCiEtrY2Ro4cCRcXF0WHRUiDkZaWhqlTp+LChQsAgEmTJmHr1q31oliCUCjE9evX0aNHD4WVQFbm6zepO5Rs1qCoqChs27YNO3bsQHp6OoDSnsdBgwbBz88PgwYNqpPex5CQEDg7O1N5SyUmlUpx4cIFhIWFAQAaNWqEMWPGwNjYWLGBEdKA3LhxAz4+PkhOToaOjg7+/PNPzJw5U2X2znxXXFwc3rx5g+7duys6FI6qXL9J7aJh9BrUrFkz/Pzzz4iPj8fBgwfRu3dvSKVSnDlzBsOHD4eTkxNWrlxZK5vUl3nw4AEuXbqEHTt2QCAQ1NrjkOrh8XgoLCwEAHh6emL69OmUaBJSRyQSCVatWoXevXsjOTkZLVu2RFhYGGbNmqWyiWZ2djZ27dqFq1ev4tWrV4oOhxAZ1LNZy16+fIlt27Zh586dyMjIAFDa2zl48GCut7Mmh78FAgH2798PFxcXpfp0S0q9vTJUKBQiISFB5bdTIUSVpKSkYPLkydy0p+nTp2Pz5s3Q09NTcGTVd+HCBRQWFmLIkCHQ0tJSdDgAVPv6TWoOJZt1RCgU4vjx4/D398f169e54/b29pg9ezZmzpyJRo0a1chjicViqKurc5/QGWMq+2m9vigpKcGFCxcgEAgwduxYej0IUYCYmBh4enoiNTUVurq62Lp1K6ZOnarosKosLi4OVlZWXGIplUrB4/GU6v2lPly/SfXRMHod0dLSwoQJE3Dt2jU8f/4cixcvhpmZGeLj47FixQo4OjpixIgROHv2bLUrA/H5fO7NRiqV4siRIwgPD6+Jp0GqKDMzEw8ePEBkZCQSExMVHQ4hDVLjxo3Rrl07tGnTBnfv3lXpRDM8PBw7d+7E6dOnuaIjampqSpVoElKGkk0FcHFxwYYNG5CQkIB9+/ahR48ekEqlOHnyJIYMGYImTZpg9erVSEpKqvZjRUREIDIyEhcuXEBOTk71gydVYm1tjSFDhmDy5Mk11oNNCPmwpKQkbv66mpoaDhw4gNDQULRs2VLBkVWPtbU1gNLOBalUquBoCHk/GkZXEs+fP0dAQAB27dqFrKwsAIC6ujqGDRsGX19f9O/fv0pzOxljuHnzJqysrNCiRYuaDptUoGzY3N3dHTY2NooOh5AG6fLly/Dx8cHIkSOxbds2RYdTbUKhUGYuZnp6utLvOtIQrt/kw6hnU0m0aNECv/32GxITE7F37150794dEokEQUFBGDx4MJo2bYqffvoJycnJlTovj8dDjx49ZBJNgUBQ7aF6UrH09HRs27YN9+7dw9GjR6nXgRAFUVNTQ2ZmJu7evYuCggJFh1NlUqkU165dw+bNm5Gfn88dV/ZEk5AylGwqGW1tbUyaNAk3b95EREQEFi5cCBMTE7x58wbffvst7O3tMXr0aFy4cKFKSUxxcTF2796N/fv3QyQS1cIzaNgePnyIgIAApKenQ19fH0OGDJGpS0wIqV0lJSXc/3v37o1Tp07h9u3b0NfXV2BU1SORSPD8+XMUFBQgIiJC0eEQUmk0jK4CioqKEBgYCH9/fwQHB3PHGzdujDlz5mDmzJnc/J0PiY+Px549e6CpqYlZs2ZRScQaIhKJcPbsWTx69AgA0KRJE4waNUqlL3CEqJrTp09j/vz5uHTpEpo1a6bocGpURkYGkpOT0bZtW0WHUikN/fpNSlGyqWIiIiIQEBCA3bt3cwt++Hw+RowYAV9fX/Tt2/eDPWkJCQng8/kfnaCS90tNTUVgYCAyMjLA4/HQs2dPdO/enVaFElJHRCIRli5dit9++w0AMGPGDGzfvl3BUVVd2bC5hYUF2rVrp+hwqoWu3wSgZFNlCQQCHDlyBAEBAQgJCeGON2nSBHPmzMGMGTNgZWX1UedKSUmBuro6zf+pJMYY7t+/j/Pnz0MsFsPAwABjxoyBo6OjokMjpMF4/fo1JkyYgNDQUADAwoUL8fPPPyvNpuZVce/ePZw+fRqamppYsGCBSm84T9dvAlCyWS88efIEAQEB2LNnD3JzcwGU9naOHDkSfn5+6N27d4W9nVlZWdi+fTukUimmTZv20QlqQycUCnH69Gk8ffoUQGmp0pEjR6r0RYEQVRMUFIQZM2YgJycHxsbG2LFjB0aOHKnosKpNKpXi8OHDaNu2LVq3bq3ocKqFrt8EoGSzXhEIBDh8+DD8/f1x584d7njTpk253k5LS0u5++zbt49LNrW1tes6bJWTnJyMwMBAZGVlgcfjoU+fPvD09KRhc0LqiFAoxNdff40//vgDANClSxccPHgQjRs3VmxgVSSRSPDo0SO4ubnVu/cRun4TgJLNeuvx48dcb2deXh4AQENDA6NGjYKvry969erF9XaKRCKUlJRQr9xHun79Om7cuAFDQ0N4e3vD3t5e0SER0mBER0dj/PjxuHfvHgDgq6++wpo1a6ChoaHgyKqGMYbdu3fj9evX6NevHzw9PRUdUo2i6zcBKNms9woLC3Ho0CEEBARwc5qA0mFfX19fTJ8+XW6uZmRkJAoKCtCpU6e6DlclSKVSXL9+HR4eHtDR0VF0OIQ0GEeOHMHs2bORl5cHU1NT7N69G0OGDFF0WNV29+5dXLlyBSNGjKh3xTfo+k0ASjYblLI9IPfu3cttDKyhoYHRo0fDz88PPXv2RGZmJv7++29IJBL4+PigefPmCo5a8RITExEcHIzRo0eDz+crOhxCGhypVIrPP/8cW7duBQB4eXnhwIEDKjuqIBaLUVxczG2NxhhDYWFhvdwqja7fBKBN3RsUV1dXbNmyBUlJSfjnn3/QqVMnlJSU4NChQ+jduzdcXFywY8cOdOjQAS1btqx3+9RVhVgsxqFDhxAZGYn//vtP0eEQ0iCpqalxcxmXLl2K69evq2yimZ2dje3bt+PgwYNcJTcej1cvE01CylDPZgP34MED+Pv7Y9++fVw5N01NTYwZMwZ+fn745JNPAJR+8m6olXBevXqFBw8eYPjw4bSAipA6VFxczP3NFRcXIzQ0FD169FBwVNWTk5MDf39/8Hg8TJ8+XW7RZn1D128CULJJ/r+CggIcOHAA/v7+3MR7AHBxceG2RJo8eTI0NTUVGGXdSEhIQHFxMfXsEqIgAoEACxcuRHR0NC5dugR1dXVFh1QtjDGZVeaxsbEwNTWFkZGRAqOqG3T9JgANo5P/T19fH3PmzMHdu3dx9+5d+Pr6Ql9fH8nJySgoKEB8fDwWLFiAmzdvQgU+n1QJYwzBwcHYsWMHjh49ylVoIoTUrcTERBw4cADXr1/HzZs3FR1OtWRmZmL79u1ISUnhjjk5OTWIRJOQMtSzSSqUn5+P/fv34/DhwxAKhVxd9pYtW8LX1xdTp06FqampgqOsGQKBAEFBQXj16hUAoHXr1hg2bJhKVyEhRJUFBgbCxMQEffr0UXQo1RIYGIiIiAjY29tjxowZ9W4fzQ+h6zcBKNkkH+nu3bvw9/fHgQMHUFxcDENDQwgEAowdOxZ+fn7w8vJS2TfRuLg4BAYGIj8/H+rq6hg4cCDc3d1V9vkQomoKCwsxf/58TJ06FT179lR0ODVKIBDg3Llz6NevX4O8ftH1mwCUbJJKysnJwd9//428vDzs2rULSUlJAIBWrVpxvZ0mJiYKjvLjMMZw69YtXLt2DYwxmJmZwdvbG9bW1ooOjZAG4+nTpxg7diyeP38Oe3t7vHr1SqVHFNLT0xEXFwd3d3dFh6IU6PpNAJqzSSpJW1sbZmZm0NHRQUBAAGbNmgVdXV08e/YMX3zxBWxtbTFt2jQEBwcr9dzOwsJC7Nu3D1evXgVjDO3atYOvry8lmoTUEcYYtwXb8+fPYWtriz179qh0opmTk4Nt27bh9OnTiI2NVXQ4hCgN6tkklSYUCpGYmIgmTZoAAHJzc7Fv3z74+/vj8ePHXLs2bdrA19cXU6ZMgbGxsYKilff69WscPXoUBQUF4PP5GDx4MFxdXWnYnJA6kp+fj08//RT79+8HAAwYMAB79uyRq2amik6ePImcnByMHj2a9s4EXb9JKUo2SbUVFhYiOjoabdu2RVhYGPz9/XHw4EEUFRUBAHR0dDBu3Dj4+fmha9euCkvqpFIp/vvvP9y4cQOMMZibm2Ps2LH1fp87QpTJw4cPMX78eLx8+RLq6ur48ccf8fXXX6vsPr7p6ekwNjbmarOLxWKoqamp7POpaXT9JgAlm6SaSkpKsGPHDiQnJ2PgwIHo0qULgNLhpLLezidPnnDt27ZtC19fX0yePLnOeztfvXrF9aS4urpi0KBBDWLfUEKUAWMMf//9N7788ksIhUI0atQIBw8ehJeXl6JDq7InT57g5MmTaN++PYYOHarocJQSXb8JQHM2STXx+Xw4OztDV1cXTZs25Y4bGxtj3rx5ePToEUJCQjBt2jRoa2vjyZMnmD9/PmxtbTFz5kyEhobW2dxOZ2dndOrUCSNHjsSIESMo0SSkjuTm5mLChAmYO3cuhEIhhg4diocPH6p0ogkAurq6EIvFyMnJ4UpPqiLGGN68eaPoMEg9Rj2bpEYUFhZCT0/vvW2ys7Oxd+9e+Pv7IyIigjverl07+Pn5YdKkSTW60bFUKkVISAjc3Nw+GBshpHbcu3cP48aNQ0xMDPh8Pn7++Wd8+eWXKjtHWiKRyFQ0evPmDRwcHFTq+RQVFeHu3bsIDg5GcHAwQkJCUFBQgNzc3BovyUvXbwJQsklqQVpaGv777z8MGzas3N5Dxhhu374Nf39/HD58GMXFxQBKewkmTJgAPz8/dOrUqdpv3idPnsSDBw/QrFkzTJw4UaUuBoTUF5s2bcIXX3wBR0dHHDp0iJtqo2oYY7h37x7u3LmDWbNmQUdHR9EhfbSUlBQuqQwODsb9+/dRUlIi00ZHRwd37txBu3btavSx6fpNAEo2SQ2TSqX466+/kJWVhU6dOmHw4MHvbZ+VlYU9e/bA398fkZGR3HFXV1f4+flh4sSJVX7NU1NTsWfPHgwcOBBt2rSp0jkIIdXDGMOGDRswe/ZsldmDtzwlJSX4+++/kZWVhd69e6N79+6KDqlcUqkUERERMr2WMTExcu1sbGzg5eXF3VxdXblFTjWJrt8EoGST1IL4+HhcuXIF48eP/+hP/2V1yf39/XHkyBEIhUIAgJ6eHnx8fODn54eOHTu+9xwSiQQJCQlwdHTkjpWUlNTKGyghpHyhoaH4/vvvERgYCAMDA0WHU6OSk5MRGxsLDw8PpRkpKSgoQFhYGJdc3rlzB7m5uTJteDwe2rVrB09PTy65dHR0rJPnQNdvAlCySWoJY0zmjawySV9WVhZ2794Nf39/PH/+nDveoUMH+Pr6YuLEiXIXsdzcXBw9ehSJiYmYMWMGGjVqVDNPhBDy0cRiMVxcXBATE4Mvv/wSv/32m6JDqjLGGMLCwmBsbAwXFxdFh8OJj4+XGRJ/9OiR3OIkfX19dO3aFV5eXvD09ETXrl0Vdu2k6zcBKNkkdeDFixc4ffo0fHx8YGtr+9H3Y4zhv//+Q0BAAAIDA7neTn19fUycOBG+vr5wd3fHixcvcOLECRQVFUFLSwujR49G8+bNa+vpEELeIyQkBJs3b8bWrVtrdMFfXXvw4AFOnjwJbW1tzJs3TyEbtIvFYjx+/FhmSDw+Pl6unYODg8yQeJs2bcDn8+s83vJ8zPVbKpVCJBLVcWSkujQ0NGQWy70PJZukVjHGsHPnTsTFxaFjx44YMmRIlc6TmZmJXbt2ISAgAC9evAAAqKurY+LEidyWS7a2tvD29lbpeWGEqJrg4GAkJCRg/Pjxig6lRkkkEuzatQutW7dG586d62TIOTc3F3fu3OGSy9DQUBQWFsq0UVdXh5ubGzck7unpqdQjOR+6fotEIsTGxkIqlSogOlJdxsbGsLa2/uDfByWbpNYJhULcvn0b3bt3/+hPQRVhjOHmzZvYvn07tLS0YGdnBwC4e/cu7Ozs4OfnBzc3t5oImxDyHlKpFOvXr8e3334LTU1N3L17F61atVJ0WFXGGMOrV6/g7OzMXTjfnQ5U048XGxsrMyT+9OlTuX2HjY2N4eHhwSWWnTt3Vqmt3N53/WaMIS4uDiUlJbC1taWqSyqEMQaBQIC0tDQYGxvDxsbmve2Vo5+d1GtaWlro2bOnzLGEhIQqfRrn8XiwtLREy5YtuWH1Gzdu4Nq1awAAf39/dOrUCb6+vpgwYQLVJiakFqSnp2Pq1Kk4f/48AGDUqFGwt7dXcFRVxxjDkSNHEBkZiWHDhqFDhw4AUKOJpkgkwoMHD2SSy5SUFLl2TZs2lRkSb9myZb1NwsRiMQQCAWxtbaGrq6vocEgllS0ATktLg6Wl5Xs7kyjZJHUuODgYly9fRq9evfDJJ5989P3EYjEuXbqEsLAwAECjRo0wZswYfP/997h+/Tr8/f1x7NgxhIeHIzw8HIsWLcLkyZPh5+eH9u3b19bTIaRBuXnzJnx8fJCUlARtbW38+eefmDVrltKszq4KHo8HOzs7vHz5ssYqmmVmZuL27dvckHh4eDi3p3AZDQ0NdOzYUWZI3MrKqkYeXxWULWyiam6qq+xDQklJCSWbRLmUTQSvzAT2rKwsBAYGIjk5GQDg6emJ3r17c7/cvXr1Qq9evZCeno6dO3ciICAAUVFR2Lp1K7Zu3YrOnTvDz88P48ePV6khKEKUhUQiwdq1a7FixQpIpVK0aNEChw8fRtu2bRUdWpUwxiASiaClpQWg9D2lRYsWMDMzq9K5Xr58KdNr+fZOGmXMzMy4HktPT0907Nixxiv2qCJV/qDS0H3sa0dzNolCxMXFwcHB4aPaFhcX448//kBRURF0dHQwcuTID642l0qlXG/n8ePHuWoZhoaGXG9nTVfKIKS+Sk1NxaRJk3DlyhUAwLRp0/DXX3+p7Ae3wsJCBAUFQSKRYPLkyZUepi4uLubKPYaEhCAkJAQZGRly7Vq0aCGTXDZv3rzBJVbvu34XFxcjNjYWTk5OlHSrqI99DalnkyjE24mmRCJBcHAwunbtWu5wira2Njw9PfHq1SuMGTPmoz5wqKmpoXfv3ujduzfS0tKwY8cOBAQEICYmBlu2bMGWLVvQtWtX+Pn5Ydy4cTRfiJAKXLlyBZMmTUJqaip0dXWxZcsWTJs2TdFhVUtRURHevHkDxhhSU1M/uLghNTWV67EMDg7GvXv35Mo9amtro3PnztyQuIeHR5V6SUn9cv36dfTq1QvZ2dkwNjZWdDgKQz2bROFOnTqF+/fvw8nJCVOmTAGPx0NmZiYYYzA3NwdQOkzFGKvWRHmpVIqrV6/C398fQUFBEIvFAAAjIyNMmTIFfn5+VNaSkP9PIpFg1apVWL16NRhjaNOmDQ4dOqTSK87f9vz5c5iYmMjNkZRKpXj27JnMkHh0dLTc/a2trbkeSy8vL7i5udHcw3LUx57N6dOnIycnB0FBQR9sW9+TTerZJCrD1dUVL168QNeuXcHj8RATE4ODBw/C2NgYc+bMgYaGBng8XrWHn9TU1NC3b1/07dsXKSkp3NzO2NhYbN68GZs3b4anpyd8fX0xbty4jy61SUh9dPv2baxatQoAMHv2bGzatEllRwAKCgpw5swZ9O3bl+ttbNGiBYDSIfW3yz3evn273HKPbdq0kRkSd3JyanBD4oRUVf3cT4GoFHt7eyxYsICbh2lpaQktLS3o6enVWlUJa2tr/O9//0NUVBQuXLiAMWPGgM/nIyQkBNOnT4etrS0WLlyIiIiIWnl8QpRdt27dsGLFCuzbtw/btm1T2UQTAM6dO4fnz5/jxIkTiI+Px+HDh7Fw4UJ07NgRRkZG6N27N7777jucP38eubm50NPTQ58+fbhj2dnZePz4MbZu3YrJkyejSZMmlGgSAKX7SC9YsACWlpbQ1tZGt27dEB4eLtfu3r176NixI3R1deHp6ckVJwGAlStXwtXVFXv27EHjxo1hZGSECRMmID8/n2sTGBiItm3bQkdHB2ZmZujbty+34b9UKsWqVavQqFEjaGlpwdXVlduWDABev34NHo+HY8eOoVevXtDV1UX79u1x+/btWvzJvIOpgNzcXAaA5ebmKjoUUkvy8vK4/wsEAvbPP/+whISEOo0hKSmJ/fTTT6xx48YMAHfz8vJiu3fvZgKBoE7jIaQulZSUsJUrV7LXr18rOpQaU1JSwu7fv882bdrElixZwtq1ayfzt112s7e3ZxMmTGB//PEHu3fvHispKVF06PXG+67fRUVF7NmzZ6yoqIgxxphUKmUFBQUKuUml0o9+TtOmTWMjRoxgjDG2YMECZmtry86ePcsiIiLYtGnTmImJCcvMzGSMMXbt2jUGgHXp0oVdv36dRUREsO7duzNPT0/ufCtWrGD6+vps9OjR7MmTJ+zmzZvM2tqaLVu2jDFWem3i8/nst99+Y7Gxsezx48fsr7/+Yvn5+Ywxxn777TdmaGjIDhw4wJ4/f86+/vprpqGhwV6+fMkYYyw2NpYBYC1atGCnT59mL168YN7e3szR0bHav+vvvoYVoWSTKNyDBw/YTz/9xB4/fswYY+zkyZNs5cqVbPPmzUwikdR5PBKJhJ0/f56NGjWKqaurcxckExMTtnDhQvbs2bM6j4mQ2jZv3jwGgHl4eCjk764m5ObmsgsXLrDvv/+ejR8/nunr68sllurq6qxDhw5s/vz57ODBgywuLk7RYddrlUk2CwoKyv0wUBe3goKCj35OZclmQUEB09DQYPv27eO+JxKJmK2tLVu/fj1j7P+SzcuXL3Ntzpw5wwBwz3vFihVMV1dXptNlyZIlrEuXLowxxu7du8cAVPhB0NbWlv30008yxzp16sTmzp3LGPu/ZPOff/7hvh8REcEAsMjIyI9+3uX52GSThtGJwohEIgQFBeHEiRMoKSnBs2fPAAD9+/dHy5YtMXbsWIVUzlBTU8OAAQNw7NgxxMXF4ccff4SjoyOys7OxadMmtGrVCp988gn27t0rt0kzIapq8eLFcHBwwJdffqkSFWvY/y/3uG/fPsydOxft27eHsbExxo4di6KiIjRv3hxGRkYwNDTEgAEDsGrVKly5cgU5OTm4d+8e/vjjD4wfP16lKx8RxYqOjkZJSQm8vLy4YxoaGujcuTMiIyNl2r691V7Z7gdpaWncscaNG8PAwECmTdn327dvjz59+qBt27YYO3Ystm3bhuzsbAClC7CSkpJkYgAALy+vSsdQm2iBEFGI1NRUBAYGIiMjAzweDz179kS3bt0AlJa3HDdunEx7gUCgkDljtra2WL58Of73v//h4sWL8Pf3x+nTp/Hff//hv//+w8KFCzFt2jT4+vpyCw4IUQUlJSW4fPkyBg0aBABwcnLCq1evlHZFdUlJCR48eCCzBVFZkYe3mZubgzEGLS0tHD58GF26dHlvZROiPHR1dVFQUKCwx65NGhoa3P/L5vtKpdJyv1/Wpuz76urquHTpEkJCQnDx4kX8+eefWL58OUJDQyu1vdaHYqhNlGySOsUYw4MHD3Du3DmIxWIYGBhg9OjRaNy4cYX3ycjIwI4dO9C1a1d069ZNIRPz1dXVMWjQIAwaNAiJiYnYvn07tm3bhvj4ePz+++/4/fff8cknn8DPzw9jxozhqpIQoozevHmD8ePHIzQ0FOfPn8eAAQMAKFfZwKysLK7cY0hICMLCwlBUVCTTRkNDAx06dEC3bt3g4eEBT09P2NjYQCgUQl1dvVJVyoji8Xg8lSoU0LRpU2hqaiI4OBiOjo4ASj8UhYeH44svvqjRx+LxeNxuCN9//z0cHR1x/PhxLFq0CLa2tggODkaPHj249sHBwejcuXONxlAd9JdI6oxQKMTp06fx9OlTAECzZs0wcuTID765vHz5EgKBAM+fP4eHh4fCLyB2dnb47rvvsGzZMly4cIHr7bx58yZu3ryJBQsWYPr06ZgzZw5cXFwUGish7woKCsKMGTOQk5MDY2Njuc3JFYExhlevXsn0Wr47BAgApqam3L6WXl5e6NixIxITE3Hs2DEYGhpyQ4P0YY/UBT09PXz22WdYsmQJTE1N4eDggPXr10MgEGDWrFk19jihoaG4cuUK+vfvD0tLS4SGhiI9PR0tW7YEACxZsgQrVqxA06ZN4erqih07duDhw4fYt29fjcVQXZRskjqRkpKCI0eOICsrCzweD71794aXl9dH9VJ6enpCR0cHzZs3V3ii+TZ1dXUMHjwYgwcPRkJCAv7991/8888/SEhIwK+//opff/0VPXv2hJ+fH0aNGkUXQKJQIpEIX3/9NTZt2gQA6Ny5Mw4dOvTeUYXaUlxcjHv37nHJZUhICNLT0+Xaubi4yGyc7uLiIveeUVJSgqKiIrx+/RpisVip3iNI/SSVSrnfs3Xr1kEqlWLKlCnIz89Hx44dceHCBZiYmNTY4xkaGuLmzZvYuHEj8vLy4OjoiF9//ZWbArNgwQLk5uZi8eLFSEtLQ6tWrXDy5Ek4OzvXWAzVVakKQlu3bsXWrVvx+vVrAEDr1q3x/fffc0/4XTt37sSMGTNkjmlpaVV6UQVVEFJdjDHcvXsXFy5cgEQigaGhIby9vas9KT82NhaNGjWSm+eiaBKJBOfOnYO/vz/Onj3LzYcxNzfH9OnT4evrq1RvAKRhiImJwfjx43H37l0ApYuB1qxZU2fD5mlpaTKJ5d27d+X20NXS0kKnTp24XksPDw+ugti7GGMySeezZ8+U7sMoKVUfKwgNHDgQzZo1w+bNmxUdisLVSgWhRo0aYd26dXB2dgZjDLt27cKIESPw4MEDtG7dutz7GBoaymxeShvhNiynTp3CgwcPAADNmzfHiBEjqj0ROzo6Gvv374ednR0mTZqkVD2G6urqGDp0KIYOHYr4+HiutzMxMREbNmzAhg0b0Lt3b/j6+mLUqFFKNUeO1E+BgYGYNWsW8vLyYGpqil27dmHo0KG19nhSqRSRkZEyQ+JRUVFy7SwtLbnEsqzc48f8LT9//hzBwcGYMmUK9/dTX0poEuWWnZ2N4OBgXL9+HZ9++qmiw1EplUo2hw0bJvP1Tz/9hK1bt+LOnTsVJps8Hg/W1tZVj5CotGbNmuHRo0fo27cvV46yujQ1NaGpqQkjIyOlTtbs7e2xcuVKfPvttzh79iwCAgJw9uxZXL16FVevXoWFhQVmzJiBOXPmoFmzZooOl9QzxcXFWLx4MbZs2QKgdCuUAwcO1PhWPwKBAGFhYVxyefv2bW5bljI8Hg+tW7eWGRKvShWekpISnDt3Dnl5eQgJCUHPnj1r8JkQ8n4zZ85EeHg4Fi9ejBEjRig6HJVSqWH0t0kkEhw5cgTTpk3DgwcPyv1kuXPnTsyePRt2dnaQSqXo0KED1qxZU2FiWkYoFEIoFHJf5+Xlwd7enobRVQBjDLm5uTA2NuaOlS1EqEmZmZkwNjZWuS1N4uLi8M8//+Dff/9FUlISd7xPnz7w8/PDiBEjlDqBJqrh1atXGD9+PDeqsHTpUvzwww81Mu0kKSmJ67EMCQnBgwcPIBaLZdro6uqiS5cuXK9l165da+w9IC4uDs+fP0efPn1U7u+/IaqPw+jk/3zsa1jpZPPJkyfw8PBAcXEx9PX1sX//fgwePLjctrdv38arV6/Qrl075ObmYsOGDbh58yYiIiLQqFGjCh9j5cqV+OGHH+SOU7Kp3IqLi3HixAnExcXh008/ldmgtrYFBwejSZMm3GpUZScWi3HmzBn4+/vj/PnzKPsztLS05Ho7mzZtquAoiSoSCARwcnJCWloazM3NsXfvXm5ro8qSSCR4+vQpl1wGBwfjzZs3cu3s7OxkhsTbtWtXY/Opnz17Bl1dXYUsZCLVR8lm/VZryaZIJEJcXBxyc3MRGBiIf/75Bzdu3PioOTMlJSVo2bIlfHx8sHr16grbUc+mahKLxfjnn3+QkZEBb2/vOtvk/PHjxzh+/Dg0NTXx+eef12mSWxNev36Nf//9F//++6/MJtX9+vWDr68vRowYoXQLoYhyCwgIwP79+7F//37Y2tp+9P3y8/Nx584dbkj8zp07yM/Pl2mjpqaG9u3bywyJOzg41PRTAFDauXHs2DHo6+vj008/Vak9GEkpSjbrt1pLNt/Vt29fNG3aFP7+/h/VfuzYseDz+Thw4MBHPwatRldejDEwxrjydpmZmRAKhZW6wFWXUCjEwYMH4eTkhE8++aTOHremlZSU4PTp0/D398fFixe53k4rKyvMnDkTc+bMgZOTk4KjJMro+fPnKCwshLu7O4DSv0upVPreYWbGGOLi4mSGxB8/fixXUcTAwAAeHh5cctmlS5c6+0AnEonw77//wtnZGb169aJhcxVEyWb9VmfJZu/eveHg4ICdO3d+sK1EIkHr1q0xePBg/Pbbbx/9GJRsKieBQICgoCDY2dnJVC5QBIlEAjU1NW7Bwbtbo6ia2NhY/PPPP9i+fTtSUlIAlC6y6NevH/z8/DBs2DDq7SQAgBs3bmDw4MGwsLDAgwcPKtzfr6SkBI8ePZJJLhMTE+XaOTk5yWyc3rp16zpN8hITE2FnZycTN/2uqy5KNuu3Wtn6aOnSpRg0aBAcHByQn5+P/fv34/r167hw4QIAYOrUqbCzs8PatWsBAKtWrULXrl3RrFkz5OTk4JdffsGbN28we/bsajw1ogzi4uJw9OhR5OXl4fXr13B3d4e+vr7C4nn7YiiVShEYGAhbW9uP3jhe2Tg5OeGnn37CypUrcfLkSQQEBODixYvczdraGrNmzcLs2bNpLlsD5+bmBhsbGzg6OspUA8rOzsbt27e5IfGwsDAIBAKZ+/L5fHTo0IFLLj09Pet0VOJtjDGcOXMG9+7dg7e3N7eQlBJNQlRfpZLNtLQ0TJ06FcnJyTAyMkK7du1w4cIF9OvXD0BpAlI2nAqUvtnNmTMHKSkpMDExgbu7O0JCQmhPNBXGGENwcDCuXr0KxhhMTU0xduxYhSaa73r58iUiIyPx8uVLtGrVCqampooOqco0NDQwZswYjBkzBjExMdi2bRvX2/nTTz9hzZo1GDBgAPz8/DB06FDa1LqBeP36NRwdHcHj8WBoaIhr165BIBDg3LlzXK9lRESE3P1MTExkEstOnTpVe9/bmsLj8aCjowMAclsnEUJUW7WH0esCDaMrh8LCQhw/fhzR0dEAgLZt22LIkCFKtal6mdu3b8PY2JirHVufiEQinDx5Ev7+/rh8+TJ33MbGhuvtdHR0VGCEpLYwxrB9+3bMnz8fc+fOhbW1NZdcpqWlybV3dnaWWSXu4uIi0yGgDCQSCTcyIZVKkZSU9N7dSohqoWH0+q3O5mzWBUo2Fe/169c4evQoCgoKwOfzMWjQILi5uanMEHVhYSE0NTXr3ZBcVFQUN7ezrLY0j8fDoEGD4OvriyFDhlBvZz2Qnp6OK1euYPXq1Xj27Fm5bTQ1NdGpUyeZnksLC4s6jvTjiUQinDt3DsXFxRg3bpzKvJeQyqmPyeb06dORk5ODoKAgRYeicLUyZ5M0PFKpFP/99x9u3LgBxhjMzc0xduxYWFpaKjq0j1ZcXIw9e/ZAU1MTPj4+3FBdfdCsWTOsW7cOq1atQlBQEAICAnDlyhWcPXsWZ8+ehZ2dHWbNmoVZs2bV2vY0pGZJpVK8ePFCZiHPy5cv5dqZm5ujW7duXGLp7u6ulKMMFcnKysKTJ08glUqRmJhIvZmE1GPKNZ5ClEpBQQH27t2L69evgzEGV1dXzJkzR6USTaB0/ldubi6ysrJQVFSk6HBqhaamJsaNG4fLly/j5cuXWLJkCczNzZGYmIhVq1bByckJQ4cOxalTp+SqvRDFEggEuHnzJtauXYuhQ4fCwsICrVq1wpw5c7Bz506ZRFNPTw/Lli3Dq1evkJaWhuPHj+Orr76Cp6enSiWaAGBtbY2hQ4di6tSplGiSeuPGjRvo3LkztLS0YGNjg//9738y77k9e/bE559/js8//xxGRkYwNzfHd999h7cHmYVCIb766ivY2dlBT08PXbp0wfXr12XOwePx5G6vX7+uw2daOdSzScr15s0bHDlyBIWFhdDQ0MCQIUPQvn17RYdVJTY2Npg+fTqkUqlKLxb6WM7Ozli/fj1Wr16NoKAg+Pv749q1azhz5gzOnDmDRo0acXM76SJf95KTk7key+DgYNy/f1/uA4COjg7c3d2RmZmJyMhIAMCQIUOwa9cumJmZKSLsahOJRLh06RK6desGIyMjAICrq6tigyJKqbCwsNL30dLS4qYMicViCIVCqKmpyYxkVXTemioWkJiYiMGDB2P69OnYvXs3nj9/jjlz5kBbWxsrV67k2u3atQuzZs1CWFgY7t69C19fXzg4OGDOnDkAgM8//xzPnj3DwYMHYWtri+PHj2PgwIF48uQJnJ2dcezYMYhEIu588+bNQ0REBKysrGrkedQKpgJyc3MZAJabm6voUBqMxMREtmrVKrZlyxaWlpam6HBqXHJyMktKSlJ0GHXmxYsX7KuvvmJmZmYMAAPA1NTU2LBhw9jp06eZWCxWdIj1klgsZo8ePWJbtmxhkydPZk5OTtzP/+2bra0tGzt2LNu4cSMLCwtjoaGhrGnTpgwA4/P5bMOGDUwikSj66VRLYGAgW7lyJduxYweTSqWKDofUkfddv4uKitizZ89YUVGRzPHy/kY+dDt8+DB3/8OHDzMArEePHjLnNTc3L/e+lTVt2jQ2YsQIuePLli1jLi4uMr/ff/31F9PX1+f+fnv06MFatmwp0+abb75hLVu2ZIwx9ubNG6aurs4SExNlzt2nTx+2dOlSucf87bffmLGxMXvx4kWln0dNqOg1fBf1bBLO26tCbW1tMWnSJNjb29e7RTXZ2dnYu3cvSkpKuL1h67vmzZvjl19+wY8//ohjx47B398fN27cwKlTp3Dq1CnY29tj9uzZmDVrVoP4edSW/Px8hIWFcfMt79y5g7y8PJk2ampqaNeunczG6Q4ODuDxeGCM4a+//sLixYshEong6OiIgwcPomvXrgp6RjWnd+/eSE1NRe/evWkxEKmXIiMj4eHhIfP77eXlhYKCAiQkJHDz5rt27SrTxsPDA7/++iskEgmePHkCiUSC5s2by5xbKBTKjWqcO3cO//vf/3Dq1Cm59sqGkk0CoHRV86lTpzBhwgTY2NgAAJo0aaLgqGqHjo4OzM3NUVxcrLJDklWlpaUFHx8f+Pj44MWLFwgICMDOnTsRHx+PFStW4IcffsDQoUPh5+eHAQMGUHnAD4iLi+OGw4ODg/Ho0aNyyz127dqVSy67dOlS4a4a8+bNw9atWwEAI0eOxPbt2yusCKTshEIhkpKSuBKrJiYm+OyzzyjRJB9UUFBQ6fu8PWd51KhRKCgokNvmS5nnNJYpKCiAuro67t27J/f++/Z+1s+ePcOECROwbt069O/fv67DrDRKNgkA4N69e8jLy8OtW7cwduxYRYdTq7S1tTF58mQIhUKV2m6jprm4uODXX3/FTz/9hKNHjyIgIAA3b97EyZMncfLkSW4O0cyZMxVWVUaZiMVirtxjWYKZkJAg187R0ZHrsfT09ETbtm0/OmkfM2YMduzYgZ9//hnz589X2cQsPz8fO3bsQH5+vsyiQlV9PqRuVXcOJZ/PL3fLt5qam1mRli1b4ujRozLlkoODg2FgYCAzPz40NFTmfnfu3IGzszPU1dXh5uYGiUSCtLQ0dO/evdzHycjIwLBhwzBmzBh8+eWXtfeEahAlmwQAMHz4cJibmyu8xnldeffNKDIyEllZWfD09GxwF0RtbW1MmjQJkyZNQmRkJAICArBr1y7ExcXhu+++w8qVKzFs2DD4+fmhX79+Daa3MycnB3fu3OF6LUNDQ+XKPZZdHN5OLiszDYExhhcvXqBFixYAgD59+uD169fKPdH/I+jr68PMzAxSqZR2PyD1Um5uLh4+fChzzNfXFxs3bsT8+fPx+eef48WLF1ixYgUWLVok08saFxeHRYsWwc/PD/fv38eff/6JX3/9FUDplKdJkyZh6tSp+PXXX+Hm5sbts9uuXTsMGTIEY8aMga6uLlauXImUlBTuvBYWFsr7/lwXE0irixYI1bwXL16wM2fO0ER9xlhWVhZbvXo1W7lyJYuIiFB0OEqhqKiI7dmzh3Xr1k1mIr2joyP78ccf693iKqlUyqKiotiuXbuYn58fa9OmDePxeHILCYyNjdngwYPZjz/+yK5du8YKCgqq/Jh5eXls2LBhzMDAgL169aoGn41iFBUVybyfFBYWMoFAoMCIiDKoygIhZTdt2rRyFxrNmjWLXb9+nXXq1Ilpamoya2tr9s0337CSkhLuvj169GBz585ln376KTM0NGQmJiZs2bJlMn87IpGIff/996xx48ZMQ0OD2djYsFGjRrHHjx8zxipeQBUbG1vXP4qPfg2pglADI5FIcOXKFdy+fRsAMHbsWKpVj9LylvHx8fD29la6cn6KFhERgW3btmHXrl3IyckBUNozPHz4cPj6+qJfv34q9zMTiUS4f/++zJB4amqqXLtmzZrJ9Fq2bNmyxp6rWCxG7969ERYWhr1798Lb27tGzqsIiYmJCAwMhJubGz755BNFh0OUSH2sIFQdPXv2hKurKzZu3KjoUGoEVRAicnJychAYGIjExEQAQJcuXZR+BVtd8fDwkFkhyBiDVCpV3iGJOtS6dWts3LgRa9euxZEjRxAQEIDg4GAcO3YMx44dg5OTE+bMmYMZM2bA2tpa0eGWKyMjA7dv3+aGxMPDwyEUCmXaaGpqwt3dnUsuPTw8anw4WyqVQiKRQENDA3w+H/v370d6ejrc3Nxq9HHqWnp6OnJycvDo0SN4enpSiVRCiAzq2Wwgnj9/jhMnTqC4uBja2toYMWIEN0+MyLt58yaio6Ph4+PTYD5xV8bTp08REBCA3bt3Izc3F0Bpb+eIESPg5+eHPn36KKy3k/3/eZBvrxJ/8eKFXDtzc3Oux9LLywvu7u61+lqnp6dj2rRpcHZ2xqZNm2rtcRQlPDwcbdu2pb8XIoN6NmU11J5NSjbrObFYjEuXLiEsLAwAYGdnB29vbxgbGys2MCVWUFCAzZs3QygUYuTIkSpbOakuCAQCHDlyBP7+/tzUDKB026yy3s7aXuxSVFSEu3fvckPiISEhyMzMlGvXsmVLmeTS2dm5zhaD3bx5Ez4+PkhKSoKOjg5evHgBe3v7Onns2hAfH4/g4GB4e3tTLyZ5L0o26zdKNgmys7Nx5MgRJCcnAygdKu7Tpw8NDX+ElJQUREdHw8vLS9GhqIwnT57A398fe/bs4TYy19DQwMiRI+Hn54devXrVSG9nSkqKTK/l/fv3UVJSItNGW1sbnTt35obEu3btqpA9VSUSCdauXYsVK1ZAKpWiRYsWOHz4MNq2bVvnsdQUsViMTZs2oaCgAD169EDPnj0VHRJRYpRs1m+UbDZwz549w8mTJyEUCqGjo4ORI0fS/MxqkEgkyM7Ohrm5uaJDUXqFhYU4fPgw/P39ZfaTa9asGebMmYPp06dz+y5+iFQqRUREhExyGRMTI9fOxsZGptfS1dUVmpqaNfacqiI1NRWTJ0/G5cuXAQBTp07FX3/9JbMxs6qKiorC48ePMWTIEJnNtAl5FyWb9Rslmw2UWCzGhQsXcPfuXQCAvb09vL296edWDYwxHD16FFFRUZgwYQIaN26s6JBUxqNHjxAQEIC9e/fK9HaOGjWK6+18eyi7sLAQoaGh3JD47du3uTmhZXg8Htq2bSuTXDZu3Fip9ke9evUqJk2ahJSUFOjq6uKvv/7C9OnTFR1Wlb158wYaGhq0uT+pNEo26zdajd5ACQQCREREAAC6detWY0OXDVlJSQkKCgpQUlJCG1RXUvv27fHXX39h/fr1OHjwIAICAhAWFobDhw/j8OHDcHZ2xpQpU5Cens6Ve5RIJDLn0NPTQ9euXbkh8S5dusDIyEhBz+j9JBIJVq1ahdWrV4MxhtatW+Pw4cMqvb1YZGQkjhw5AiMjI/j5+VFSQAipNOrZrIeioqIAlA5bkpohFouRkJBAvZo14OHDh/D398e+ffuQn58v930HBweZXsu2bduqxCKUpKQkTJo0CdevXwcAzJo1C3/88Qd0dXUVG1g1FRcXw9/fHw4ODhgyZIjCpycQ1UI9m/UbDaM3ECUlJTh//jycnZ1pK6M6JBAIEBkZCXd3d0WHorIKCgpw8OBBnD59Go6Ojlxy+XYNYVXx33//YcyYMUhPT4eenh78/f0xadIkRYdVZdnZ2TAxMeG+FggEKp80E8WgZLN+o2H0BiIsLAz3799HZGQknJycaLJ+HRCLxdi3bx+SkpJQVFSEbt26KToklaSvr4/Zs2dj9uzZig6l2iwtLSEQCNC+fXscPnxYZRfjMcZw48YNbqsmZ2dnAKBEkxBSLZRsqriuXbsiPj4enTt3pkSzjvD5fLRu3Ro5OTnUm9yAvd3b5+LigsuXL8PV1VWle2h4PB4EAgEYY4iNjeWSTULI/5k+fTpycnIQFBSk6FBUBq0cUTEikQj//fcft4hCXV0dEyZMQJMmTRQcWcPi6emJzz//nLZCaqDOnj0LJycn3LhxgzvWtWtXlU00355N1b9/f4wfPx79+/dXYESEkPqEkk0VkpaWhm3btuHq1au4du2aosNp8HR0dLj/p6Wl4eDBgyguLlZgRKSuBAYGIi0tDRs2bFB0KNUilUpx5coVnDx5kjvG5/Opx56QKnr69CkGDRoEfX19WFlZYcqUKcjIyOC+L5VKsXbtWjg5OUFHRwft27dHYGCgAiOuG5RsqgDGGO7fv49t27YhIyMDBgYGtNJciTDGEBgYiBcvXuDixYuKDofUgT///BOrV69W+YtESkoKgoOD8fDhQ8THxys6HEIAlO63W1hYKNPjLhKJUFhYCKFQWG5bqVTKHSspKUFhYaHch/+K2taUnJwc9O7dG25ubrh79y7Onz+P1NRUjBs3jmuzdu1a7N69G3///TciIiLw5ZdfYvLkyTKjJPURJZtKTigU4vjx4zh16hTEYjGaNWsGPz8/2oJHifB4PIwePRpNmjRBv379FB0OqQUnTpzA5MmTuYuUnp4evv32W5WfJ21ra4t+/fphzJgxKl2rndQv+vr60NfXl+kR/OWXX6Cvr4/PP/9cpq2lpSX09fURFxfHHSur1DVr1iyZto0bN4a+vj4iIyO5Yzt37qyxuDdv3gw3NzesWbMGLVq0gJubG7Zv345r167h5cuXEAqFWLNmDbZv344BAwagSZMmmD59OiZPngx/f/8ai0MZ0QIhJZaSkoLAwEBkZmaCx+Ohd+/e8PLyUqpKKaSUtbU1pkyZInNMKBSqfDLS0IlEInz99dfYtGkTAKBv374qXQlIIpHg1q1b6NixI/T09AAAHh4eCo6KkPrh0aNHuHbtWrklaaOjo1FSUgKBQCDXKSESieDm5lZXYSoEJZtKiDGGe/fu4fz585BIJDA0NMSYMWPg4OCg6NDIR3r58iWCgoIwfvx4ODo6KjocUgUxMTEYP348V/p10aJFmDhxooKjqp5Tp07h0aNHiI+Px6RJk+iDK1FKBQUFAGS33FqyZAm++OILuQIPaWlpAGTn0M+bNw9z5syBurq6TNvXr1/Lta3JD48FBQUYNmwYfv75Z7nv2djY4OnTpwCAM2fOwM7OTub79b1jgpJNJSMUCnHq1Cmu5GTz5s0xYsQI2udOhTDGEB4ejqKiIjx69IiSTRUUGBiIWbNmIS8vDyYmJti1axeGDRum6LCqzdPTE9HR0XB3d6dEkyitsl73t2lqapZbvaq8thoaGtDQ0PjotjWlQ4cOOHr0KBo3blxu1bNWrVpBS0sLcXFx6NGjR409riqgZFOJJCUlITAwENnZ2VBTU0Pfvn3RtWtXuiioGB6Ph3HjxuHOnTvw9PRUdDikEoqLi7F48WJs2bIFQOkQ88GDB1V2VEEikSAtLQ02NjYASue3LVy4UCXKfxKizHJzc/Hw4UOZY76+vti2bRt8fHzw9ddfw9TUFFFRUTh48CD++ecfGBgY4KuvvsKXX34JqVSKbt26ITc3F8HBwTA0NMS0adMU82TqAL3jKAnGGE6dOoXs7GwYGRnB29tbJcv2kVIaGhro3r27zLHXr1/Twi4l9urVK4wbN467gHzzzTdYvXp1jfZ81KXCwkLs378fmZmZ8PX1hampKQBQoklIDbh+/brcPMtZs2YhODgY33zzDfr37w+hUAhHR0cMHDgQamql67FXr14NCwsLrF27FjExMTA2NkaHDh2wbNkyRTyNOkO10ZVIamoqbt26hcGDB8vMKSGqLyQkBJcuXYKnpyetWFdCBw4cgK+vLwoKCmBubo7du3dj0KBBig6rWqRSKXbu3In09HSMGzcOTk5Oig6JNEBUG71+o9roKiAhIQFpaWno0KEDAMDKygpjxoxRcFSkNpR9pqO5t8qlqKgICxcuxLZt2wAA3bt3x4EDB+Qm76sKsVgMdXV18Hg8qKmpwdvbG4wxGBkZKTo0QkgDRsmmgqSmpmLHjh0ASudR0ZB5/ebl5YXGjRurbBJTXwkEApw/fx48Hg/Lly/HihUrVHaYOTMzE4GBgXB1dUWXLl0AoF6PBBFCVIdqvqvWA5aWlmjZsiUYY1Rfu4F4O9GUSqW4ceMGPDw8aPhIgczMzHDo0CEUFhaib9++ig6nWqKjo7mKQB06dFDZuaaEkPqHks06FB8fDwsLC2hra4PH42HkyJHckBdpWM6fP4/w8HDExMRg5syZ9DtQRwoLCzF//nx069YNM2fOBFB/NjXv1KkTBAIBJZqEEKVD5SrrAGMMt27dwo4dO3Dy5Elu/h6fz6cko4Hq0KEDDAwM0K1bN/odqEO7d+/Gjh07sHDhQmRlZSk6nGrJyMjAqVOnuBKaPB4PPXv2pKFzQojSoZ7NWlZYWIigoCBERUUBANTV1SGRSFR2XhipGdbW1pg/f75MDxRjjBLPWubn54c7d+5gxowZ3FZAqkgsFmP37t3Iz8+HoaFhg9sgmhCiWqhnsxa9efMG/v7+iIqKAp/Px7BhwzB69GhKNAkA2coVRUVF2LlzJ968eaPAiOqfgoICLF++HAKBAACgpqaGXbt2oWfPnooNrJr4fD4GDBgAJycnbjcLQghRVpT11AKpVIpbt27h+vXr3AIgb29vWFlZKTo0oqRu3LiBuLg4nDhxAvPmzZOr6Usq79GjRxg3bhxevnyJjIwM+Pv7KzqkaklLSwOPx4OFhQUAoHXr1mjVqhX1hhNClB4lmzWsoKAAx44dQ2xsLACgffv2GDx4cLk1XQkp06dPHxQVFcHT05MSzWpijCEgIAALFy6EUCiEnZ0dJk+erOiwqiUqKgqHDh2CiYkJZs+ezb2fUKJJCFEFlGzWoJiYGBw7dgyFhYXQ0NDA4MGD4erqquiwiArQ0NDAqFGjZI4VFBRAX19fQRGppry8PPj6+uLQoUMAgMGDB2PXrl0qv72YjY0NtLW1YWBgALFYTB9eCVFCPXv2hKurKzZu3FijbesDSjZrQNmeiTdv3gRQuoemt7c3N9xFSGVlZGRgx44dcHV1Rd++fakH6yPcv38f48aNQ3R0NPh8PtasWYPFixdzNYlVTVFREVe2Vk9PDzNnzoSxsTH9LhCiYNOnT8euXbvkjoeGhqJly5YKiEj5UbJZA65evYrg4GAAgJubGwYNGkT73JFqef36NQQCAWJjYyEWi+n36T0YY/jrr7+wePFiiEQiODg44ODBgyq7fyZjDPfv38fFixcxceJEODo6AgBMTEwUHBkhpMzAgQO5KoBlLCwsFDoNSiQSKe2oh2p+5FcyXbt2hampKUaPHo3hw4dTYkCqrWPHjhgzZgwmTZpEv0/vkZOTA29vb8yfPx8ikQjDhw/HgwcPVDbRLBMXFweRSIRHjx4pOhRCSDm0tLRgbW0tc+vTpw+++OILrs2WLVvg7OwMbW1tWFlZwdvbW+YcUqkUX3/9NUxNTWFtbY2VK1fKfD8nJwezZ8+GhYUFDA0N0bt3b5n3hJUrV8LV1RX//PMPnJyclLoaHfVsVoFUKsWLFy+47nJ9fX3MmzdPZYfriHJq06aNzNcxMTGwtbVV6jeUuhQWFobx48fj9evX0NDQwC+//IIFCxao/DAzj8fDkCFDYG9vD3d3d0WHQ0idYYyhpKREIY+toaFRo+8dd+/exYIFC7Bnzx54enoiKysL//33n0ybXbt2YdGiRQgNDcXt27cxffp0eHl5oV+/fgCAsWPHQkdHB+fOnYORkRH8/f3Rp08fvHz5ktsnOCoqCkePHsWxY8eUenEpJZuVJJVKsWvXLsTFxWH06NFo27YtAFCiSWpVTEwM9u3bB0tLS0ydOpWby9dQMcawePFivH79Gk5OTjh06BA6deqk6LCqhDGG8PBw5OTkoH///gAATU1NdOzYUcGREVK3SkpKsHbtWoU89tKlSys1BH369GmZBZyDBg2S+X5cXBz09PQwdOhQGBgYwNHREW5ubjJt2rVrhxUrVgAAnJ2dsXnzZly5cgX9+vXDrVu3EBYWhrS0NGhpaQEANmzYgKCgIAQGBsLX1xdA6dD57t27lX6NCCWblaSmpgZHR0ekpKQo9acIUr/o6OhAR0cHZmZm3BtPQ8bj8bB7926sWrUKv//+O4yNjRUdUpUlJyfj3LlzAIAWLVrAwcFBwRERQj6kV69e2Lp1K/e1np4efHx8uK/79esHR0dHNGnSBAMHDsTAgQMxatQo6Orqcm3atWsnc04bGxukpaUBKN0nuKCgAGZmZjJtioqKEB0dzX3t6Oio9IkmQMnmR5FIJCgqKuI+xfTs2RMdOnRQ6QscUS02NjaYPXs29PX1G2wvekhICG7fvo3FixcDAJycnOQm6KsiW1tbdO/eHbq6urC3t1d0OIQojIaGBpYuXaqwx64MPT09NGvWrMLvGxgY4P79+7h+/TouXryI77//HitXrkR4eDiXO7z7mDweD1KpFEDp1nc2Nja4fv263Lnfzj309PQqFbeiULL5ATk5OQgMDIRUKsXMmTPB5/OhpqZGiSapc+/+zt26dQsODg4Noifs1atX6NGjB8RiMdq3b4++ffsqOqQqK1tt3rp1a27+be/evRUcFSGKx+PxlHY1dVXw+Xz07dsXffv2xYoVK2BsbIyrV69i9OjRH7xvhw4dkJKSAj6fj8aNG9d+sLWMks33eP78OU6cOIHi4mJoa2sjPT0dNjY2ig6LEERERODKlSvg8/n4/PPPYWRkpOiQapWzszPmzJmD7OxsdO7cWdHhVMu5c+cQHh6OmJgYeHt7q/yCJkKIvNOnTyMmJgaffPIJTExMcPbsWUilUri4uHzU/fv27QsPDw+MHDkS69evR/PmzZGUlIQzZ85g1KhRKjenm5LNcojFYly+fBmhoaEAADs7O3h7e1NvJlEazZs3R/PmzWFra1tvE81bt26hadOm3Ae8P/74A+rq6iqfnLVv3x6PHj2qF70VhJDyGRsb49ixY1i5ciWKi4vh7OyMAwcOoHXr1h91fx6Ph7Nnz2L58uWYMWMG0tPTYW1tjU8++QRWVla1HH3N4zHGmKKD+JC8vDwYGRkhNzcXhoaGtfpY2dnZOHLkCJKTkwEAHh4e6NOnDy0GIkpHKpWCx+NxyZdUKq0X8zmlUinWrl2L77//Hj169MClS5dU+u+PMYbs7GxuqxJAtjoQIfXZ+67fxcXFiI2NVfo9IknFPvY1pJ7Ntzx79gwnT56EUCiEjo4ORowY8dFd3oTUtbcTS6lUisDAQJiamqJPnz4q2/uXmpqKKVOm4NKlSwBKRxVEIpHKJmbFxcU4evQokpKS4Ofnx11sVfX5EEJIVVSqG2Tr1q1o164dDA0NYWhoCA8PD27LjoocOXIELVq0gLa2Ntq2bYuzZ89WK+DaIBaLcebMGRw5cgRCoRD29vbw8/OjRJOojJiYGERGRuLOnTtIT09XdDhVcvXqVbi6uuLSpUvQ0dHB9u3bsXv3bpVOzPh8PgoKCiASibjREkIIaWgq1bPZqFEjrFu3Ds7OzmCMYdeuXRgxYgQePHhQ7jyEkJAQ+Pj4YO3atRg6dCj279+PkSNH4v79+3LVURQlMzMTgYGBSElJAQB4eXmhV69eKj1sRxqeZs2aYdiwYdDW1oalpaWiw6kUiUSC1atXY9WqVWCMoVWrVjhy5AhatWql6NCqhDHG9Szz+Xx4e3tDLBar5DwrQgipCdWes2lqaopffvkFs2bNkvve+PHjUVhYiNOnT3PHunbtCldXV/z9998VnlMoFEIoFHJf5+Xlwd7evsbnbAYFBXF1RqVSKQoLCyEWiz94vyFDhnDlpBISErBhwwYYGRnhhx9+4Nps3LgRr1+/rlQ8PXr0wKhRowCUbrm0cuVKqKur49dff+Xa/PPPP3j69Gmlzuvu7o4pU6YAKO3F/eqrrwAAa9eu5XqNDh48iDt37lTqvC4uLvjss8+4r//3v/+huLgYy5cv5zaZPX36NC5fvlyp89rZ2WHJkiXc1z/++CMyMjKwcOFCODk5AQCuX7+OoKCgSp23otdo1qxZXCWou3fvYu/evZU6b0Wv0fjx47ka3c+fP3/v73xFynuNyvv9Kw+Px0NFf97lvUbl/f5VVnmvUUW/f2Xu3r2L4OBgAMDMmTPx559/ymx8rEoKCgpw/PhxtG3bFq6urooOhxCFozmb9dtHv4asisRiMTtw4ADT1NRkERER5baxt7dnv//+u8yx77//nrVr1+69516xYgUDIHfLzc2tarhypFIpW7duHVu5ciV3++6779jcuXOZt7c3++STT1iLFi2Yqakp4/F4MnH89NNP3Hnu37/PADBbW1uZ83t4eJT7HN53++KLL7j7JyQkMABMQ0ND5rzDhw+v9HknTpzI3V8oFHLHc3JyuOOzZ8+u9Hn79esnE5uhoSEDwF6+fMkdW7p0aaXP6+rqKnPeZs2aMQAsODiYO/bbb79V+rwVvUZBQUHcsb1791b6vBW9RgEBAdyxCxcuVPq8Fb1G5f3+vXvT0tJifn5+zM/Pj+np6cl9v7zXqLzfv8reynuNKvr9e/ump6fH9uzZw1RdcHAwW7lyJVu/fj0TCoWKDocQhcvNza3w+l1UVMSePXvGioqKFBAZqQkf+xpWeoHQkydP4OHhgeLiYujr6+P48eMVDnelpKTIDR1ZWVlxQ9YVWbp0KRYtWsR9XdazWZMYY+jVqxcuXboEkUgEHo8HdXV1WFpayg1DMsZkbi4uLtynNCsrKyxbtkzuE9u0adPQq1evSsXk6enJ/V9fXx/Lli2TG84fO3ZspacgtG/fnvu/mpoali1bBgAyZQ8HDx5c6eHXd6snLF68GEKhECYmJtyxnj17Vnqxyrt7mX722WfIzMyEnZ0dd6xz587c8/hYFb1Gzs7O3LHWrVtX+rwVvUZv92w5OTlV+rxA+a/R278nZb9/7+LxeODzS/+8Fy5cKPf98l6j8n7/Kqu816ii378yWlpa8PHxkXkdVFXXrl25vUDr0+bUhBBSHZUeRheJRIiLi0Nubi4CAwPxzz//4MaNG+UmnJqamti1a5dMvdAtW7bghx9+QGpq6kc/Zl1sfcQYQ35+PtLS0mRu6enpFQ6ta2lpwdLSEhYWFlySamlpqTLlo0j9lpmZCZFIRIUIalF+fj7Cw8PRq1cvld0BgJDaRMPo9VutbX2kqanJ9Wi5u7sjPDwcmzZtgr+/v1xba2truaQyNTUV1tbWlX3YWsfj8bhV9m/32EmlUuTk5MgloZmZmRAKhYiPj0d8fLzMufT09MpNQt/upSKktpmZmcl8nZqaCqFQ2CDKW9YFiUSC7du3IycnB1paWvDy8lJ0SIQQopSqvc+mVCqVWczzNg8PD1y5cgVffPEFd+zSpUvcoglVoKamBlNTU5iamqJFixbccbFYjMzMTJke0LS0NGRnZ6OwsBCxsbGIjY2VOZeRkZFcEmphYcENdxJSW3JycrB3714UFxdj8uTJcHR0VHRIKk9dXR3du3dHaGgobZNGCCHvUaksZ+nSpRg0aBAcHByQn5+P/fv34/r167hw4QIAYOrUqbCzs8PatWsBlM4V69GjB3799VcMGTIEBw8exN27dxEQEFDzz6SO8fl8WFlZyc1JFYlEXOL5dhKan5+P3Nxc5Obm4tWrV1x7Ho8HU1NTmR5QS0tLmJqa1otqMEQ56OnpwcbGBnl5ebQFTzXk5eVBKpVypWvd3NzQrl07+sBICCHvUal3yLS0NEydOhXJyckwMjJCu3btcOHCBW4blri4OJkEydPTE/v378e3336LZcuWwdnZGUFBQUqzx2Zt0NTUhJ2dncxCCaC0PN27c0FTU1NRXFyMzMxMZGZmIjIykmuvrq4Oc3NzuSTUyMiI5oaRStPQ0MD48eMhFAppblQVxcXF4eDBgzAxMcGMGTPA5/NlFmIRQhqWlJQUrF27FmfOnEFCQgKMjIzQrFkzTJ48GdOmTauxLdx27tyJL774Ajk5OTVyPkWo1Lvkv//++97vX79+Xe7Y2LFjMXbs2EoFVR/p6OjA0dFRZviSMYaCggK5JDQtLQ0lJSVITU2Vm/OqqakpNxe0bFESJaHkfdTV1WXe/J4/f46kpCRa3PKRjIyMAJT+3RYVFcHAwEDBERFCFCUmJgZeXl4wNjbGmjVr0LZtW2hpaeHJkycICAiAnZ0dhg8frugwlQZ9JFcgHo8HAwMDGBgYoGnTptxxxpjMoqSyBDQ9PR0ikQiJiYlITEyUOZeOjo5cAmphYaHSpf5I7cnLy8PRo0chFothZmYmsz0R+T9isZjruTQyMsLUqVNhbm5OvZmE1CKRSFTp+/D5fG5kVSqVQiwWg8fjQUND44Pnrco2ZXPnzgWfz8fdu3dldqBp0qQJRowYAcYYXr9+DScnJzx48IDbCi8nJwcmJia4du0aevbsievXr6NXr144ffo0li5dipcvX8LV1RX//PMP2rRpg+vXr2PGjBkAwHUKrFixAitXrsSePXuwadMmvHjxAnp6eujduzc2btyolFXk6B1TCfF4PJiYmMDExERm4YFEIkFWVpZcEpqVlYWioiK8efMGb968kTmXgYFBuUno23+ApOExNDTEwIEDER0dzVVPIrJevHiB06dPY+LEidz2Ucq4kwYh9U3Zuo/K8Pb25spmR0ZGIjAwEI6Ojpg+fTrXZtOmTRAIBHL3XbFiRaUeKzMzExcvXsSaNWsq3OqwsqNFS5YswaZNm2BtbY1ly5Zh2LBhePnyJTw9PbFx40Z8//33ePHiBYDSfZABoKSkBKtXr4aLiwvS0tKwaNEiTJ8+HWfPnq3UY9cFSjZViLq6OiwsLGBhYSFTi76kpAQZGRlySWhubi7y8/ORn5+P6OhomXOZmJjIJaFmZmZUE74BcXd3R4cOHbg3RcYYJBIJ9dr9fw8fPkRBQQGCg4Ph7e2t6HAIIUoiKiqKK/DyNnNzcxQXFwMA5s2bJ1PO+UNWrFjBrX/ZtWsXGjVqhOPHj2PcuHHcWo13P+zOnDmT+3+TJk3wxx9/oFOnTigoKOASUmVBV5V6QENDAzY2NnKbdxcXF8usjC+7CQQCZGdnIzs7m/ukBJRu82RmZiaXhJqYmNCcvnrq7df11q1biIyMxKRJk6gwAYDhw4fDysoK3bt3V3QohDQoS5curfR93v6Q3LJlSyxdulTuulVeNbWaFBYWBqlUikmTJlW4JWRF3t4S0tTUFC4uLjKLhstz7949rFy5Eo8ePUJ2djakUimA0sWMFVV2VBRKNusxbW1t2Nvby5X6LCwslEtA09LSuG2b0tPTERERwbXn8/kyQ/Bl/zcwMKAktJ4oKirCnTt3IBAI8OLFC3To0EHRIdW5yMhIZGZmolu3bgBK50H37NlTsUER0gBVt9SrmppaueeoqRKyzZo1A4/Hk+msAUp7FwFwayXK5pC+XaixpKSkRmIoLCzEgAEDMGDAAOzbtw8WFhaIi4vDgAEDqjTntbZRstkA6enpwcnJCU5OTtwxxhjy8vIqLNeZlJSEpKQkmfNoa2uXWympprZ7IHVHR0cHM2fObLCJZnJyMg4fPgwAcHBwoCpLhJAKmZmZoV+/fti8eTPmz59f4UiQhYUFgNL3Fzc3NwCl03PKc+fOHe59Jzs7Gy9fvkTLli0BlCbJEolEpv3z58+RmZmJdevWcR1Kd+/erfZzqy2UbBIApcOpRkZGMDIygrOzM3dcKpUiOzu73HKdxcXFiIuLQ1xcnMy59PX1y62UROU6lZuZmRk8PT25ryUSCTIyMhrEJvA2NjZwd3eHlpaW3B65hBDyri1btsDLywsdO3bEypUr0a5dO6ipqSE8PBzPnz+Hu7s7dHR00LVrV6xbtw5OTk5IS0vDt99+W+75Vq1aBTMzM1hZWWH58uUwNzfHyJEjAQCNGzdGQUEBrly5gvbt20NXVxcODg7Q1NTEn3/+iU8//RRPnz7F6tWr6/AnUDmUbJL3KpvHaWZmxn3KAuTLdZbdcnJyUFBQgIKCAsTExMicy9jYWC4JpW1klBNjDCdOnEBkZCTGjRsn8wGkvnjx4gWaNGnC7cwwZMgQmhZCCPkoTZs2xYMHD7BmzRosXboUCQkJ0NLSQqtWrfDVV19h7ty5AIDt27dj1qxZcHd3h4uLC9avX4/+/fvLnW/dunVYuHAhXr16BVdXV5w6dYob9vf09MSnn36K8ePHIzMzk9v6aOfOnVi2bBn++OMPdOjQARs2bFDavT157O3JBEoqLy8PRkZGyM3NhaGhoaLDIe/xbrnOsltBQUG57Xk8Hrco6e0klMp1KpZYLMahQ4cQExMDHx8fNGvWTNEh1airV6/iv//+g5ubm9K+ORNSH7zv+l1cXIzY2Fg4OTk12MpmZftsZmdnc2VwVcnHvobUpURqVEXlOgUCQblJaHFxMTIyMpCRkSHTvmybp3eTUCrXWTf4fD4mTJiAxMTEejl/0cnJCbdu3YKenh4YY/Q7RQghtYiSTVIndHV1KyzXmZqaKrM/aFpaGsRiMVJSUpCSkiJzHk1NzXIXJSnbnmL1gbq6ukyiKRAI8PjxY3Tp0kUlkzOBQMAtXnNycsL8+fNhYmKi4KgIIaT+o2STKMzb5TrfHqZljMksSipLQjMyMiASiZCQkICEhASZc+nq6pZbKamhDs3UNKlUiv379yMxMRECgQC9e/dWdEgfraSkBGfPnkVMTAz8/Py4hJMSTUKIovXs2RMqMJux2ijZJEqHx+PB1NQUpqamaNGiBXdcIpHILEp6u1ynQCDA69ev8fr1a5lzGRoayiWh5ubmVK6zktTU1ODm5obs7GyVK2/JGEN8fDzy8vIQExODNm3aKDokQghpUCjZJCpDXV2dSxjfVlJSIjMEX/b/vLw87hYVFSVzH1NTU7kk1NTUlMp1voe7uzvatGmjcltYaWpqYuzYsRAIBDJ7yxJCCKkblGwSlaehoQFbW1vY2trKHC8uLpbboD41NRVFRUXIyspCVlYWnj9/zrVXU1ODubm5XBJqbGysknMUa8PbiWZ6ejouXLiAUaNGKVV5S5FIhDNnzqBFixbcdl0NYa9QQghRVpRsknpLW1tbrhoMY0yuXGdZT6hIJOKOvU1DQ0NuQVLZoqSGmoQyxnDs2DGkpKTgwoULGD16tKJD4oSFheHx48d49eoVmjZtWmMl6gghhFQNJZukQeHxeNDX14e+vj5XxxYoTZ5yc3PlEtD09HSUlJS8t1znu7eyurj1GY/Hw5gxY3DhwgUMHDhQ0eHI8PDwQFJSErp06UKJJiGEKAHa1J2Q95BKpcjKypJLQjMzMytcQVhWrvPdlfENIfEpLi6u8x0AhEIhHj58iM6dOzfYnmZClBVt6l6/0abuhNSAsnmc5ubmaNWqFXdcLBYjIyNDbpP63NzcCst1mpiYlFuus74sSnr16hWOHj0Kb2/vOqs4JJFI8O+//yI9PR1qamro1KlTnTwuIYRU1cdUDdq5cye++OIL5OTk1GlstYWSTUKqgM/nw9raGtbW1jLHhUJhuZWSCgsLkZ2djezsbLx48YJrX1Z7/t0k1MTEROXKdT548ABCoRARERF1lmyqq6vD1dUVYWFhcq8FIYTUhunTp2PXrl0ASq8FjRo1wtixY7Fq1aoa66EdP348Bg8eXCPnUgaUbBJSg7S0tNCoUSM0atRI5nhhYWG5SWhZcpqeni7Tns/nl1uu09DQUGmHiseMGYOwsDB07ty5Vh+nuLgYYrGYqxrl4eGBDh060DAcIaTODBw4EDt27EBJSQnu3buHadOmgcfj4eeff66R8+vo6NSr+f+q1XVCiIrS09ND48aN0blzZwwdOhQzZ87EN998gy+//BKTJk1Cv3790L59e9jY2IDP50MsFiM5ORmPHj3C5cuXsX//fmzcuBE///wztm/fjlOnTiE0NBSxsbEoLCxU9NMDUNrL6OHhITMtIDo6ukarY6SkpMDf3x+BgYGQSqUAShcrUaJJSP0hEokgEolk3jskEglEIhHEYnGNt60KLS0tWFtbw97eHiNHjkTfvn1x6dIlAKUjXAsWLIClpSW0tbXRrVs3hIeHy50jODgY7dq1g7a2Nrp27YqnT59y39u5c6fMEPvKlSvh6uqKPXv2oHHjxjAyMsKECROQn5/PtQkMDETbtm2ho6MDMzMz9O3bl7s+SKVSrFq1Co0aNYKWlhZcXV1x/vx57r6vX78Gj8fDsWPH0KtXL+jq6qJ9+/a4fft2lX4+76KeTUIUhMfjwdDQEIaGhjLDzlKpFDk5OXK9oJmZmRAKhYiPj0d8fLzMufT09MqtGa/IDdhv376Nixcvwt3dHUOGDKmRHlkNDQ0IBAIApQsPKprvRAhRXWvXrgUAfPXVV9wevsHBwbh27Rrc3NwwfPhwru2GDRtQUlKChQsXcu8H4eHhuHDhAtq2bSuzLdumTZsgEAjw2WefccVBHj58CHd392rF+/TpU4SEhMDR0REA8PXXX+Po0aPYtWsXHB0dsX79egwYMABRUVEwNTXl7rdkyRJs2rQJ1tbWWLZsGYYNG4aXL19WWOEuOjoaQUFBOH36NLKzszFu3DisW7cOP/30E5KTk+Hj44P169dj1KhRyM/Px3///ccl1ps2bcKvv/4Kf39/uLm5Yfv27Rg+fDgiIiLg7OzMPcby5cuxYcMGODs7Y/ny5fDx8UFUVBT4/Oqli5RsEqJk1NTUPqpcZ9ktOzsbhYWFiI2NRWxsrMy5jIyMyl2UVBflOsseo7qb4jPGuPubmZnBx8cH1tbW1JtJCFGY06dPQ19fH2KxGEKhEGpqati8eTMKCwuxdetW7Ny5E4MGDQIAbNu2DZcuXcK///6LJUuWcOdYsWIF+vXrBwDYtWsXGjVqhOPHj2PcuHHlPqZUKsXOnTthYGAAAJgyZQquXLnCJZtisRijR4/mkt63Swtv2LAB33zzDSZMmAAA+Pnnn3Ht2jVs3LgRf/31F9fuq6++wpAhQwAAP/zwA1q3bo2oqCiZa1FVULJJiIqoqFynSCQqd2V8fn4+cnNzkZubi1evXnHty2rPlyWhVlZWXLnOmlyU1LFjRzRq1Kha1XsSEhJw8uRJjBs3Dubm5gCAxo0b11CEhBBltHTpUgCQ+VDs5eWFrl27yr1HffXVV3JtO3XqhA4dOsi1XbhwoVxbV1fXKsXYq1cvbN26FYWFhfj999/B5/MxZswYPH78GCUlJfDy8uLaamhooHPnzoiMjJQ5h4eHB/d/U1NTuLi4yLV5W+PGjblEEwBsbGy4IiTt27dHnz590LZtWwwYMAD9+/eHt7c3TExMkJeXh6SkJJmYgNKf6aNHj2SOtWvXTub8AJCWlkbJJiENnaamZrnlOouKirhFSampqdz/i4qKkJmZiczMTJk3NnV19XLLdRoZGVW5Z/LtFeJSqRRXr16Fh4fHR5e3vHHjBtLT03HlyhWMHz++SjEQQlRLeXsSq6url7tNXE20rQo9PT1u+tP27dvRvn17/Pvvv7W6/dq7I1I8Ho+bu66uro5Lly4hJCQEFy9exJ9//only5cjNDQUZmZmVXqMsvf9sseoDko2CamndHR0yi3XWVBQUG65zpKSEqSmpiI1NVXmPJqamuWW69TT06tUEnrx4kWEhoYiKioKvr6+H9WLOmLECFy/fp0baiKEEGWjpqaGZcuWYdGiRYiKioKmpiaCg4O54eySkhKEh4fjiy++kLnfnTt3uPfn7OxsvHz5Ei1btqxyHDweD15eXvDy8sL3338PR0dHHD9+HIsWLYKtrS2Cg4PRo0cPrn1wcHCt7x5ShpJNQhoQHo8HAwMDGBgYoGnTptxxxpjMoqSyBDQjIwMikQiJiYlITEyUOZeOjk65lZIq2q6jY8eOePHiBXr27FlhohkXF4f09HRuwr6+vj6GDh1aQ8+eEEJqx9ixY7FkyRJs3boVn332GZYsWQJTU1M4ODhg/fr1EAgEmDVrlsx9Vq1aBTMzM1hZWWH58uUwNzfHyJEjq/T4oaGhuHLlCvr37w9LS0uEhoYiPT2dS16XLFmCFStWoGnTpnB1dcWOHTvw8OFD7Nu3r7pP/aNQskkIAY/Hg4mJCUxMTODi4sIdl0gk5ZbrzMrKQlFREd68eYM3b97InMvAwEAuCS2rwjRv3jyZVY1vL/5JSUnBzp07AQBWVlZye5USQoiy4vP5+Pzzz7F+/XrExsZCKpViypQpyM/PR8eOHXHhwgWYmJjI3GfdunVYuHAhXr16BVdXV5w6darKZY0NDQ1x8+ZNbNy4EXl5eXB0dMSvv/7KLVJasGABcnNzsXjxYqSlpaFVq1Y4efKkzEr02kS10QkhlVZSUiKzKKksCc3Nza3wPmXlOt+eC3rhwgX07NkTzZo1A2MMx44dg5qaGoYMGdIgaskTUt9RbfT6jWqjE0JqjYaGBmxsbLjVimWKi4tlKiWV/b+icp0AcODAAbRp0waOjo7o1q0bLCwsVK5UJyGqKikpCdbW1vQ3R2oVJZuEkBqjra0Ne3t72NvbyxwvLCyUW5SUmpoKkUgEqVSKx48f4/HjxwBK54KWncPe3h62trZ1si8oIQ3Nr7/+iu+++w5btmzB9OnTFR0Oqcco2SSE1Do9PT04OTnBycmJO8YYQ15eHlJSUpCQkID4+HgkJiaiqKgIL1++xMuXLwGUrvS0sbHhkk8HBweuLjohpOqkUimKiopw5swZSjZJraJkkxCiEDweD0ZGRjAyMuIWJUkkEqSkpCAuLg4JCQmIi4tDQUEBtxr+zp07AErnf77d+0lD74R8WHh4OAwMDLgNuhcsWABnZ2eMGDFCwZGR+o6STUKI0lBXV4ednR3s7OwA/N+WTGX14OPj45GamsrN/ywbetfS0kKjRo24nk87OztaYETIW7Zs2YJ58+ahb9++uHjxIng8HrS0tKq81U5NUoF1yqQCH/vaUbJJCFFab2/JVFZGrbi4GImJiYiLi0N8fDwSEhIgFAoRHR2N6Oho7n7W1tYyvZ9GRkaKfCqEKNTAgQOhra0NW1tbCIVCpVj9XVa9RyQSVbg/L1FuAoEAgHx1o3fR1keEEJUmlUqRmpoq0/tZ3hZMhoaGMvM+raysaOid1EuMMRw5cgQpKSlYsGABdzw5OVluB4na9r7rN2MMcXFxKCkpga2tLf09qhDGGAQCAdLS0mBsbPzB3ytKNgkh9U5eXh7X8xkfH4+UlBS54R4NDQ1u6N3e3h6NGjVSit4eQqrr6tWr6NOnD7S0tPD8+XM0btxYYbF86PotEom4TdCJ6jE2Noa1tfUHSxdTskkIqffKSm6+3fspFArl2llaWsr0fhobG1eq/jshiiKVSrmeQcYYhg0bhs6dO+Orr76Crq6uwuL6mOu3VCqFSCSq48hIdWloaHBTIT6Ekk1CSIPDGEN6erpM72d2drZcO319fZl5nzY2Nh/95kpIXSguLsbGjRsRGBiIkJAQbmHc26VgFYmu3wSgZJMQQgAABQUFMj2fSUlJckN7fD4ftra2XM9no0aNFNprREheXh6aN2+O1NRU7Nq1C1OnTlV0SDLo+k0ASjYJIaRcJSUlSE5Olun9LCoqkmtnbm4u0/tpZmamFD1KpP568+YNHB0dua8PHz4MkUiEiRMnKt0iG7p+E4CSTUII+SiMMWRmZiI+Pp7bdD4jI0Ou3dvlNh0cHGBraws+n3aZI9XHGMNnn32Gbdu24ebNm/Dy8lJ0SB9E128C0D6bhBDyUXg8HszNzWFubg43NzcApXvMvTv0Xl65zbKh97IbldskVcHj8SCRSCCVSnHp0iWVSDYJAahnkxBCaoxEIkFycjKXfMbFxaGwsFCunYmJCTfn08HBARYWFjT0TuQwxnDy5El4eXnB3NwcAJCamoqoqCiVSTTp+k0ASjYJIaTWlJXbfHveZ1pamlw7LS0tmZ5PKrdJAGD+/PnYvHkz5s6di7/++kvR4VQJXb8JQMPohBBSa94ut9m+fXsApVvVJCQkcMlnWbnNqKgoREVFcfcrK7fp4OAAe3t7ulA3QGPGjMG2bdtgZmamNFsZEVIV1LNJCCEKVFZu8/+1d+fhNV17H8C/J9OJzIMkIiMSEiI1XEMEcaUVw9WL9yUNWlRpEXMVl7bmaF+0t9q3hltUi5piykWrqKGRlpAIkZFIiESIjDKf9f7hzb52k6iQk5OTfD/Pc56n53fWOfu3U/vs31l7r7We7v3My8ur0s7c3FzW+8nlNhuX0tJSfPnll3B0dMSoUaOk+P3792Fra6vBzF4Oz98EsNgkImpwcnNzZaPeq1tu08DAAA4ODlLvp4ODA5fb1GJfffUVgoOD0bJlS8THxzeaQWQ8fxPAYpOIqMErLS2t9tL7H9nZ2cl6P7ncZsNWUVEhrUhVXFyM/v3745133sG4ceMazUpVPH8TwGKTiEjrqFQqZGVlyUa95+TkVGlnYmIiG/XeokWLRlPEaLPs7Gx89NFHSElJwZEjR6QfBI3xvkyevwlgsUlE1Cjk5+fL5vy8d+9etcttVl56r3w0a9ZMQxk3XUlJSWjfvj3Kysrw+++/o1u3bppOSW14/iaAxSYRUaNUVlaG9PR0WQH6rOU2K0e9W1lZNbretYYgOTkZbdq0kZ5/9dVXaN++Pf76179qMCv14/mbgFoWmyEhIQgNDUVcXByaNWuGXr164ZNPPkG7du1qfM+2bdswYcIEWUypVKK4uPi5k+Q/ViKil1O53ObTo94fPnxYpZ2RkZGs55PLbb6c/Px8jBo1Cr/88gvi4+Ph7Oys6ZTqFc/fBNRyns0zZ85g2rRp6NatG8rLy/GPf/wDAwYMQGxsLIyNjWt8n5mZGeLj46Xn/NVMRFS/nl5us0uXLgD+s9xm5aj3u3fv4vHjx4iPj5e+s3V1dWFvby/r/XzW9z3JmZiY4PHjx6ioqMCvv/7a5IpNIuAlL6NnZWXB1tYWZ86cQd++fatts23bNsyaNavam9efF38ZERGpX3l5uWy5zbS0tGqX27SyspL1fnK5zf8oLy/Hd999h7Fjx0JfXx8AEBcXB11dXbi7u2s4u/rH8zcBL7mCUG5uLoAnXzzPUlBQABcXF6hUKnTp0gWrVq1Chw4damxfUlIim9ajugmOiYiobunp6UkFJPDk0vujR4+k3s+0tDRkZWUhOzsb2dnZiI6OBgAYGhrCyclJGvXu4OAgFVpNzYABA3D69Gnk5eVh5syZAAAPDw8NZ0WkWS9cbKpUKsyaNQu+vr7w8vKqsV27du2wZcsWeHt7Izc3F2vWrEGvXr1w/fp1ODo6VvuekJAQLF269EVTIyKiOqBQKGBlZQUrKytpuc2ioiLZnJ93795FcXExEhMTkZiYCADQ0dGRltusfDSVXq033ngDV69ehYWFhaZTIWowXvgy+pQpU3Ds2DGcP3++xqKxOmVlZfD09ERQUBCWL19ebZvqejadnJzYDU9E1MBUVFRIy23euXMHqampyM/Pr9LO3NxcuufTyckJtra2Wr/c5qNHj7B8+XKMGjUKPXv2BPDk75Gfn89i8//xMjoBL1hsBgcH49ChQzh79ixatWpV642OHDkSenp62LVr13O15z9WIiLtIISQltusfGRmZla73Kajo6NUfDo6OkKpVGoo6xczY8YMrF+/Ht27d0dERATvW60Gz98E1PIyuhAC06dPx4EDB/DLL7+8UKFZUVGBmJgYDB48uNbvJSKihk2hUMDCwgIWFhbo2LEjgCdXq+7evSv1fqalpaG0tBQ3b97EzZs3pffZ2trKRr2bm5s3uAKuvLxcmgrqH//4B37//XcsXbq0weVJ1JDUqmdz6tSp2LlzJw4dOiSbW9Pc3FxaheKtt96Cg4MDQkJCAADLli1Dz5494ebmhpycHPzP//wPDh48iMjISLRv3/65tstfRkREjYdKpcL9+/dlvZ/VzVhiamoqu+9Tk8ttJicnY86cOXBxccEXX3yhkRy0Ec/fBNSy2Kzpl9vWrVsxfvx4AEC/fv3g6uqKbdu2AQBmz56N0NBQZGRkwNLSEl27dsWKFSvQuXPn506S/1iJiBq3yuU2K0e9Z2RkVFluU19fHw4ODtKod0dHx3pbbvPUqVPw9/eHUqlEWloabGxs6mW72o7nbwK4XCURETVAZWVluHv3rqz3s7qV52xsbKSeT2dnZ1haWtbJJe2KigrcunULbm5uUmzVqlUYNmzYc1+VI56/6QkWm0RE1OAJIfDgwQPZqPfs7Owq7YyNjWWX3u3t7Wu93ObNmzcxYsQIPHjwAPHx8Vwx6SXw/E0Ai00iItJShYWFsp7P9PR0VFRUyNro6uqiZcuWsgL0z4rH4uJieHp6IicnB8eOHZOmNaLa4/mbABabRETUSFQut1l532daWhoeP35cpZ2VlZVszk+lUol9+/bh7bffltpERkbCxcUFzZs3r89daHR4/iaAxSYRETVSQghkZ2fLej+zsrKqtCsuLkZqair69+8Pf3//Jr3cZl3j+ZsAFptERNSEVC63Wdn7effuXZSXl8va6OjowN7eXhr17uTkBFNTUw1lrN14/iaAxSYRETUhKSkp+PDDDxESEgJHR0dp1HlGRoZ0Cb6goKDK+ywsLGSj3m1sbLR+uc36wPM3AbVcQYiIiEibTZo0CT///DMA4LvvvoOuri7c3NykKY4ql9t8+r7P+/fvIycnBzk5OYiJiQEAKJVK2XKbDg4OWrfcJlF9Yc8mERE1WiqVCkIIaeWhyMhILFiwAGvXroW3t/dzfUZJSYm0zGZaWhru3LmD0tJSWRuFQgE7OztZ76e5uXmd74+24fmbABabRETUSEVERGDGjBl48803MX369Dr73MrlNp/u/czNza3SzszMrMpym03t0jvP3wSw2CQiokZqw4YNmDJlClxcXJCUlFTryd1rIy8vTzbq/d69e/jj6bVyuc2nC1BDQ0O15dQQ8PxNAItNIiJqJAoLC5GVlQVXV1cAT+bdXL58OaZOnQo7O7t6zaW0tBTp6elS7+edO3eqXW7T1tZWNuq9rpbbbCh4/iaAxSYRETUCv/76KwIDA+Hk5ITw8PAGV7AJIZCVlSXr/VTXcpsNCc/fBLDYJCKiRiA9PR1t27aFjY0Nzp49CycnJ02n9KcKCgqqXHqvbrnNP156NzIy0lDGtcfzNwEsNomISAvduXMHZ86cwZgxY6RYeHg4unTporX3QZaXlyM9PV1WgFa33Ka1tbVs1Lu1tXWD68mtxPM3ASw2iYhIy9y+fRvt27dHaWkpYmJi4OHhoemU1KJyuc2nR70/ePCgSrtmzZrJej5btmzZYJbb5PmbAE7qTkREWsbFxQX+/v7Izs6GSqXSdDpqo1AoYG1tDWtra3Tu3BkA8PjxY9mcn3fv3kVRURESEhKQkJAA4D/LbT7d+2liYqLJXaEmjj2bRETUoF28eBGffvopvv32W+l+xfz8fJiYmDTYy8f1paKiAhkZGbLez+qW27S0tJT1ftra2tbL347nbwJYbBIRUQNWXl4Od3d3pKSkYPny5Vi8eLGmU2rQhBDIyclBWloaUlNTcefOHWRmZlZp9/Rym87OznBwcICBgUGd58PzNwEsNomIqIEpLS2VFT579uxBWFgYQkJC4ODgoMHMtFNxcXGV5TbLyspkbRQKBSZPnowWLVrU6bZ5/iaAxSYRETUgoaGhmDNnDjZu3IiAgABNp9MoqVQqZGZmSsVnamoqCgsLsWDBgjqf05PnbwI4QIiIiBqQc+fO4fbt21i3bh2LTTWpHEBkb2+P7t27A3iy+pI2Tx5PDRv/ZRERkcZkZGRAoVBIy0l+9NFHaN68OWbPnq3hzJoWY2NjTadAjZiOphMgIqKmadeuXWjbti3mzZsnxSwtLbFo0SKtWiWHiJ6NxSYREWmEm5sb8vPzkZCQgOLiYk2nQ0RqwmKTiIjqRVRUFA4fPiw979atG86dO4fw8HCtXWKSiP4c79kkIiK1O336NPz9/WFpaYmkpCRYWloCAHr37q3hzIhI3VhsEhGR2vXp0wcdOnRAhw4dUFpaqul0iKgesdgkIqI6JYTA4cOHsW/fPmzfvh0KhQJ6enq4cOEC1+gmaoJYbBIRUZ168OABRo8ejcePH2Po0KEYNWoUALDQJGqiWGwSEdFLKy4ulgb52NjY4OOPP0ZOTg4GDRqk4cyISNM4Gp2IiF6YSqXCunXr4OzsjISEBCn+wQcfYNWqVTA1NdVgdkTUELDYJCKiF6ajo4OTJ08iKysLX3/9tabTIaIGiJfRiYioVmJjY9GqVSs0a9YMALBu3TqMGDEC48eP12xiRNQgsWeTiIie2/Lly+Ht7Y1169ZJsXbt2mHixInQ1dXVYGZE1FCx2CQioufWpk0bVFRUIC4uTtOpEJGW4GV0IiKq0fHjx2FiYiKt9BMUFIQ2bdqgR48eGs6MiLQFezaJiKhaGzZswKBBgzBlyhSUl5cDABQKBQtNIqoVFptERFStUaNGoUWLFggICOASk0T0wngZnYiIUF5ejk2bNiE5ORlr164FAFhZWSE5ORlGRkYazo6ItBmLTSIiQnR0NKZNmwYAGDt2LDp37gwALDSJ6KWx2CQiaqKKioqkuTK7du2KGTNmoF27dujYsaOGMyOixoTFJhFRE/P48WN8+OGH+OGHH3D9+nVYWFgAAP75z39qNjEiapQ4QIiIqInR19fHsWPHkJ6ejr1792o6HSJq5NizSUTUBPz222/o3r07FAoF9PX1sWHDBhQVFSEgIEDTqRFRI8eeTSKiRkwIgTFjxqBnz57Yt2+fFO/bty8LTSKqFyw2iYgaMYVCgbZt20JXVxeJiYmaToeImiCFEEJoOok/k5eXB3Nzc+Tm5sLMzEzT6RARNVgVFRXYsmUL+vXrB3d3dwBPBgSlpKSgffv2Gs6OmhqevwlgzyYRUaMye/ZsTJ48GfPmzZNiRkZGLDSJSGNYbBIRNSJTpkyBjY0N+vXrBy24cEVETQBHoxMRaan8/HysWrUKzZs3x9y5cwEAnp6eSE1NhaGhoYazIyJ6gsUmEZGWCgsLw+rVq2FiYoJx48ahefPmAMBCk4gaFBabRERapLCwEMbGxgCAwMBAhIWFITAwENbW1hrOjIioeiw2iYi0QEZGBmbOnIm4uDhcvnwZurq60NHRwY4dOzSdGhHRM3GAEBGRFtDX18eJEydw7do1/Prrr5pOh4joudWq2AwJCUG3bt1gamoKW1tbDBs2DPHx8X/6vr1798LDwwOGhobo2LEjjh49+sIJExE1BSqVCuHh4dJza2trbNmyBZcvX0bfvn01mBkRUe3Uqtg8c+YMpk2bhoiICJw4cQJlZWUYMGAACgsLa3xPeHg4goKCMHHiRFy5cgXDhg3DsGHDcO3atZdOnoioMSoqKoKPjw969+6Ny5cvS/Fhw4bhlVde0WBmRES191IrCGVlZcHW1hZnzpyp8Zd2YGAgCgsLERYWJsV69uyJTp06YcOGDc+1HXWuQBAVFQUrKys4OTlBoVDU6WcTEb2oMWPG4MiRI9i8eTMCAwM1nQ7RC+EKQgS85D2bubm5AAArK6sa21y4cAGvvvqqLBYQEIALFy7U+J6SkhLk5eXJHury5ptvwsXFBceOHZNi6enpOHXqFO7fv6+27RIRVSosLMSqVauk71QAWLt2LRISElhoEpHWe+FiU6VSYdasWfD19YWXl1eN7TIyMmBnZyeL2dnZISMjo8b3hISEwNzcXHo4OTm9aJrPJISAgYEB9PT0ZPvw73//G/7+/njrrbdk7UNDQxEeHo7i4mK15ENETdOwYcOwaNEirFixQoq1aNECLVq00GBWRER144WLzWnTpuHatWv44Ycf6jIfAMDChQuRm5srPdLS0up8GwCgUCgQGRmJwsLCKgVtmzZt0LFjR+m5SqXC2LFj4evri9u3b0vxyMhIbN++/bkGShERVWf27NlwdXWFj4+PplMhIqpzL1RsBgcHIywsDKdPn4ajo+Mz27Zo0QKZmZmyWGZm5jN/sSuVSpiZmcke6mRgYCC7X3PSpElISkrCp59+KsVyc3PRt29ftG7dGm3atJHie/bswbhx4/DFF19IMSEEVqxYgb1797IXlIhk7t69izfffBP79++XYoMGDUJcXBxGjBihwcyIiNSjVsWmEALBwcE4cOAATp06hVatWv3pe3x8fHDy5ElZ7MSJE1rxC/7pAtTS0hLHjx9HcnIy9PT+Mxd+q1at4Ofnhx49ekix9PR0fPjhhwgKCpJ93v79+xESEoKoqCi1505EDdPmzZvx/fff44MPPkBFRQWAJ981SqVSw5kREalHrVYQmjZtGnbu3IlDhw7B1NRUuu/S3NwczZo1AwC89dZbcHBwQEhICABg5syZ8PPzw9q1azFkyBD88MMPuHTpEjZt2lTHu6IZ7733Ht577z1ZrKKiAhMnTkR+fr5sjeKdO3ciNDQUhoaG6NSpEwAgOzsb8+bNQ8eOHTFz5kyOiCdqZIQQKCgogKmpKQBg3rx5uH79OhYsWABdXV0NZ0dEpH61mvqopkJo69atGD9+PACgX79+cHV1xbZt26TX9+7di8WLFyMlJQXu7u749NNPMXjw4OdOsrFMnfDNN9/g9OnTCA4ORs+ePQEAZ8+ehZ+fH1xdXXHr1i2p7cqVK5Geno6JEyeiS5cumkqZiF7C9evX8e6778LW1hahoaGaToeo3jWW8ze9nJeaZ7O+NOZ/rElJSfj++++hVCqxcOFCKd6pUydER0fj8OHDGDp0KIAnc4LOnz8fffr0weLFizWVMhE9p+vXr+OVV16BUqlEXFyc2mbWIGqoGvP5m55frS6jU91zc3PDkiVLqsQXLlyIK1euoGvXrlIsMjISP/30E1QqlazYHDlyJEpLS7Fy5cpnTkNFROpVVFSEqKgo6Z70Dh06YOvWrejfvz8cHBw0nB0RkWawZ1OL3Lx5E6dOnYK1tTWGDx8O4MmUTGZmZigsLERsbCw8PT0BPBklv3TpUowcOVJWzAoheF8okRrcvn0bfn5+yM7ORkJCAufIJALP3/QEeza1SOvWrdG6dWtZTAiBsLAwxMTEwM3NTYpfuXIFsbGxsmmnhBBwdnaGra0tDhw4AGdnZwBAaWkp9PX1WYQSvQQnJyfY2tqivLwct27dYrFJRPT/2LPZSGVmZuLKlSuws7ND586dATxZzcne3h46OjooKCiQZhBYtmwZ1q1bh/fff192ef7hw4ewtrbWSP5EDV1GRga+/vprfPTRR9Ko8lu3bsHW1hbGxsYazo6oYeD5mwD2bDZadnZ2GDhwoCxmY2ODhIQE3Lx5Uyo0gSeDGHJzc2WxR48eoXnz5rCzs8OtW7ek1zIyMmBkZMQvDWrSysvL0aNHD6SmpsLJyQnvvPMOADzX3MNERE3NCy9XSdpHV1cX7u7uCAgIkMW/++47XL16VTYJfWJiIoAnqzk9XYR+8MEHMDc3x+effy7FSkpKcOXKFa6WRE2Gnp4eZs+ejW7dusmWtSUioqpYbBIMDAzQsWNHtGzZUop1794d+fn5OHHihKxt5T2gT/fgxMTEoEuXLlXuJ718+TLi4uJQXl6uxuyJ1C86OhqvvvqqbPWv4OBgREREyFYPIyKiqlhsUo1MTEzQtm1bWezHH3/Ew4cP8dprr0mx+/fvw9LSUhoJXyk4OBienp7Yt2+fFMvMzERYWBhSU1PVmzxRHfrkk09w8uRJLFiwQIrp6elBR4dfoUREf4b3bFKtWVlZyZ4PHjwYDx8+RGFhoSxubGwMY2Nj2WXG06dPIygoCL169cKvv/4qxfft2wcLCwv07NkTJiYm6t0Boj9RWlqK8vJyGBkZAQBWr14NHR0drFy5UsOZERFpH/4spzqhUCiqFIknTpxAXl6erMdTR0cH3t7eVZbgnDp1Kl577TXEx8dLsejoaGzYsEF26ZJI3U6ePIkOHTpg2bJlUszZ2Rnff/89XFxcNJgZEZF2YrFJaqWjoyO71Dhq1ChER0dj/fr1Uqy4uBi9e/dG27ZtZYXpkSNHMGXKFHz22Weyz1y2bBm2bduGgoIC9e8ANTlFRUVISkrCDz/8gJKSEk2nQ0Sk9TjPJjVYO3fuxI4dOzBs2DBMmjQJAJCbmwsLCwsAT6ZnqvzvQ4cO4dKlSxg0aBB69eqloYxJGz148ACpqalSb7sQAt988w0CAwNhamqq4eyItBvP3wTwnk1qwEaPHo3Ro0fLYiUlJZg+fTru3bsnFZoAcODAAXz77bfQ19eXis2ioiJMmDABXl5emD9/PvT19eszfdIC4eHhGDJkCKytrXH9+nUolUooFApp3kwiInp5LDZJq9ja2uKLL76oEh88eDAMDAzQt29fKXbjxg3s3r0bP//8MxYtWiTFP/30U9y4cQNvv/02+vTpUy95U8Pk7e2NZs2awdTUFPfu3YOrq6umUyIianRYbFKjMGrUKIwaNUoWs7W1xSeffIKysjLZuu9HjhzB+fPnZdM3JSQkYOLEiejRowfWrFlTb3lT/YqNjcWhQ4ewcOFCAE+m9zp79ixatWolLTlJRER1i8UmNVqOjo744IMPqsQXLlyIS5cuwcfHR4pFR0fj/PnzKCsrk7UdPXo0srKysGLFCk7ereUyMzPRpUsXlJSUoFevXvDz8wMAuLm5aTgzIqLGjcUmNTmDBw/G4MGDZTFfX1/s2LEDSqVSFj99+jQyMjJk8yuGhYVh+vTp+Pvf/y5btrOiooK9Yw2YnZ0dJkyYgMzMTDg5OWk6HSKiJoPFJhGAli1bVhmMJITAoUOHEBMTgw4dOkjxq1evIiUlBQ8ePJC19/DwgJ6eHkJDQ6UpnIqKiqCvrw89PR5q9e348eNYunQpDh48CDs7OwDA+vXr+f+CiKiecZ5NohooFAp0794dEydOhLGxsRSfOnUqzpw5gzlz5kix/Px8JCUlIS4uDra2tlJ8w4YNMDExwfvvvy/77PT0dGjBrGNaS6VSYfHixYiIiEBISIgUZ6FJRFT/+M1LVEsWFhayUe/Ak4Emd+7cQVxcHKytraX4jRs3UFJSIltdqbi4GM7OzjAyMsLNmzfRvHlzAE8KUD09PVmxSs8vJycHpqam0NXVhY6ODj7//HMcPHgQixcv1nRqRERNGns2ieqAQqGAg4MD/P39ZfENGzYgKSkJkydPlmIpKSnQ0dGBnp6erDBduXIl7OzssGTJEilWXl6O8PBw5Obmqn0ftNnWrVvRpk0bfPvtt1Ksd+/eWLNmjWw+ViIiqn8sNonUSEdHB23atEHLli2lmIeHBwoKChAZGSmbkunRo0dQKBSy0dHJycnw9fWFg4MDVCqVFL906RIuX76MoqKi+tmRBi47OxvZ2dnYuXOnplMhIqI/YLFJpAEGBgZo1aqVLLZz504UFBRgxIgRUiwrKwuOjo5o3769bI35RYsWoWvXrtixY4cUe/jwIfbs2YMbN26ofwc0LDExEQkJCdLz6dOnY8uWLTh+/LgGsyIiouqw2CRqQIyMjGBkZCQ97927N9LS0nDu3DlZOwsLC1hbW8PLy0uKRUREIDAwsMrk9nv37sXhw4fx6NEj9SZfT3bs2IEOHTpgypQp0iArAwMDTJgwgQOAiIgaIH4zE2mBP87/uXv37iqj2XV0dNCzZ0907NhRFl+wYAFu3ryJU6dO4a9//SsA4Pr16/jxxx/Ro0cP+Pr6qjf5Oubr6wsdHR0YGhqisLBQNviKiIgaHhabRFrq6fs9AWDQoEEYNGiQLKZSqdC7d2+YmZnJekF//vlnzJ07F8OHD5cVm0uXLoWNjQ3eeOMNWFlZqXcHntOpU6eQkJCA9957DwDg6uqKa9euceUfIiItoRBaMNlfXl4ezM3NkZubCzMzM02nQ6T1jhw5gu3bt8PPzw/BwcEAIE3RVF5ejrS0NDg6OgIAjh49ip9//hkDBw7EgAED6jXPiIgI+Pj4QKlU4saNG1XucyWiho3nbwLYs0nUJA0dOhRDhw6VxUpKSjB37lwkJyfDwcFBih87dgxffvkl9PT0pGKzoqICI0eOhIeHBxYtWiSb9P5lCSGkXtsePXogICAA7u7uMDc3r7NtEBFR/WHPJhE909GjR/HTTz9hyJAheO211wA8GQ3etm1bGBoaoqCgQFoT/rPPPkNERAQmTJiAgQMH1mo7FRUV2Lp1K7799lucPHkSBgYGUpxrzhNpJ56/CWDPJhH9icGDB2Pw4MGymIWFBdavX4/c3FxZIfjTTz/h+PHj6N+/vxS7c+cOXn/9dXTu3Bn/+te/qtxrWunx48f48MMPkZGRga1bt+Ldd98FABaaRERajsUmEdWajY2NdK/n0xYsWAB/f3/069dPisXExODKlSsoKSmRFZrjx49HYmIili1bBn9/f5iammLdunXIyMjAhAkT6mM3iIioHrDYJKI64+fnBz8/P1mse/fuOHDgACoqKmTx8PBwJCYmymJBQUFqz5GIiOoXi00iUitra2sMGzasSjw0NBTXrl1D165d6z8pIiKqNyw2iUgjvLy8ZHN/EhFR48TlKomIiIhIbVhsEhEREZHasNgkIiIiIrVhsUlEREREasNik4iIiIjUhsUmEREREakNi00iIiIiUhsWm0RERESkNiw2iYiIiEhtWGwSERERkdqw2CQiIiIitWGxSURERERqw2KTiIiIiNRGT9MJPA8hBAAgLy9Pw5kQERHR86o8b1eex6lp0opiMz8/HwDg5OSk4UyIiIiotvLz82Fubq7pNEhDFEILfm6oVCqkp6fD1NQUCoWizj43Ly8PTk5OSEtLg5mZWZ19bkPS2PeR+6f9Gvs+cv+0X2PfR3XunxAC+fn5aNmyJXR0eOdeU6UVPZs6OjpwdHRU2+ebmZk1yi+QpzX2feT+ab/Gvo/cP+3X2PdRXfvHHk3izwwiIiIiUhsWm0RERESkNk262FQqlfj444+hVCo1nYraNPZ95P5pv8a+j9w/7dfY97Gx7x9pnlYMECIiIiIi7dSkezaJiIiISL1YbBIRERGR2rDYJCIiIiK1YbFJRERERGqjdcXmkiVL0KlTJ02n8Vx++eUXKBQK5OTkaDoVojrF45BIs7Zt2wYLCwtNp/FcUlJSoFAoEBUVpelUSEMaRLG5evVqKBQKzJo1SxZXKBQ4ePBgnWxDCIHNmzfDx8cHZmZmMDExQYcOHTBz5kwkJSXVyTaItM2SJUugUChkDw8PD1kbHodE6nX37l2MHTsW1tbWaNasGTp27IhLly5Jr7u6uuLzzz+vs+3t378f/fv3h6WlJZo1a4Z27drh7bffxpUrV+psG0RP03ixefHiRWzcuBHe3t5q24YQAqNHj8aMGTMwePBg/PTTT4iNjcU333wDQ0NDrFixosb3lpaWqi0vooagQ4cOuHfvnvQ4f/68WrbD45CoqkePHsHX1xf6+vo4duwYYmNjsXbtWlhaWqple/Pnz0dgYCA6deqEw4cPIz4+Hjt37kTr1q2xcOHCGt/HY5BeitCg/Px84e7uLk6cOCH8/PzEzJkzpddcXFwEAOnh4uIihBDi448/Fq+88orYvn27cHFxEWZmZiIwMFDk5eXVuJ1du3YJAOLQoUPVvq5SqaT/HjdunPj73/8uVqxYIezt7YWrq6sQQojt27eLrl27ChMTE2FnZyeCgoJEZmam7HP+/e9/C3d3d2FoaCj69esntm7dKgCIR48eSW3OnTsnevfuLQwNDYWjo6OYPn26KCgoqOVfjqhuVB5PNeFxSKRe8+fPF717967xdT8/P9kxWHna3rp1qzA3NxfHjx8XHh4ewtjYWAQEBIj09PQaP+vChQsCgPjnP/9Z7etPH4OVx/jmzZuFq6urUCgUQgghjh07Jnx9fYW5ubmwsrISQ4YMEUlJSbLP+e2330SnTp2EUqkUXbt2FaGhoQKAuHLlitQmJiZGDBw4UBgbGwtbW1sxduxYkZWV9ad/L9JOGu3ZnDZtGoYMGYJXX321ymsXL14EAGzduhX37t2TngNAcnIyDh48iLCwMISFheHMmTNYvXp1jdvZtWsX2rVrh9dff73a1xUKhez5yZMnER8fjxMnTiAsLAwAUFZWhuXLlyM6OhoHDx5ESkoKxo8fL70nLS0NI0aMwNChQxEVFYV33nkHCxYskH1ucnIyBg4ciP/6r//C1atXsXv3bpw/fx7BwcHP/kMRqVFiYiJatmyJ1q1bY8yYMUhNTZVe43FIpF6HDx/GX/7yF4wcORK2trbo3LkzNm/eLL0eGhoKR0dHLFu2TLr6UOnx48dYs2YNvvvuO5w9exapqal4//33a9zWrl27YGJigqlTp1b7+h+PwaSkJOzfvx+hoaHS/ZaFhYWYM2cOLl26hJMnT0JHRwfDhw+HSqUCABQUFOBvf/sb2rdvj8jISCxZsqRKTjk5Oejfvz86d+6MS5cu4fjx48jMzMSoUaNq9bcjLaKpKnfXrl3Cy8tLFBUVCSFElZ5NIYQAIA4cOCCLffzxx8LIyEjWgzJv3jzRo0ePGrfl4eEhXn/9dVls5syZwtjYWBgbGwsHBwcpPm7cOGFnZydKSkqemf/FixcFAJGfny+EEGLhwoWiffv2sjbz58+X9ahMnDhRTJ48Wdbm3LlzQkdHR/o7ENWno0ePij179ojo6Ghx/Phx4ePjI5ydnWXHF49DIvVRKpVCqVSKhQsXisuXL4uNGzcKQ0NDsW3bNqmNi4uL+Oyzz2Tvq+yxf7pX8auvvhJ2dnY1bmvgwIHC29tbFlu7dq10DBobG4ucnBwhxJNjXF9fX9y/f/+Z+WdlZQkAIiYmRgghxMaNG4W1tbXsWPr6669lPZvLly8XAwYMkH1OWlqaACDi4+OfuT3SThrp2UxLS8PMmTOxY8cOGBoa1vr9rq6uMDU1lZ7b29vj/v37tfqMRYsWISoqCh999BEKCgpkr3Xs2BEGBgayWGRkJIYOHQpnZ2eYmprCz88PAKReoBs3bqBHjx6y9/j4+MieR0dHY9u2bTAxMZEeAQEBUKlUuHXrVq3yJ6oLgwYNwsiRI+Ht7Y2AgAAcPXoUOTk52LNnz5++l8ch0ctTqVTo0qULVq1ahc6dO2Py5MmYNGkSNmzY8KfvNTIyQps2baTnL3IMvv3224iKisLGjRtRWFgI8dQK1i4uLrCxsZG1T0xMRFBQEFq3bg0zMzO4uroCkB+D3t7esnN7dcfg6dOnZcdg5cDE5OTkWuVP2kFPExuNjIzE/fv30aVLFylWUVGBs2fP4ssvv0RJSQl0dXVrfL++vr7suUKhkLrwq+Pu7o74+HhZzMbGBjY2NrC1ta3S3tjYWPa8sLAQAQEBCAgIwI4dO2BjY4PU1FQEBATU6qbpgoICvPvuu5gxY0aV15ydnZ/7c4jUxcLCAm3btn2ukeE8Dolenr29Pdq3by+LeXp6Yv/+/X/63uqOwaeLxT9yd3fH+fPnUVZWJr3XwsICFhYWuHPnTpX2fzwGAWDo0KFwcXHB5s2b0bJlS6hUKnh5edX6GBw6dCg++eSTKq/Z29s/9+eQ9tBIz6a/vz9iYmIQFRUlPf7yl79gzJgxiIqKkgpNfX19VFRUvPT2goKCEB8fj0OHDr3Q++Pi4vDw4UOsXr0affr0gYeHR5Vfj56envj9999lsYiICNnzLl26IDY2Fm5ublUef+zBIdKEgoICJCcny77weRwSqY+vr2+VH2EJCQlwcXGRnhsYGNTZMVhQUID//d//faH3P3z4EPHx8Vi8eDH8/f3h6emJR48eydp4enri6tWrKC4ulmLVHYPXr1+Hq6trlWOwugKXtJ9Gik1TU1N4eXnJHsbGxrC2toaXl5fUztXVFSdPnkRGRkaVf9C18cYbb+C///u/8cYbb2DZsmX47bffkJKSgjNnzmD37t3P7EUFnvR2GBgYYP369bh58yYOHz6M5cuXy9q89957SExMxLx586SpJLZt2yZrM3/+fISHhyM4OBhRUVFITEzEoUOHODCBNOb999/HmTNnkJKSgvDwcAwfPhy6uroICgqS2vA4JFKf2bNnIyIiAqtWrUJSUhJ27tyJTZs2Ydq0aVIbV1dXnD17Fnfv3sWDBw9eeFs+Pj6YO3cu5s6dizlz5uD8+fO4ffs2IiIi8M0330ChUEBHp+aywNLSEtbW1ti0aROSkpJw6tQpzJkzR9Zm9OjRUCgUmDRpEmJjY3H06FGsWbNG1mbatGnIzs5GUFAQLl68iOTkZPz444+YMGFCnRTV1ABp+qbRStUNEDp8+LBwc3MTenp6VaZcedpnn30mvV6TiooKsWHDBtGjRw9hbGwsDAwMROvWrcWkSZNEbGys1K5yypU/2rlzp3B1dRVKpVL4+PiIw4cPV5nK4ciRI8LNzU0olUrRp08fsWXLlipTrvz+++/itddeEyYmJsLY2Fh4e3uLlStXPsdfiKjuBQYGCnt7e2FgYCAcHBxEYGBglWlMeBwSqdeRI0eEl5eXUCqVwsPDQ2zatEn2+oULF4S3t7dQKpVVpj562oEDB8TznNZ3794t+vXrJ8zNzYW+vr5wdHQUo0ePFhEREVKbmqZFO3HihPD09BRKpVJ4e3uLX375pcogwgsXLohXXnlFGBgYiE6dOon9+/dXOU4TEhLE8OHDhYWFhWjWrJnw8PAQs2bNkk2/RI2HQohn3OBBRERERPQSNL6CEBERERE1Xiw2iYiIiEhtWGwSERERkdqw2CQiIiIitWGxSURERERqw2KTiIiIiNSGxSYRERERqQ2LTSIiIiJSGxabRERERKQ2LDaJiIiISG1YbBIRERGR2vwfy7q7go3maDYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(students\n",
    "     .set_index('Last Name')\n",
    "     .drop('First Name', axis=1)\n",
    "     .apply(num_score)\n",
    "     .T\n",
    "     .plot(title=\"Student score by year\")\n",
    "     .legend(bbox_to_anchor=(1, .75))\n",
    ")\n",
    "plt.savefig(\"img/(Ch01)Student score by year\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data layout exposes its limitations once the class advances to 7th grade, or if we were to obtain 3rd grade information.  To accommodate such additional data, we would need to change the number and position of columns, not simply add additional rows.  It is natural to make new observations or identify new samples (rows), but usually awkward to change the underlying variables (columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The particular class level (e.g. 4th grade) that a letter grade pertains to is, at heart, a value not a variable.  Another way to think of this is in terms of independent variables versus dependent variables.  Or in machine learning terms, features versus target.  In some way, the class level might correlate with or influence the resulting letter grade; perhaps the teachers at the different levels have different biases, or children of a certain age lose or gain interest in schoolwork, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most analytic purposes, this data would be more useful if we make it tidy (normalized) before further processing.  In Pandas, the `DataFrame.melt()` method can perform this tidying.  We pin some of the columns as `id_vars`, and we set a name for the combined columns as a variable and the letter grade as a single new column.  This Pandas method is slightly magical, and takes some practice to get used to.  The key thing is that it preserves data, simply moving it between column labels and data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Level</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mia</th>\n",
       "      <th>Johnson</th>\n",
       "      <th>4th Grade</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liam</th>\n",
       "      <th>Lopez</th>\n",
       "      <th>4th Grade</th>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Isabella</th>\n",
       "      <th>Lee</th>\n",
       "      <th>4th Grade</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mason</th>\n",
       "      <th>Fisher</th>\n",
       "      <th>4th Grade</th>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Isabella</th>\n",
       "      <th>Lee</th>\n",
       "      <th>6th Grade</th>\n",
       "      <td>B-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mason</th>\n",
       "      <th>Fisher</th>\n",
       "      <th>6th Grade</th>\n",
       "      <td>C+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Olivia</th>\n",
       "      <th>Gupta</th>\n",
       "      <th>6th Grade</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sophia</th>\n",
       "      <th>Robinson</th>\n",
       "      <th>6th Grade</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Score\n",
       "First Name Last Name Level          \n",
       "Mia        Johnson   4th Grade     A\n",
       "Liam       Lopez     4th Grade     B\n",
       "Isabella   Lee       4th Grade     C\n",
       "Mason      Fisher    4th Grade     B\n",
       "...                              ...\n",
       "Isabella   Lee       6th Grade    B-\n",
       "Mason      Fisher    6th Grade    C+\n",
       "Olivia     Gupta     6th Grade     A\n",
       "Sophia     Robinson  6th Grade     A\n",
       "\n",
       "[18 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students.melt(\n",
    "    id_vars=[\"Last Name\", \"First Name\"], \n",
    "    var_name=\"Level\",\n",
    "    value_name=\"Score\"\n",
    ").set_index(['First Name', 'Last Name', 'Level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the R Tidyverse, the procedure is similar.  Do not worry about the extra Jupyter magic `%%capture`, this simply quiets extra informational messages sent to STDERR that would distract from the printed book.  A **tibble** that we see here is simply a kind of data frame that is preferred in the Tidyverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in library(\"tidyverse\") : there is no package called ‘tidyverse’\n"
     ]
    },
    {
     "ename": "RInterpreterError",
     "evalue": "Failed to parse and evaluate line \"library('tidyverse')\\n\\nstudentsR <- read_csv('data/students-scores.csv')\\nstudentsR\\n\".\nR error message: 'Error in library(\"tidyverse\") : there is no package called ‘tidyverse’'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:385\u001b[0m, in \u001b[0;36mRMagics.eval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# Need the newline in case the last line in code is a comment.\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     value, visible \u001b[38;5;241m=\u001b[39m \u001b[43mro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwithVisible(\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m})\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ri\u001b[38;5;241m.\u001b[39membedded\u001b[38;5;241m.\u001b[39mRRuntimeError, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m# Otherwise next return seems to have copy of error.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/robjects/__init__.py:459\u001b[0m, in \u001b[0;36mR.__call__\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    458\u001b[0m p \u001b[38;5;241m=\u001b[39m rinterface\u001b[38;5;241m.\u001b[39mparse(string)\n\u001b[0;32m--> 459\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mget_conversion()\u001b[38;5;241m.\u001b[39mrpy2py(res)\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/robjects/functions.py:208\u001b[0m, in \u001b[0;36mSignatureTranslatedFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         kwargs[r_k] \u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSignatureTranslatedFunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/robjects/functions.py:131\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         new_kwargs[k] \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mpy2rpy(v)\n\u001b[0;32m--> 131\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m res \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mrpy2py(res)\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/rinterface_lib/conversion.py:45\u001b[0m, in \u001b[0;36m_cdata_res_to_rinterface.<locals>._\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 45\u001b[0m     cdata \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# TODO: test cdata is of the expected CType\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/rinterface.py:817\u001b[0m, in \u001b[0;36mSexpClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error_occured[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 817\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m embedded\u001b[38;5;241m.\u001b[39mRRuntimeError(_rinterface\u001b[38;5;241m.\u001b[39m_geterrmessage())\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[0;31mRRuntimeError\u001b[0m: Error in library(\"tidyverse\") : there is no package called ‘tidyverse’\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRInterpreterError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibrary(\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtidyverse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mstudentsR <- read_csv(\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/students-scores.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mstudentsR\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:943\u001b[0m, in \u001b[0;36mRMagics.R\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m e\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mendswith(e\u001b[38;5;241m.\u001b[39merr):\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;28mprint\u001b[39m(e\u001b[38;5;241m.\u001b[39merr)\n\u001b[0;32m--> 943\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01min\u001b[39;00m DEVICES_STATIC:\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:923\u001b[0m, in \u001b[0;36mRMagics.R\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    921\u001b[0m         return_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 923\u001b[0m     text_result, result, visible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    924\u001b[0m     text_output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m text_result\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m visible:\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:389\u001b[0m, in \u001b[0;36mRMagics.eval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ri\u001b[38;5;241m.\u001b[39membedded\u001b[38;5;241m.\u001b[39mRRuntimeError, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m# Otherwise next return seems to have copy of error.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     warning_or_other_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RInterpreterError(code, \u001b[38;5;28mstr\u001b[39m(exception),\n\u001b[1;32m    390\u001b[0m                             warning_or_other_msg)\n\u001b[1;32m    391\u001b[0m text_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text_output, value, visible[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mRInterpreterError\u001b[0m: Failed to parse and evaluate line \"library('tidyverse')\\n\\nstudentsR <- read_csv('data/students-scores.csv')\\nstudentsR\\n\".\nR error message: 'Error in library(\"tidyverse\") : there is no package called ‘tidyverse’'"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout err\n",
    "%%R\n",
    "library('tidyverse')\n",
    "\n",
    "studentsR <- read_csv('data/students-scores.csv')\n",
    "studentsR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the Tidyverse, specifically within the **tidyr** package, there is a function `pivot_longer()` that is similar to Pandas' `.melt()`.  The aggregation names and values have parameters spelled `names_to` and `values_to`, but the operation is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in read_csv(\"data/students-scores.csv\") : \n",
      "  could not find function \"read_csv\"\n"
     ]
    },
    {
     "ename": "RInterpreterError",
     "evalue": "Failed to parse and evaluate line 'studentsR <- read_csv(\\'data/students-scores.csv\\')\\nstudentsR %>% \\n  pivot_longer(c(`4th Grade`, `5th Grade`, `6th Grade`), \\n               names_to = \"Level\", \\n               values_to = \"Score\")\\n'.\nR error message: 'Error in read_csv(\"data/students-scores.csv\") : \\n  could not find function \"read_csv\"'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:385\u001b[0m, in \u001b[0;36mRMagics.eval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# Need the newline in case the last line in code is a comment.\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     value, visible \u001b[38;5;241m=\u001b[39m \u001b[43mro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwithVisible(\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m})\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ri\u001b[38;5;241m.\u001b[39membedded\u001b[38;5;241m.\u001b[39mRRuntimeError, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m# Otherwise next return seems to have copy of error.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/robjects/__init__.py:459\u001b[0m, in \u001b[0;36mR.__call__\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    458\u001b[0m p \u001b[38;5;241m=\u001b[39m rinterface\u001b[38;5;241m.\u001b[39mparse(string)\n\u001b[0;32m--> 459\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mget_conversion()\u001b[38;5;241m.\u001b[39mrpy2py(res)\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/robjects/functions.py:208\u001b[0m, in \u001b[0;36mSignatureTranslatedFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         kwargs[r_k] \u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSignatureTranslatedFunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/robjects/functions.py:131\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         new_kwargs[k] \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mpy2rpy(v)\n\u001b[0;32m--> 131\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m res \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mrpy2py(res)\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/rinterface_lib/conversion.py:45\u001b[0m, in \u001b[0;36m_cdata_res_to_rinterface.<locals>._\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 45\u001b[0m     cdata \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# TODO: test cdata is of the expected CType\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/rinterface.py:817\u001b[0m, in \u001b[0;36mSexpClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error_occured[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 817\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m embedded\u001b[38;5;241m.\u001b[39mRRuntimeError(_rinterface\u001b[38;5;241m.\u001b[39m_geterrmessage())\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[0;31mRRuntimeError\u001b[0m: Error in read_csv(\"data/students-scores.csv\") : \n  could not find function \"read_csv\"\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRInterpreterError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstudentsR <- read_csv(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mdata/students-scores.csv\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mstudentsR \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m  pivot_longer(c(`4th Grade`, `5th Grade`, `6th Grade`), \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m               names_to = \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLevel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m               values_to = \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mScore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:943\u001b[0m, in \u001b[0;36mRMagics.R\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m e\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mendswith(e\u001b[38;5;241m.\u001b[39merr):\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;28mprint\u001b[39m(e\u001b[38;5;241m.\u001b[39merr)\n\u001b[0;32m--> 943\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01min\u001b[39;00m DEVICES_STATIC:\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:923\u001b[0m, in \u001b[0;36mRMagics.R\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    921\u001b[0m         return_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 923\u001b[0m     text_result, result, visible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    924\u001b[0m     text_output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m text_result\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m visible:\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:389\u001b[0m, in \u001b[0;36mRMagics.eval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ri\u001b[38;5;241m.\u001b[39membedded\u001b[38;5;241m.\u001b[39mRRuntimeError, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m# Otherwise next return seems to have copy of error.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     warning_or_other_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RInterpreterError(code, \u001b[38;5;28mstr\u001b[39m(exception),\n\u001b[1;32m    390\u001b[0m                             warning_or_other_msg)\n\u001b[1;32m    391\u001b[0m text_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text_output, value, visible[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mRInterpreterError\u001b[0m: Failed to parse and evaluate line 'studentsR <- read_csv(\\'data/students-scores.csv\\')\\nstudentsR %>% \\n  pivot_longer(c(`4th Grade`, `5th Grade`, `6th Grade`), \\n               names_to = \"Level\", \\n               values_to = \"Score\")\\n'.\nR error message: 'Error in read_csv(\"data/students-scores.csv\") : \\n  could not find function \"read_csv\"'"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout err\n",
    "%%R\n",
    "studentsR <- read_csv('data/students-scores.csv')\n",
    "studentsR %>% \n",
    "  pivot_longer(c(`4th Grade`, `5th Grade`, `6th Grade`), \n",
    "               names_to = \"Level\", \n",
    "               values_to = \"Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple example above gives you a first feel for tidying tabular data.  To reverse the tidying operation that moves variables (columns) to values (rows), the `pivot_wider()` function in tidyr can be used.  In Pandas there are several related methods on DataFrames, including `.pivot()`, `.pivot_table()`, and `.groupby()` combined with `.unstack()`, which can create columns from rows (and do many other things too)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having looked at the idea of tidyness as a general goal for tabular, let us being looking at specific data formats, beginning with comma-separated values and fixed-width files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Speech sounds cannot be understood, delimited, classified and explained\n",
    "> except in the light of the tasks which they perform in language.<br/>\n",
    "> –Roman Jakobson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concepts**:\n",
    "\n",
    "* Delimited and fixed-width data\n",
    "* Parsing problems\n",
    "* Heuristics and \"eyeballing\"\n",
    "* Inferring data types\n",
    "* Escaping special characters\n",
    "* Families of related CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delimited text files, especially comma-separated values (CSV) files, are ubiquitous.  These are text files that put multiple values on each line, and separate those values with some semi-reserved character, such as a comma.  They are almost always the exchange format used to transport data between other tabular representations, but a great deal of data both starts and ends life as CSV, perhaps never passing through other formats.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading delimited files is not the fastest way of reading data from disk into RAM memory, but it is also not the slowest.  Of course, that concern only matters for large-ish data sets, not for the small data sets that make up most of our work as data scientists (small nowadays means roughly \"fewer then 100k rows\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a great number of deficits in CSV files, but also some notable strengths.  CSV files are the format second most susceptible to structural problems.  All formats are generally equally prone to content problems, which are not tied to the format itself.  Spreadsheets like Excel are, of course, *by a very large margin* the worst format for every kind of data integrity concern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the same time, delimited formats—or fixed-width text formats—are also almost the only ones you can easily open and make sense of in a text editor or easily manipulate using command-line tools for text processing.  Thereby delimited files are pretty much the only ones you can fix fully manually without specialized readers and libraries.  Of course, formats that rigorously enforce structural constraints *do avoid some* of the need to do this.  Later in this chapter, and in the next two chapters, a number of formats that enforce structure more are discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One issue that you could encounter in reading CSV or other textual files is the actual character set encoding may not be the one you expect, or that is the default on your current system.  In this age of Unicode, this concern is diminishing, but only slowly, and archival files continue to exist.  This topic is discussed in chapter 3 (*Data Ingestion – Repurposing Data Sources*) in the section *Custom Text Formats*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick example, suppose you have just received a medium sized CSV file, and you want to make a quick sanity check on it. At this stage, we are concerned about whether the file is formatted correctly at all.  We can do this with command-line tools, even if most libraries are likely to choke on them (such as shown in the next code cell).  Of course, we could also use Python, R, or another general-purpose language if we just consider the lines as text initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParserError\n",
      "Error tokenizing data. C error: Expected 6 fields in line 75, saw 8\n"
     ]
    }
   ],
   "source": [
    "# Use try/except to avoid full traceback in example\n",
    "try:\n",
    "    pd.read_csv('data/big-random.csv')\n",
    "except Exception as err:\n",
    "    print_err(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What went wrong there? Let us check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100000  100000 4335846 data/big-random.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# What is the general size/shape of this file?\n",
    "wc data/big-random.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! 100,000 rows; but there is some sort of problem on line 75 according to Pandas (and perhaps on other lines as well).  Using a single piped bash command which counts commas per line might provide insight.  We could absolutely perform this same analysis in Python, R, or other languages; however, being familiar with command-line tools is a benefit to data scientists in performing one-off analyses like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     46 3\n",
      "  99909 5\n",
      "     45 7\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat data/big-random.csv | \n",
    "    tr -d -c ',\\n' | \n",
    "    awk '{ print length; }' | \n",
    "    sort | \n",
    "    uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have figured out already that 99,909 of the lines have the expected 5 commas.  But 46 have a deficit and 45 a surplus.  Perhaps we will simply discard the bad lines, but that is not altogether too many to consider fixing by hand, even in a text editor.  We need to make a judgement, on a per problem basis, about both the relative effort and reliability of automation of fixes versus manual approaches.  Let us take a look at a few of the problem rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74-squarcerai,45,quiescenze,12,scuoieremo,70\n",
      "75:fantasmagorici,28,immischiavate,44,schiavizzammo,97,sfilzarono,49\n",
      "76-interagiste,50,repentagli,72,attendato,95\n",
      "--\n",
      "712-resettando,58,strisciato,46,insaldai,62\n",
      "713:aspirasse,15,imbozzimatrici,70,incanalante,93,succhieremo,41\n",
      "714-saccarometriche,18,stremaste,12,hindi,19\n",
      "--\n",
      "8096-squincio,16,biascicona,93,solisti,70\n",
      "8097:rinegoziante,50,circoncidiamo,83,stringavate,79,stipularono,34\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "grep -C1 -nP '^([^,]+,){7}' data/big-random.csv | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these lists of Italian words and integers of slightly varying number of fields does not immediately illuminate the nature of the problem.  We likely need more domain or problem knowledge.  However, given that fewer than 1% of rows are a problem, perhaps we should simply discard them for now.  If you do decide to make a modification such as removing rows, then versioning the data, with accompanying documentation of change history and reasons, becomes crucial to good data and process provenance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell uses a regular expression to filter the lines in the \"almost CSV\" file.  The pattern may appear confusing, but regular expressions provide a compact way of describing patterns in text.  The match in `pat` indicates that from beginning of a line (`^`) until the end of that line (`$`) there are exactly five repetitions of character sequences that do not include commas, each followed by one comma (`[^,]+,`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>infilaste</td>\n",
       "      <td>21</td>\n",
       "      <td>esemplava</td>\n",
       "      <td>15</td>\n",
       "      <td>stabaccavo</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abbadaste</td>\n",
       "      <td>50</td>\n",
       "      <td>enartrosi</td>\n",
       "      <td>85</td>\n",
       "      <td>iella</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frustulo</td>\n",
       "      <td>77</td>\n",
       "      <td>temporale</td>\n",
       "      <td>83</td>\n",
       "      <td>scoppianti</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gavocciolo</td>\n",
       "      <td>84</td>\n",
       "      <td>postelegrafiche</td>\n",
       "      <td>93</td>\n",
       "      <td>inglesizzanti</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99905</th>\n",
       "      <td>notareschi</td>\n",
       "      <td>60</td>\n",
       "      <td>paganico</td>\n",
       "      <td>64</td>\n",
       "      <td>esecutavamo</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99906</th>\n",
       "      <td>rispranghiamo</td>\n",
       "      <td>11</td>\n",
       "      <td>schioccano</td>\n",
       "      <td>44</td>\n",
       "      <td>imbozzarono</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99907</th>\n",
       "      <td>compone</td>\n",
       "      <td>85</td>\n",
       "      <td>disfronderebbe</td>\n",
       "      <td>19</td>\n",
       "      <td>vaporizzavo</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99908</th>\n",
       "      <td>ritardata</td>\n",
       "      <td>29</td>\n",
       "      <td>scordare</td>\n",
       "      <td>43</td>\n",
       "      <td>appuntirebbe</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99909 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0   1                2   3              4   5\n",
       "0          infilaste  21        esemplava  15     stabaccavo  73\n",
       "1          abbadaste  50        enartrosi  85          iella  54\n",
       "2           frustulo  77        temporale  83     scoppianti  91\n",
       "3         gavocciolo  84  postelegrafiche  93  inglesizzanti  63\n",
       "...              ...  ..              ...  ..            ...  ..\n",
       "99905     notareschi  60         paganico  64    esecutavamo  20\n",
       "99906  rispranghiamo  11       schioccano  44    imbozzarono  80\n",
       "99907        compone  85   disfronderebbe  19    vaporizzavo  54\n",
       "99908      ritardata  29         scordare  43   appuntirebbe  24\n",
       "\n",
       "[99909 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pat = re.compile(r'^([^,]+,){5}[^,]*$')\n",
    "with open('data/big-random.csv') as fh:\n",
    "    lines = [l.strip().split(',') \n",
    "             for l in fh if re.match(pat, l)]\n",
    "pd.DataFrame(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code we managed, within Python, to read all rows without formatting problems.  We could also have used the `pd.read_csv()` parameter `error_bad_lines=False` to achieve the same effect, but walking through it in plain Python and Bash gives you a better picture of why they are excluded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Good, The Bad, and The Textual Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us return to some virtues and deficits of CSV files.  Here when we mention CSV, we really mean any kind of delimited file.  And specifically, text files that store tabular data nearly always use a single character for a delimiter, and end rows/records with a newline (or carriage return and newline in legacy formats).  Other than commas, probably the most common delimiters you will encounter are tabs and the pipe character `|`.  However, nearly all tools are more than happy to use an arbitrary character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixed-width files are similar to delimited ones.  Technically they are different in that, although they are line oriented, they put each field of data in specific character positions within each line.  An example is used in the next code cell below.  Decades ago, when Fortran and Cobol were more popular, fixed-width formats were more prevalent; my perception is that their use has diminished in favor of delimited files.  In any case, fixed-width textual data files have most of the same pitfalls and strengths as do delimited ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Bad**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns in delimited or flat files do not carry a data type, being simply text values.  Many tools will (optionally) make guesses about the data type, but these are subject to pitfalls.  Moreover, even where the tools accurately guess the broad type category (i.e. string vs. integer vs. real number) they cannot guess the specific bit length desired, where that matters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, the representation used for \"real\" numbers is not encoded—most systems deal with IEEE-754 floating-point numbers of some length, but occasionally decimals of some specific length are more appropriate for a purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most typical way that type inference goes wrong is where the initial records in some data set have an apparent pattern, but later records deviate from this.  The software library may infer one data type but later encounter strings that cannot be cast as such.  \"Earlier\" and \"later\" here can have several different meanings.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For out-of-core data frame libraries like **Vaex** and **Dask** (Python libraries) that read *lazily*, type heuristics might be applied to a first few records (and perhaps some other sampling) but will not see those strings that do not follow the assumed pattern.  However, later might also mean months later, when new data arrives.<sup><i>partnum</i></sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"partnum\"\n",
    "     style=\"display: inline-block; margin: 0 5% 0 5%; border-style: solid; border-width: 1px\">\n",
    "    <i>partnum</i><br/>\n",
    "For example, in a former job of mine, we received client data about commercial products that had a \"part number.\"  That number was an actual integer, for many months, until it was not; it became a string that sometimes mixed letters with numerals. Unfortunately, other tooling had already made a wrong assumption about the undocumented data type (in this case an SQL schema, but it could be other code as well).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most data frame libraries are greedy about inferring data types—although all will allow manual specification to shortcut inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many layouts, data frame libraries can guess a fixed-width format and infer column positions and data types (where it cannot guess, we could manually specify).  But the guesses about data types can go wrong.  For example, viewing the raw text, we see a fixed-width layout in `parts.fwf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part_No  Description              Maker               Price (USD)\n",
      "12345    Wankle rotary engine     Acme Corporation    555.55\n",
      "67890    Sousaphone               Marching Inc.       333.33\n",
      "2468     Feather Duster           Sweeps Bros         22.22\n",
      "A9922    Area 51 metal fragment   No Such Agency      9999.99"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat data/parts.fwf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in a few rows of data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading this with Pandas correctly infers the intended column positions for the fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Part_No</th>\n",
       "      <th>Description</th>\n",
       "      <th>Maker</th>\n",
       "      <th>Price (USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12345</td>\n",
       "      <td>Wankle rotary engine</td>\n",
       "      <td>Acme Corporation</td>\n",
       "      <td>555.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67890</td>\n",
       "      <td>Sousaphone</td>\n",
       "      <td>Marching Inc.</td>\n",
       "      <td>333.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2468</td>\n",
       "      <td>Feather Duster</td>\n",
       "      <td>Sweeps Bros</td>\n",
       "      <td>22.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Part_No           Description             Maker  Price (USD)\n",
       "0    12345  Wankle rotary engine  Acme Corporation       555.55\n",
       "1    67890            Sousaphone     Marching Inc.       333.33\n",
       "2     2468        Feather Duster       Sweeps Bros        22.22"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_fwf('data/parts.fwf', nrows=3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Part_No          int64\n",
       "Description     object\n",
       "Maker           object\n",
       "Price (USD)    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We deliberately only read the start of the `parts.fwf` file.  From those first few rows, Pandas made a type inference of `int64` for the `Part_No` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us read the entire file.  Pandas does the \"right thing\" here: `Part_No` becomes a generic object, i.e. string. However, if we had a million rows instead, and the heuristics Pandas uses, for speed and memory efficiency, happened to limit inference to the first 100,000 rows, we might not be so lucky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Part_No</th>\n",
       "      <th>Description</th>\n",
       "      <th>Maker</th>\n",
       "      <th>Price (USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12345</td>\n",
       "      <td>Wankle rotary engine</td>\n",
       "      <td>Acme Corporation</td>\n",
       "      <td>555.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67890</td>\n",
       "      <td>Sousaphone</td>\n",
       "      <td>Marching Inc.</td>\n",
       "      <td>333.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2468</td>\n",
       "      <td>Feather Duster</td>\n",
       "      <td>Sweeps Bros</td>\n",
       "      <td>22.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A9922</td>\n",
       "      <td>Area 51 metal fragment</td>\n",
       "      <td>No Such Agency</td>\n",
       "      <td>9999.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Part_No             Description             Maker  Price (USD)\n",
       "0   12345    Wankle rotary engine  Acme Corporation       555.55\n",
       "1   67890              Sousaphone     Marching Inc.       333.33\n",
       "2    2468          Feather Duster       Sweeps Bros        22.22\n",
       "3   A9922  Area 51 metal fragment    No Such Agency      9999.99"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_fwf('data/parts.fwf')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Part_No         object\n",
       "Description     object\n",
       "Maker           object\n",
       "Price (USD)    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes  # type of `Part_No` changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R **tibbles** behave the same as Pandas, with the minor difference that data type imputation always uses 1000 rows (and will discard values if inconsistencies occur thereafter).  Pandas can be configured to read all rows for inference, but by default reads a dynamically determined number.  Pandas will sample more rows than R does, but still only approximately tens of thousands. The R collections **data.frame** and **data.table** are likewise similar.  Let us reading the same file as above using R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in read_table(\"data/parts.fwf\") : \n",
      "  could not find function \"read_table\"\n"
     ]
    },
    {
     "ename": "RInterpreterError",
     "evalue": "Failed to parse and evaluate line \"read_table('data/parts.fwf')\\n\".\nR error message: 'Error in read_table(\"data/parts.fwf\") : \\n  could not find function \"read_table\"'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:385\u001b[0m, in \u001b[0;36mRMagics.eval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# Need the newline in case the last line in code is a comment.\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     value, visible \u001b[38;5;241m=\u001b[39m \u001b[43mro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwithVisible(\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m})\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ri\u001b[38;5;241m.\u001b[39membedded\u001b[38;5;241m.\u001b[39mRRuntimeError, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m# Otherwise next return seems to have copy of error.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/robjects/__init__.py:459\u001b[0m, in \u001b[0;36mR.__call__\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    458\u001b[0m p \u001b[38;5;241m=\u001b[39m rinterface\u001b[38;5;241m.\u001b[39mparse(string)\n\u001b[0;32m--> 459\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mget_conversion()\u001b[38;5;241m.\u001b[39mrpy2py(res)\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/robjects/functions.py:208\u001b[0m, in \u001b[0;36mSignatureTranslatedFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         kwargs[r_k] \u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSignatureTranslatedFunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/robjects/functions.py:131\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         new_kwargs[k] \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mpy2rpy(v)\n\u001b[0;32m--> 131\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m res \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mrpy2py(res)\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/rinterface_lib/conversion.py:45\u001b[0m, in \u001b[0;36m_cdata_res_to_rinterface.<locals>._\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 45\u001b[0m     cdata \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# TODO: test cdata is of the expected CType\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/rinterface.py:817\u001b[0m, in \u001b[0;36mSexpClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error_occured[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 817\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m embedded\u001b[38;5;241m.\u001b[39mRRuntimeError(_rinterface\u001b[38;5;241m.\u001b[39m_geterrmessage())\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[0;31mRRuntimeError\u001b[0m: Error in read_table(\"data/parts.fwf\") : \n  could not find function \"read_table\"\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRInterpreterError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mread_table(\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/parts.fwf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:943\u001b[0m, in \u001b[0;36mRMagics.R\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m e\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mendswith(e\u001b[38;5;241m.\u001b[39merr):\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;28mprint\u001b[39m(e\u001b[38;5;241m.\u001b[39merr)\n\u001b[0;32m--> 943\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01min\u001b[39;00m DEVICES_STATIC:\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:923\u001b[0m, in \u001b[0;36mRMagics.R\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    921\u001b[0m         return_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 923\u001b[0m     text_result, result, visible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    924\u001b[0m     text_output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m text_result\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m visible:\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:389\u001b[0m, in \u001b[0;36mRMagics.eval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ri\u001b[38;5;241m.\u001b[39membedded\u001b[38;5;241m.\u001b[39mRRuntimeError, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m# Otherwise next return seems to have copy of error.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     warning_or_other_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RInterpreterError(code, \u001b[38;5;28mstr\u001b[39m(exception),\n\u001b[1;32m    390\u001b[0m                             warning_or_other_msg)\n\u001b[1;32m    391\u001b[0m text_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text_output, value, visible[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mRInterpreterError\u001b[0m: Failed to parse and evaluate line \"read_table('data/parts.fwf')\\n\".\nR error message: 'Error in read_table(\"data/parts.fwf\") : \\n  could not find function \"read_table\"'"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout err\n",
    "%%R\n",
    "read_table('data/parts.fwf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the first three rows are consistent with an integer data type, although this is inaccurate for later rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Error in read_table(\"data/parts.fwf\", n_max = 3, col_types = cols(\"i\",  : \n",
      "  could not find function \"read_table\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in read_table(\"data/parts.fwf\", n_max = 3, col_types = cols(\"i\",  : \n",
      "  could not find function \"read_table\"\n"
     ]
    },
    {
     "ename": "RInterpreterError",
     "evalue": "Failed to parse and evaluate line 'read_table(\\'data/parts.fwf\\', \\n           n_max = 3, \\n           col_types = cols(\"i\", \"-\", \"f\", \"n\"))\\n'.\nR error message: 'Error in read_table(\"data/parts.fwf\", n_max = 3, col_types = cols(\"i\",  : \\n  could not find function \"read_table\"'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:385\u001b[0m, in \u001b[0;36mRMagics.eval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# Need the newline in case the last line in code is a comment.\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     value, visible \u001b[38;5;241m=\u001b[39m \u001b[43mro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwithVisible(\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m})\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ri\u001b[38;5;241m.\u001b[39membedded\u001b[38;5;241m.\u001b[39mRRuntimeError, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m# Otherwise next return seems to have copy of error.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/robjects/__init__.py:459\u001b[0m, in \u001b[0;36mR.__call__\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    458\u001b[0m p \u001b[38;5;241m=\u001b[39m rinterface\u001b[38;5;241m.\u001b[39mparse(string)\n\u001b[0;32m--> 459\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mget_conversion()\u001b[38;5;241m.\u001b[39mrpy2py(res)\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/robjects/functions.py:208\u001b[0m, in \u001b[0;36mSignatureTranslatedFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         kwargs[r_k] \u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSignatureTranslatedFunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/robjects/functions.py:131\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         new_kwargs[k] \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mpy2rpy(v)\n\u001b[0;32m--> 131\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m res \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mrpy2py(res)\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/rinterface_lib/conversion.py:45\u001b[0m, in \u001b[0;36m_cdata_res_to_rinterface.<locals>._\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 45\u001b[0m     cdata \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# TODO: test cdata is of the expected CType\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/rinterface.py:817\u001b[0m, in \u001b[0;36mSexpClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error_occured[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 817\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m embedded\u001b[38;5;241m.\u001b[39mRRuntimeError(_rinterface\u001b[38;5;241m.\u001b[39m_geterrmessage())\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[0;31mRRuntimeError\u001b[0m: Error in read_table(\"data/parts.fwf\", n_max = 3, col_types = cols(\"i\",  : \n  could not find function \"read_table\"\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRInterpreterError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mread_table(\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43mdata/parts.fwf\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m           n_max = 3, \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m           col_types = cols(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:943\u001b[0m, in \u001b[0;36mRMagics.R\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m e\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mendswith(e\u001b[38;5;241m.\u001b[39merr):\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;28mprint\u001b[39m(e\u001b[38;5;241m.\u001b[39merr)\n\u001b[0;32m--> 943\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01min\u001b[39;00m DEVICES_STATIC:\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:923\u001b[0m, in \u001b[0;36mRMagics.R\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    921\u001b[0m         return_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 923\u001b[0m     text_result, result, visible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    924\u001b[0m     text_output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m text_result\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m visible:\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning3.9/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:389\u001b[0m, in \u001b[0;36mRMagics.eval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ri\u001b[38;5;241m.\u001b[39membedded\u001b[38;5;241m.\u001b[39mRRuntimeError, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m# Otherwise next return seems to have copy of error.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     warning_or_other_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RInterpreterError(code, \u001b[38;5;28mstr\u001b[39m(exception),\n\u001b[1;32m    390\u001b[0m                             warning_or_other_msg)\n\u001b[1;32m    391\u001b[0m text_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text_output, value, visible[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mRInterpreterError\u001b[0m: Failed to parse and evaluate line 'read_table(\\'data/parts.fwf\\', \\n           n_max = 3, \\n           col_types = cols(\"i\", \"-\", \"f\", \"n\"))\\n'.\nR error message: 'Error in read_table(\"data/parts.fwf\", n_max = 3, col_types = cols(\"i\",  : \\n  could not find function \"read_table\"'"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "read_table('data/parts.fwf', \n",
    "           n_max = 3, \n",
    "           col_types = cols(\"i\", \"-\", \"f\", \"n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Delimited files—but not so much fixed-width files—are prone to escaping issues.  In particular, CSVs specifically often contain descriptive fields that sometimes contain commas within the value itself.  When done right, this comma should be escaped.  It is often not done right in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV is actually a family of different dialects, mostly varying in their escaping conventions.  Sometimes spacing before or after commas is treated differently across dialects as well. One approach to escaping is to put quotes around either every string value, or every value of any kind, or perhaps only those values that contain the prohibited comma.  This varies by tool and by the version of the tool.  Of course, if you quote fields, there is potentially a need to escape those quotes; usually this is done by placing a backslash before the quote character when it is part of the value.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternate approach is to place a backslash before those commas that are not intended as a delimeter but rather part of a string value (or numeric value that might be formatted, e.g. `$1,234.56`).  Guessing the variant can be a mess, and even single files are not necessarily self consistent between rows, in practice (often different tools or versions of tools have touched the data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tab-separated and pipe-separated formats are often chosen with the hope of avoiding escaping issues.  This works to an extent.  Both tabs and pipe symbols are far less common in ordinary prose.  But both still wind up occurring in text occasionally, and all the escaping issues come back.  Moreover, in the face of escaping, the simplest tools sometimes fail.  For example, the bash command `cut -d,` will not work in these cases, nor will Python's `str.split(',')`.  A more custom parser becomes necessary, albeit a simple one compared to full-fledged grammars.  Python's standard library `csv` module is one such custom parser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding danger for fixed-width files, in contrast to delimited ones, is that values become too long.  Within a certain line position range you can have any codepoints whatsoever (other than newlines).  But once the description or name that someone thought would never be longer than, say, 20 characters becomes 21 characters, the format fails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "A special consideration arises around reading datetime formats.  Data frame libraries that read datetime values typically have an optional switch to parse certain columns as datetime formats.  Libraries such as Pandas support heuristic guessing of datetime formats; the problem here is that applying a heuristic to each of millions of rows can be *exceedingly slow*.  Where a date format is uniform, using a manual format specifier can make it several orders of magnitude faster to read.  Of course, where the format varies, heuristics are practically magic; and perhaps we should simply marvel that the dog can talk at all rather than criticize its grammar. Let us look at a Pandas' attempt to guess datetimes for each row of a tab-separated file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Notice many date formats\n",
    "cat data/parts.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let Pandas make guesses for each row\n",
    "# VERY SLOW for large tables\n",
    "parts = pd.read_csv('data/parts.tsv', \n",
    "                    sep='\\t', parse_dates=['Date'])\n",
    "parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that the dates are genuinely a datetime data type within the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have looked at some challenges and limitations of delimited and fixed-width formats, let us consider their considerable advantages as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Good**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The biggest strength of CSV files, and their delimited or fixed-width cousins, is the ubiquity of tools to read and write them.  Every library dealing with data frames or arrays, across every programming language, knows how to handle them.  Most of the time the libraries parse the quirky cases pretty well.  Every spreadsheet program imports and exports as CSV.  Every RDBMS—and most non-relational databases as well—imports and exports as CSV.  Most programmers' text editors even have facilities to make editing CSV easier.  Python has a standard library module `csv` that processes many dialects of CSV (or other delimited formats) as a line-by-line record reader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that so very many structurally flawed CSV files live in the wild shows that not *every* tool handles them entirely correctly.  In part, that is probably because the format is simple enough to *almost* work without custom tools at all. I have myself, in a \"throw-away script,\" written `print(\",\".join([1,2,3,4]), file=csv)` countless times; that works well, until it doesn't.  Of course, throw-away scripts become fixed standard procedures for data flow far too often."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The lack of type specification is often a strength rather than a weakness.  For example, the part numbers mentioned a few pages ago may have started out always being integers as an actual business intention, but later on a need arose to use non-integer \"numbers.\"  With formats that have a formal type specifier, we generally have to perform a migration and copy to move old data into a new format that follows the loosened or revised constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One particular case where a data type change happens especially often, in my experience, is with finite-width character fields.  Initially some field is specified as needing 5, or 15, or 100 characters for its maximum length, but then a need for a longer string is encountered later, and a fixed table structure or SQL database needs to be modified to accommodate the longer length.  Even more often—especially with databases—the requirement is underdocumented, and we wind up with a data set filled with truncated strings that are of little utility (and perhaps permanently lost data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text formats in general are usually flexible in this regard. Delimited files—but not fixed-width files—will happily contain fields of arbitrary length.  This is similarly true of JSON data, YAML data<sup><i>config</i></sup>, XML data, log files, and some other formats that simply utilize text, often with line-oriented records.  In all of this, data typing is very loose and only genuinely exists in the data processing steps.  That is often a great virtue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"config\"\n",
    "     style=\"display: inline-block; margin: 0 5% 0 5%; border-style: solid; border-width: 1px\">\n",
    "    <i>config</i><br/>\n",
    "YAML usually contains relatively short configuration information rather than *data* in the prototypic sense.  TOML is a similar format in this regard, as is the older INI format.  All of these are really intended for hand editing, and hence are usually of small size, even though good APIs for reading and writing their data are common.  While you <i>could</i> put a million records into any of these formats, you will rarely or never encounter that in practice.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "A related \"looseness\" of CSV and similar formats is that we often indefinitely aggregate multiple CSV files that follow the same informal schema.  Writing a different CSV file for each day, or each hour, or each month, of some ongoing data collection is very commonplace.  Many tools, such as Dask and **Spark** will seamlessly treat collections of CSV files (matching a *glob* pattern on the file system) as a single data set.  Of course, in tools that do not directly support this, manual concatenation is still not difficult.  But under the model of having a directory that contains an indefinite number of related CSV snapshots, presenting it as a single common object is helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The libraries that handle families of CSV files seamlessly are generally lazy and distributed.  That is, with these tools, you do not typically read in all the CSV files at once, or at least not into the main memory of a single machine.  Rather, various cores or various nodes in a cluster will each obtain file handles to individual files, and the schema information will be inferred from only one or a few of the files, with actual processing deferred until a specific (parallel) computation is launched.  Splitting processing of an individual CSV file across cores is not easily tractable since a reader can only determine where a new record begins by scanning until it finds a newline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While details of the specific APIs of libraries for distributed data frames is outside the scope of this book, the fact that parallelism is easily possible given an initial division of data into many files is a significant strength for CSV as a format.  Dask in particular works by creating many Pandas DataFrames and coordinating computation upon all of them (or those needed for a given result) with an API that exactly copies the same methods of individual Pandas objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated data files with random values\n",
    "from glob import glob\n",
    "# Use glob() function to identify files matching pattern\n",
    "glob('data/multicsv/2000-*.csv')[:8] # ... and more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read this family of CSV files into one virtualized DataFrame that acts like a Pandas DataFrame, even if loading it with Pandas would require more memory than our local system allows.  In this specific example, the collection of CSV files is not genuinely too large for a modern workstation to read into memory; but when it becomes so, using some distributed or out-of-core system like Dask is necessary to proceed at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "df = dd.read_csv('data/multicsv/2000-*-*.csv', \n",
    "                 parse_dates=['timestamp'])\n",
    "print(\"Total rows:\", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we require some summary to be computed, Dask will coordinate workers to aggregate on each individual DataFrame, then aggregate those aggregations.  There are more nuanced issues of what operations can be reframed in this \"map-reduce\" style and which cannot, but that is the general idea (and the Dask or Spark developers have thought about this for you so you do not have to)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having looked at some pros and cons of working with CSV data, let us turn to another format where a great deal of data is stored.  Unfortunately, for spreadsheets, there are almost exclusively cons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spreadsheets Considered Harmful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Drugs are bad. m'kay. You shouldn't do drugs. m'kay. \n",
    "> If you do them you're bad, because drugs are bad. m'kay. \n",
    "> It's a bad thing to do drugs, so don't be bad by doing drugs. m'kay.<br/>\n",
    "> –Mr. Mackay (South Park)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concepts**:\n",
    "\n",
    "* Non-enforced field/column identity\n",
    "* Computational opacity\n",
    "* Semi-tabular data\n",
    "* Non-contiguous data\n",
    "* Invisible data and data type discrepancies\n",
    "* User interface as attractive nuisance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edward Tufte, that brilliant doyen of information visualization, wrote an essay called *[The Cognitive Style of Powerpoint: Pitching Out Corrupts Within](https://www.edwardtufte.com/tufte/powerpoint)*.  Amongst his observations is that the manner in which slide presentations, and Powerpoint specifically, hides important information more than it reveals it, was a major or even main cause of the 2003 Columbia space shuttle disaster.  Powerpoint is anathema to clear presentation of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To no less of a degree, spreadsheets in general, and Excel in particular, are anathema to effective data science.  While perhaps not as much as in CSV files, a great share of the world's data lives in Excel spreadsheets.  There are numerous kinds of data corruption that are the special realm of spreadsheets.  As a bonus, data science tools read spreadsheets much more slowly than they do every other format, while spreadsheets also have hard limits on the amount of data they can contain that other formats do not impose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of what spreadsheets do to make themselves convenient for their users makes them bad for scientfic reproducibility, data science, statistics, data analysis, and related areas.<sup><i>computation</i></sup> Spreadsheets have apparent rows and columns in them, but nothing enforces consistent use of those, even within a single sheet.  Some particular feature often lives in column F for some rows, but the equivalent thing is in column H for other rows, for example.  Contrast this with a CSV file or an SQL table; for these latter formats, while all the data in a column is not necessarily *good* data, it generally must pertain to the same feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"computation\"\n",
    "     style=\"display: inline-block; margin: 0 5% 0 5%; border-style: solid; border-width: 1px\">\n",
    "    <i>computation</i><br/>\n",
    "Another danger of spreadsheets is not around data ingestion, per se, at all. Computation within spreadsheets is spread among many cells in no obvious or easily inspectable order, leading to numerous large-scale disasterous consequences (loss of <a href=\"https://www.businessinsider.com/excel-partly-to-blame-for-trading-loss-2013-2\">billions in financial transaction</a>; a <a href=\"https://theconversation.com/the-reinhart-rogoff-error-or-how-not-to-excel-at-economics-13646\">worldwide economic planning debacle</a>; a <a href=\"https://www.bbc.com/news/technology-54423988\">massive failure of Covid-19 contact tracing</a> in the UK).  The <a href=\"http://www.eusprig.org/\">European Spreadsheet Risks Interest Group</a> is an entire organization devoted to chronicling such errors.  They present a number of lovely quotes, including this one:\n",
    "    \n",
    "> There is a literature on denial, which focuses on illness and the fact that many people with terminal illnesses deny the seriousness of their condition or the need to take action. Apparently, what is very difficult and unpleasant to do is difficult to contemplate. Although denial has only been studied extensively in the medical literature, it is likely to appear whenever required actions are difficult or onerous. Given the effortful nature of spreadsheet testing, developers may be victims of denial, which may manifest itself in the form of overconfidence in accuracy so that extensive testing will not be needed. –<a href=\"http://arxiv.org/abs/0804.0941\">Ray Panko, 2003</a>\n",
    "\n",
    "In procedural programming (including object-oriented programming), actions flow sequentially through code, with clear locations for branches or function calls; even in functional paradigms, compositions are explicitly stated.  In spreadsheets it is anyone's guess what computation depends on what else, and what data ranges are actually included.  Errors can occasionally be found accidentally, but program analysis and debugging are *nearly* impossible.  Users who know only, or mostly, spreadsheets will likely object that *some* tools exist to identify dependencies within a spreadsheet; this is technically true in the same sense as that many goods transported by freight train could also be carried on a wheelbarrow. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, every cell in a spreadsheet can have a different data type.  Usually the type is assigned by heuristic guesses within the spreadsheet interface.  These are highly sensitive to the exact keystrokes used, the order cells are entered, whether data is copy/pasted between blocks, and numerous other things that are both hard to predict and that change between every version of every spreadsheet software program. Infamously, for example, Excel interprets the gene name 'SEPT2' (Septin 2) as a date (at least in a wide range of versions).  Compounding the problem, the interfaces of spreadsheets make determining the data type for a given cell uncomfortably difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start with an example.  The screenshot below is of a commonplace and ordinary looking spreadsheet.  Yes, some values are not aligned in their cells exactly consistently, but that is purely an aesthetic issue.  The first problem that jumps out at us is the fact that one sheet is being used to represent two different (in this case related) tables of data.  Already this is going to be difficult to make tidy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/Excel-Pitfalls.png\" alt=\"Excel Pitfalls\" width=\"50%\"/>\n",
    "\n",
    "__Image: Excel Pitfalls__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we simply tell Pandas (or specifically the supporting **openpyxl** library) to try to make sense of this file, it makes a sincere effort and applies fairly intelligent heuristics.  It does not crash, to its credit.  Other DataFrame libraries will be similar, with different quirks you will need to learn. But what went wrong that we can see initially?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default engine `xlrd` might have bug in Python 3.9\n",
    "pd.read_excel('data/Excel-Pitfalls.xlsx',\n",
    "              sheet_name=\"Dask Sample\", engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right away we can notice that the `id` column contains a value 1019.5 that was invisible in the spreadsheet display.  Whether that column is intended as a floating-point or an integer is not obvious at this point.  Moreover, notice that visually the date on that same row looks slightly wrong.  We will come back to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, we can, with laborious manual intervention, pull out the two separate tables we actually care about.  Pandas is actually a little bit *too smart* here—it will, by default, ignore the data typing actually in the spreadsheet and do inference similar to what it does with a CSV file.  For this purpose, we tell it to use the data type actually stored by Excel.  Pandas' inference is not a panacea, but it *is* a useful option at times (it can fix *some*, but not *all*, of the issues we note below; however, other things are made worse).  For the next few paragraphs, we wish to see the raw data types stored in the spreadsheet itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel('data/Excel-Pitfalls.xlsx', \n",
    "                    nrows=5, dtype=object, engine=\"openpyxl\")\n",
    "df1.loc[:2]   # Just look at first few rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read the second implicit table as well by using the `pd.read_excel()` parameter `skiprows`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel('data/Excel-Pitfalls.xlsx', skiprows=7, engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the data types read in, we will see they are all Python objects to preserve the various cell types.  But let us look more closely at what we actually have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The timestamps in this particular small example are all reasonable to parse with Pandas.  But real-life spreadsheets often provide something much more ambiguous, often impossible to parse as dates.  Look above at the screenshot of a spreadsheet to notice that the data type is invisible in the spreadsheet itself.  We can find the Python data type of the generic object stored in each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the stored data type of each cell\n",
    "tss = df1.loc[:2, 'timestamp']\n",
    "for i, ts in enumerate(tss):\n",
    "    print(f\"TS {i}: {ts}\\t{ts.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas `to_datetime()` function is idempotent<sup><i>idempotent</i></sup> and would have run if we had not specifically disabled it in by using `dtype=object` in the `pd.read_excel() call`.  However, many spreadsheets are far messier, and the conversion will simply not succeed, producing an `object` column in any case.  Particular cells in a column might contain numbers, formulae, or strings looking nothing like dates (or sometimes strings looking just enough like date string that a human, but not a machine, might guess the intent; say 'Decc 23,, 201.9')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"idempotent\"\n",
    "     style=\"display: inline-block; margin: 0 5% 0 5%; border-style: solid; border-width: 1px\">\n",
    "    <i>idempotent</i><br/>\n",
    "    \n",
    "The word and concept *idempotent* is a useful one in mathematics, computer science, and generally in programming.  It means that calling the same function again on its own output will continue to produce the same answer.  This is related to the even fancier concept in mathematics of an *attractor*.\n",
    "    \n",
    "In ordinary programming terms, this means that you do not have to worry as much about potentially modifying a value repeatedly in an idempotent way, which may emerge from the vicissitudes of program flow.  In other words, whatever the initial `x` is, you know that:\n",
    "    \n",
    "```python\n",
    "pd.to_datetime(x) == pd.to_datetime(pd.to_datetime(x))\n",
    "```\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at using `pd.to_datetime()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(tss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other columns pose a similar difficulty.  The values that look identical in the spreadsheet view of the `id` column are actually a mixture of integers, floating-point numbers, and strings.  It is *conceivable* that such was the intention, but in practice it is almost always an accidental result of the ways that spreadsheets hide information from their users.  By the time these data sets arrive on your data science desk, they are merely messy, and the causes are lost in the sands of time. Let us look at the data types in the `id` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the stored data type of each cell\n",
    "ids = df1.loc[:3, 'id']\n",
    "for i, id_ in enumerate(ids):\n",
    "    print(f\"id {i}: {id_}\\t{id_.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course tools like Pandas can type cast values subsequent to reading them, but we require domain-specific knowledge of the data set to know what cast is appropriate.  Let us cast data using the `.astype()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting together the cleanup we mention, we might carefully type our data in a manner similar to the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only rows through index `3` are useful\n",
    "# We are casting to more specific data types \n",
    "#   based on domain and problem knowledge\n",
    "df1 = df1.loc[0:3].astype(\n",
    "    {'id': np.uint16, \n",
    "     'name': pd.StringDtype(), \n",
    "     'x': float})\n",
    "# datetimes require conversion function, not just type\n",
    "df1['timestamp'] = pd.to_datetime(df1.timestamp)\n",
    "print(df1.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.set_index('timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What makes spreadsheets harmful is not principally their underlying data formats.  Non-ancient versions of Excel (.xlsx), LibreOffice (OpenDocument, .ods), and Gnumeric (.gnm) have all adopted a similar format at the byte level.  That is, they all store their data in XML formats, then compress those to save space.  As I mentioned, this is slower than other approaches, but that concern is secondary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one of these spreadsheet formats were used purely as an exchange format among structured tools, they would be perfectly suitable to preserve and represent data.  It is instead the social and user interface (UI) elements of spreadsheets that make them dangerous.  The \"tabular\" format of Excel combines the worst elements of untyped CSV and strongly typed SQL databases.  Rather than assign a data type by column/feature, it allows type assignments per cell.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per-cell typing is almost always the wrong thing to do for any data science purpose.  It neither allows flexible decisions by programming tools (either using inference or type declaration APIs) nor does it enforce consistency of different values that should belong to the same feature at the time data is stored.  Moreover, the relatively free-form style of entry in the user interfaces of spreadsheets does nothing to guide users away from numerous kinds of entry errors (not only data typing, but also various misalignments within the grid, accidental deletions or insertions, and so on).  Metaphorically, the danger posed by spreadsheet UIs resembles the concept in tort law of an \"attractive nuisance\"—they do not directly create the harm, but they make harm exceedingly likely with minor inattention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, there do not currently exist any general purpose data entry tools in widespread use.  Database entry forms could serve the purpose of enforcing structure on data entry, but they are limited for non-programmatic data exploration.  Moreover, use of structured forms, whatever the format where the data might be subsequently stored, currently requires at least a modicum of software development effort, and many general users of spreadsheets lack this ability.  Something similar to a spreadsheet, but that allowed locking data type constraints on columns, would be a welcome addition to the world. Perhaps one or several of my readers will create and popularize such tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, the reality is that many users will create spreadsheets that you will need to extract data from as a data scientist.  This will inevitably be more work for you than if you were provided a different format.  But think carefully about the block regions and tabs/sheets that are of actual relevance, to the problem-required data types for casts, and about how to clean unprocessable values. With effort the data will enter your data pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can turn now to well structured and carefully date typed formats; those stored in relational databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL RDBMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> At the time, Nixon was normalizing relations with China. \n",
    "> I figured that if he could normalize relations, \n",
    "> then so could I. <br/>–E. F. Codd (inventor of relational database theory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concepts**:\n",
    "\n",
    "* Python DB-API and SQL drivers\n",
    "* Data type impedence mismatches\n",
    "* Manually casting to exact data types\n",
    "* Truncation and overflow\n",
    "* Wrapping versus clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relational databases management systems (RDBMS) are enormously powerful and versatile.  For the most part, their requirement of strict column typing and frequent use of formal foreign keys and constraints is a great boon for data science.  While specific RDBMS's vary greatly in how well normalized, indexed, and designed they are—not every organization has or utilizes a database engineer specifically—even somewhat informally assembled databases have many desirable properties for data science.  Not all relational databases are *tidy*, but they all take you several large steps in that direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with relational databases requires some knowledge of Structured Query Language (SQL).  For small data, and perhaps for medium-sized data, you can get by with reading entire tables into memory as data frames.  Operations like filtering, sorting, grouping, and even joins can be performed with data frame libraries.  However, it is much more efficient if you are able to do these kinds of operations directly at the database level; it is an absolute necessity when working with *big data*.  A database that has millions or billions of records, distributed across tens or hundreds of related tables, can itself quickly produce the hundreds of thousands of rows (tuples) that you need for the task at hand.  But loading all of these rows into memory is either unnecessary or simply impossible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many excellent books and tutorials on SQL.  I do not have a specific one to recommend over others, but finding a suitable text to get up to speed—if you are not already—is not difficult.  The general concepts of `GROUP BY`, `JOIN`, and `WHERE` clauses are the main things you should know as a data scientist.  If you have a bit more control over the database you pull data from, knowing something about how to intelligently index tables, and optimize slow queries by reformulation and looking at `EXPLAIN` output, is helpful.  However, it is quite likely that you, as a data scientist, will not have full access to database administration. If you do have such access: be careful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this book, I use a local **PostgreSQL** server to illustrate APIs.  I find that PostgreSQL is vastly better at query optimization than is its main open source competitor, **MySQL**.  Both behave equally well with careful index tuning, but generally PostgreSQL is much faster for queries that must be optimized on an ad hoc basis by the query planner.  In general, almost all of the APIs I show will be nearly identical across drivers in Python or in R (and in most other languages) whether you use PostgreSQL, MySQL, Oracle DB, DB2, SQL Server, or any other RDBMS.  The Python DB-API, in particular, is well standardized across drivers.  Even the single-file RDBMS, **SQLite3**, which is included in the Python standard library is almost DB-API compliant (and `.sqlite` is a very good storage format)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the `setup.py` module that is loaded by each chapter and is available within the source code repository, some database setup is performed.  If you run some of the functions contained therein, you will be able to create generally the same configuration on your system as I have on the one where I am writing this.  Actual installation of an RDBMS is not addressed in this book; see the instructions accompanying your database software.  But a key, and simple step, is creating a *connection* to the DB.\n",
    "\n",
    "```python\n",
    "# Similar with adapter other than psycopg2\n",
    "con = psycopg2.connect(database=db, host=host, \n",
    "                       user=user, password=pwd)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This connection object will be used in subsequent code in this book.  We also create an `engine` object that is an **SQLAlchemy** wrapper around a connection that adds some enhancements.  Some libraries like Pandas require using an engine rather than only a connection.  We can create that as follows:\n",
    "\n",
    "```python\n",
    "engine = create_engine(\n",
    "      f'postgresql://{user}:{pwd}@{host}:{port}/{db}')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Massaging Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the Dask data created earlier in this chapter to populate a table with the following schema.  These metadata values are defined in the RDBMS itself.  Within this section, we will work with the elaborate and precise data types that relational databases provide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column    | Data Type | Data Width\n",
    "|----------:|:----------|------------\n",
    "| index     | integer   | 32\n",
    "| timestamp | timestamp without time zone | None\n",
    "| id        | smallint  | 16\n",
    "| name      | character | 10\n",
    "| x         | numeric   | 6\n",
    "| y         | real      | 24\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same data structure created in the previous Dask discussion, but I have somewhat arbitrarily imposed more specific data types on the fields.  The PostgreSQL \"data width\" shown is a bit odd; it mixes bit length with byte length depending on the type.  Moreover, for the floating-point `y` it shows the bit length of the mantissa, not of the entire 32-bit memory word.  But in general we can see that different columns have different specific types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When designing tables, database engineers generally try to choose data widths that are sufficient for the purpose, but also as small as the requirement allows.  If you need to store billions of person ages, for example, a 256-bit integer could certainly hold those numbers, but an 8-bit integer can also hold all the values that can occur using 1/32nd as much storage space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Python DB-API loses some data type information.  It does *pretty well*, but Python does not have a full range of native types.  The fractional numbers are accurately stored as either `Decimal` or native floating-point, but the specific bit lengths are lost.  Likewise, the integer is a Python integer of unbounded size.  The `name` strings are always 10 characters long, but for most purposes we probably want to apply `str.rstrip()` (strip whitespace at right end) to take off the surrounding whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function connect_local() spelled out in chapter 4 (Anomaly Detection)\n",
    "con, engine = connect_local()\n",
    "cur = con.cursor()\n",
    "cur.execute(\"SELECT * FROM dask_sample\")\n",
    "pprint(cur.fetchmany(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, we lose even more data type information using Pandas (at least as of Pandas 1.0.1 and SQLAlchemy 1.3.13, current as of this writing).  Pandas is able to use the full type system of NumPy, and even adds a few more custom types of its own.  This richness is comparable to—but not necessarily identical with—the type systems provided by RDBMS's (which, in fact, vary from each other as well, especially in extension types).  However, the translation layer only casts to basic string, float, int, and date types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us read a PostgreSQL table into Pandas, and then examine what native data types were utilized to approximate that SQL data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('dask_sample', engine, index_col='index')\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specific dtypes within the DataFrame are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it is a bit more laborious, we can combine these techniques and still work with our data within a friendly data frame, but using more closely matched types (albeit not perfectly matched to the DB).  The two drawbacks here are:\n",
    "\n",
    "* We need to make manual decisions about the best type for each column.\n",
    "* Operations in Pandas will be much slower with `object` columns\n",
    "\n",
    "Let us endeavor to choose better data types for our data frame.  We probably need to determine the precise types from the documentation of our RDBMS, since few people have the PostgreSQL type codes memorized.  The DB-API cursor object has a `.description` attribute that contains column type codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT * FROM dask_sample\")\n",
    "cur.description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can introspect to see the Python types used in the results.  Of course, these do not carry the bit lengths of the DB with them, so we will need to manually choose these.  Datetime is straightforward enough to put into Pandas's `datetime64[ns]` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = cur.fetchall()\n",
    "[type(v) for v in rows[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with Decimal numbers is tricker than other types.  Python's standard library `decimal` module complies with [IBM’s General Decimal Arithmetic Specification](http://speleotrove.com/decimal/); unfortunately, databases do not.  In particular, the IBM 1981 spec (with numerous updates) allows each *operation* to be performed within some chosen \"decimal context\" that gives precision, rounding rules, and other things.  This is simply *different* from having a decimal precision *per column*, with no specific control of rounding rules.  We can usually ignore these nuances; but when they bite us, they can bite hard.  The issues arise more in civil engineering and banking/finance than they do with data science as such, but these are concerns to be aware of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we cast several columns to specific numeric data types with specific bit widths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data with no imposed data types\n",
    "df = pd.DataFrame(rows, \n",
    "                  columns=[col.name for col in cur.description],\n",
    "                  dtype=object)\n",
    "\n",
    "# Assign specific int or float lengths to some fields\n",
    "types = {'index': np.int32, 'id': np.int16, 'y': np.float32}\n",
    "df = df.astype(types)\n",
    "\n",
    "# Cast the Python datetime to a Pandas datetime\n",
    "df['timestamp'] = pd.to_datetime(df.timestamp)\n",
    "df.set_index('index').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify those data types are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Panda's \"object\" type hides the differences of the underlying classes of the Python objects stored.  We can look at those more specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint({repr(x): x.__class__.__name__ \n",
    "        for x in df.reset_index().iloc[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the most part, the steps for reading in SQL data in R are similar to those in Python.  And so are the pitfalls around getting data types just right.  We can see that the data types are the same rough approximations of the actual database types as Pandas produced.  Obviously, in real code you should not specify passwords as literal values in the source code, but use some tool for secrets management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout err\n",
    "%%R\n",
    "require(\"RPostgreSQL\")\n",
    "drv <- dbDriver(\"PostgreSQL\")\n",
    "con <- dbConnect(drv, dbname = \"dirty\",\n",
    "                 host = \"localhost\", port = 5432,\n",
    "                 user = \"cleaning\", password = \"data\")\n",
    "sql <- \"SELECT id, name, x, y FROM dask_sample LIMIT 3\"\n",
    "data <- tibble(dbGetQuery(con, sql))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is interesting to look at is that we might produce data frames that are not directly database tables (nor simply the first few rows, as in examples here), but rather some more complex manipulation or combination of that data.  Joins are probably the most interesting case here since they take data from multiple tables.  But grouping and aggregation is also frequently useful, and might reduce a million rows to a thousand summary descriptions, for example, which might be our goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout err\n",
    "%%R\n",
    "sql <- \"SELECT max(x) AS max_x, max(y) AS max_y, \n",
    "               name, count(name) \n",
    "        FROM dask_sample \n",
    "        WHERE id > 1050 \n",
    "        GROUP BY name \n",
    "        ORDER BY count(name) DESC\n",
    "        LIMIT 12;\"\n",
    "# Here we simply retrieve a data.frame \n",
    "# rather than convert to tibble \n",
    "dbGetQuery(con, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where SQL Goes Wrong (And How to Notice It)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following example, I started with a data set that described Amtrak train stations in 2012.  Many of the fields initially present were discarded, but some others were manipulated to illustrate some points.  Think of this as \"fake data\" even though it is derived from a genuine data set.  In particular, the column `Visitors` is invented whole cloth; I have never seen visitor count data, nor do I know if it is collected anywhere. It is just numbers that will have a pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amtrak = pd.read_sql('bad_amtrak', engine)\n",
    "amtrak.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the face of it—other than the telling name of the table we read in—nothing looks out of place.  Let us look for problems.  Notice that the tests below will, in a way, be anomaly detection, which is discussed in a later chapter.  However, the anomalies we find are specific to SQL data typing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "String fields in RDBMS's are prone to truncation if specific character lengths are given.  Modern database systems also have a `VARCHAR` or `TEXT` type for unlimited length strings, but often specific lengths are used in practice.  To a certain degree, database operations can be more efficient with known text lengths, so the choice is not simple foolishness.  But whatever the reason, you will find such fixed lengths frequently in practice.  In particular, the `StationName` column is defined as `CHAR(20)`.  The question is: is that a problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the character length will not automatically answer the question we care about.  Perhaps Amtrak regulation requires a certain length of all station names.  This is domain-specific knowledge that you may not have as a data scientist.  In fact, the domain experts may not have it either, because it has not been analyzed or because rules have changed over time.  Let us analyze the data itself.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, even if a database field is currently variable length or very long, it is quite possible that a column was altered over the life of a DB, or that a migration occurred.  Unfortunately, multiple generations of old data that may each have been corrupted in their own ways can obscure detection.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One place you may encounter this problem data history is with dates in older data sets where two digit years were used.  The \"Y2K\" issue had to be addressed two decades ago for active database systems—for example, I spent the calendar year of 1998 predominantly concerned with this issue—but there remain some infrequently accessed legacy data stores that will fail on this ambiguity.  If the character string '34' is stored in a column named `YEAR`, does it refer to something that happened in the 20th century or an anticipated future event a decade after this book is being written? Some domain knowledge is needed to answer this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some rather concise Pandas code can tell us something useful.  A first step is cleaning the padding in the fixed length character field.  The whitespace padding is not generally useful in our code.  After that we can look at the length of each value, count the number of records per length, and sort by those lengths, to produce a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amtrak['StationName'] = amtrak.StationName.str.strip()\n",
    "hist = amtrak.StationName.str.len().value_counts().sort_index()\n",
    "hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pattern is even more striking if we visualize it.  Clearly station names bump up against that 20 character width.  This is not quite yet a smoking gun, but it is very suggestive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.plot(kind='bar', \n",
    "          title=\"Lengths of Station Names\")\n",
    "plt.savefig('img/(Ch01)Lengths of Station Names')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to be careful not to attribute an underlying phenomenon as a *data artifact*.  For example, in preparing this section, I started analyzing a collection of Twitter 2015 tweets.  Those naturally form a similar pattern of \"bumping up\" against 140 characters—but I realized that they do this because of a limit in the accurate underlying data, not as a data artifact. However, the Twitter histogram curve looks similar to that for station names.  I am aware that Twitter doubled its limit in 2018; I would expect an aggregated collection over time to show asymptotes at both 140 and 280, but as a \"natural\" phenomenon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the character width limit changed over the history of our data, we might see a pattern of multiple soft limits.  These are likely to be harder to discern, especially if those limits are significantly larger than 20 characters to start with.  Before we absolutely conclude that we have a *data artifact* rather than, for example, an Amtrak naming rule, let us look at the concrete data.  This is not impractical when we start with a thousand rows, but it becomes more difficult with a million rows.  Using Pandas' `.sample()` method is often a good way to view a random subset of rows matching some filter, but here we just display the first and last few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amtrak[amtrak.StationName.str.len() == 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is reasonable to conclude from our examined data that truncation is an authentic problem here.  Many of the samples have words terminated in their middle at character length.  Remediating it is another decision and more effort.  Perhaps we can obtain the full texts as a followup; if we are lucky the prefixes will uniquely match full strings.  Of course, quite likely, the real data is just lost.  If we only care about uniqueness, this is likely not to be a big problem (the three letter codes are already unique).  However, if our analysis concerns the missing data itself we may not be able to proceed at all. Perhaps we can decide in a problem-specific way that prefixes nonetheless are a representative sample of what we are analyzing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "A similar issue arises with numbers of fixed lengths.  Floating-point numbers might lose desired precision, but integers might wrap and/or clip.  We can examine the `Visitors` column and determine that it stores a 16-bit `SMALLINT`.  Which is to say, it cannot represent values greater than 32,767.  Perhaps that is more visitors than any single station will plausibly have. Or perhaps we will see data corruption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ = amtrak.Visitors.max()\n",
    "amtrak.Visitors.plot(\n",
    "        kind='hist', bins=20, \n",
    "        title=f\"Visitors per station (max {max_})\")\n",
    "plt.savefig(f\"img/(Ch01)Visitors per station (max {max_})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the bumping against the limit is a strong signal. An extra hint here is the specific limit reached. It is one of those special numbers you should learn to recognize.  Signed integers of bit-length N range from $-2^{N-1}$ up to $2^{N-1}-1$.  Unsigned integers range from $0$ to $2^N$.  32,767 is $2^{16}-1$.  However, for various programming reasons, numbers one (or a few) shy of a data type bound also frequently occur.  In general, if you ever see a measurement that is exactly one of these bounds, you should take a second look and think about whether it might be an artifactual number rather than a genuine value.  This is a good rule even outside the context of databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A possibly more difficult issue to address is when values wrap instead.  Depending on the tools you use, large positive integers might wrap around to negative integers.  Many RDBMS's—including PostgreSQL—will simply refuse transactions with unacceptable values rather than allow them to occur.  But different systems vary.  Wrapping on sign is obvious in the case of counts that are non-zero by their nature, but for values where both positive and negative numbers make sense, detection is harder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, in this Pandas Series example, which is cast to a short integer type, we see values around positive and negative 15 thousand, both as genuine elements and as artifacts of a type cast.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ints = pd.Series(\n",
    "    [100, 200, 15_000, 50_000, -15_000, -50_000])\n",
    "ints.astype(np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a case like this, we simply need to acquire enough domain expertise to know whether the out of bounds values that might wrap can ever be sensible measurements.  I.e. is 50,000 reasonable for this hypothetical measure? If all reasonable observations are of numbers in the hundreds, wrapping at 32 thousand is not a large concern.  It is *conceivable* that some reasonable value got there as a wrap from an unreasonable one; but wrong values can occur for a vast array of reasons, and this would not be an unduly large concern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that integers and floating-point numbers only come, on widespread computer architectures, in sizes of 8, 16, 32, 64, and 128-bits.  For integers those might be signed or unsigned, which would halve or double the maximum number representable.  These maximum values representable within these different bit widths are starkly different from each other.  A rule of thumb, if you can choose the integer representation, is to leave an order-of-magnitude padding from the largest magnitude you *expect* to occur.  However, sometimes even an order-of-magnitude does not set a good bound on unexpected (but accurate) values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, in our hypothetical visitor count, perhaps a maximum of around 20k was reasonably anticipated, but over the years, that got as high as 35k, leading to the effect we see in the plot (of hypothetical data).  Allowing for 9,223,372,036,854,775,807 $(2^{63}-1)$ visitors to a station might have seemed like unecessary overhead to the initial database engineers.  However, a 32-bit integer, with a maximum of 2,147,483,647 $(2^{31}-1)$ would have been a better choice, even though the actual maximum remains far larger than will ever be observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us turn now to some other data formats you are likely to work with, generally binary data formats, often used for scientific requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let a hundred flowers bloom; let a hundred schools of thought contend.<br/>\n",
    "> –Confucian saying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concepts**:\n",
    "\n",
    "* Binary columnar data files\n",
    "* Hierarchical array data\n",
    "* Single-file RDBMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variety of data formats that you may encounter can be used for holding tabular data.  For the most part these do not introduce any special new cleanliness concerns that we have not addressed in earlier sections.  Properties of the data themselves are discussed in later chapters.  The data type options vary between storage formats, but the same kinds of general concerns that we discussed with RDBMS's apply to all of them.  In the main, from the perspective of this book, these formats simply require somewhat different APIs to get at their underlying data, but all provide data types per column.  The formats addressed herein are not an exhaustive list, and clearly new ones may arise or increase in significance after the time of this writing.  But the principles of access should be similar for formats not discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The closely related formats **HDF5** and **NetCDF** (discussed below) are largely interoperable, and both provide ways of storing multiple arrays, each with metadata associated and also allowing highly dimensional data, not simply tabular 2-D arrays.  Unlike with the data frame model, arrays within these scientific formats are of homogeneous type throughout.  That is, there is no mechanism (by design) to store a text column and a numeric column within the same object, nor even numeric columns of different bit-widths.  However, since they allow multiple arrays in the same file, full generality is available, just in a different way than within the SQL or data frame model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SQLite** (discussed below) is a file format that provides a relational database, consisting potentially of multiple tables, within a single file.  It is extremely widely used, being present and used everywhere from on every iOS and Android device up to the largest supercomputer clusters.  An interface for SQLite is part of the Python standard library and is available for nearly all other programming languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apache Parquet** (discussed below) is a column-oriented data store.  What this amounts to is simply a way to store data frames or tables to disk, but in a manner that optimizes common operations that typically vectorize along columns rather than along rows.  A similar philosophy motivates columnar RDBMS's like **Apache Cassandra** and **MonetDB**, both of which are SQL databases, simply with different query optimization possibilities.  **kdb+** is an older, and non-SQL, approach to a similar problem.  PostgreSQL and **MariaDB**<sup><i>mariadb</i></sup> also both have optional storage formats that use column organization.  Generally these internal optimizations are not direct concerns for data science, but Parquet requires its own non-SQL APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"mariadb\"\n",
    "     style=\"display: inline-block; margin: 0 5% 0 5%; border-style: solid; border-width: 1px\">\n",
    "    <i>mariadb</i><br/>\n",
    "MariaDB is a fork of MySQL, created by MySQL creator Monty Widenius.  It was motivated by intellectual property freedom concerns after Oracle acquired MySQL in 2009.  For the most part, the design and features are similar to those of MySQL, although some advanced features have diverged since that split.  You may be using MariaDB, in fact, even if you are unaware of doing so, since the shell tool and drivers still generally retain the name <code>mysql</code> for compatibility.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "There are a number of binary data formats that are reasonably widely used, but I do not specifically discuss in this book.  Many other formats have their own virtues, but I have attempted to limit the discussion to the handful that I feel you are *most likely* to encounter in regular work as a data scientist.  Some additional formats are listed below, with characterization mostly adapted from their respective home pages.  You can see in the descriptions which discussed formats they most resemble, and generally the identical data integrity and quality concerns apply as in the formats I discuss.  Differences are primarily in performance characteristics: how big are the files on disk, how fast can they be read and written under different scenarios, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Feather** (and **Arrow**): Feather is basically a direct serialization of the Arrow in-memory format for storage on disk with a very thin adaptor layer.\n",
    "\n",
    "> Apache Arrow is a development platform for in-memory analytics. It specifies a standardized language-independent columnar memory format for flat and hierarchical data, organized for efficient analytic operations on modern hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Apache Avro**: Avro is a data serialization system that provides rich data structures, a compact, fast, binary data format, and a container file to store persistent data.  It integrates with dynamic languages without code generation being needed (unlike in similar systems such as **Thrift** and **Protocol Buffers**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **bcolz**: As described by the project.\n",
    "\n",
    "> bcolz provides columnar, chunked data containers that can be compressed either in-memory and on-disk. Column storage allows for efficiently querying tables, as well as for cheap column addition and removal. It is based on NumPy, and uses it as the standard data container to communicate with bcolz objects, but it also comes with support for import/export facilities to/from HDF5/PyTables tables and pandas dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Zarr**: As described by the project.\n",
    "\n",
    "> Zarr provides classes and functions for working with N-dimensional arrays that behave like NumPy arrays but whose data is divided into chunks and each chunk is compressed. If you are already familiar with HDF5 then Zarr arrays provide similar functionality, but with some additional flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 and NetCDF-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a slightly convoluted history of the Hierarchical Data Format, which was begun by the National Center for Supercomputing Applications (NCSA) in 1987.  HDF4 was significantly over-engineered, and is far less widely used now.  HDF5 simplified the file structure of HDF4.  It consists of *datasets*, which are multidimensional arrays of a single data type, and *groups*, which are container structures holding datasets and other groups.  Both groups and datasets may have attributes attached to them, which are any pieces of named metadata.  What this, in effect, does is emulate a filesystem within a single file.  The nodes or \"files\" within this virtual filesystem are array objects.  Generally, a single HDF5 file will contain a variety of related data for working with the same underlying problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Network Common Data Form (NetCDF) is a library of functions for storing and retrieving array data.  The project itself is nearly as old as HDF, and is an open standard that was developed and supported by a variety of scientific agencies. As of its version 4, it supports using HDF5 as storage backend; earlier versions used some other file formats, and current NetCDF software requires continued support for those older formats.  Occasionally NetCDF-4 files do enough special things with their contents that reading them with generic HDF5 libraries is awkward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generic HDF5 files typically have an extension of `.h5`, `.hdf5`, `.hdf`, or `.he5`.  These should all represent the same binary format, and other extensions occur sometimes too. Some corresponding extensions for HDF4 also exist.  Oddly, even though NetCDF can consist of numerous underlying file formats, they all seem standardized on the `.nc` extension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tools and Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although I generally do not rely on GUI tools, in the case of viewing the fairly complex structure of HDF5, they can help.  For example, a file from NASA's Earth Science Data collection is included in this book's sample data repository.  Overall, NASA collects petabytes of Users can freely register to obtain data sets from NASA, which in aggregate is petabytes of information.  This particular HDF5/NetCDF file contains datasets for surface pressure, vertical temperature profiles, surface and vertical wind profiles, tropopause pressure, boundary layer top pressure, and surface geopotential for a 98 minute period.  In particular, some of the data is spatially 3-dimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A view of a small portion of the data using the open source viewer **[HDF Compass](https://hdf-compass.readthedocs.io/en/latest/index.html)** illustrates some of the structure.  The particular dataset viewed is one of 16 in the file.  This DELP dataset is about *pressure thickness*, and contains both an array of 32-bit values and 8 attributes describing the dataset.  You can see in the screenshot below that this particular GUI tool presents the 3rd dimension as a selection widget, and the first two dimensions in a tabular view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/HDFCompass.png\" alt=\"HDF Compass NASA data\" width=\"65%\"/>\n",
    "\n",
    "__Image: HDF Compass NASA Data__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within Python, there are two popular open source libraries for working with HDF5, **PyTables** and **h5py**.  For working with NetCDF specifically, there is a library **netcdf4-python** as well.  If you wish to read data from HDF5 files, and not to add NetCDF specific metadata, one of the general HDF5 tools is fine (h5py handles special metadata better than PyTables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTables and h5py have moderately different attitudes.  H5py stays close to HDF5 spec itself while PyTables attempts to provide a higher-level \"Pythonic\" interface.  PyTables has the advantage that its data model borrows from, and acknowledges, a library for XML access that this author wrote way back in 2000; however, that advantage may be less relevant for general readers than for me personally.  In the R world, the library **rhdf5** is available.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In libraries for working with HDF5 data, a degree of laziness is allowed when dealing with large data sets.  In the Python interfaces, data sets are virtualized NumPy arrays; importantly you can perform slice operations into these arrays, and only actually read into memory the indicated data.  You may be dealing with terabytes of underlying information, but process or modify only megabytes at a time (or at all), with efficient reading and writing from regions of on disk arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names for data files used by NASA are verbose but contain detailed indication in the names themselves of the nature of the data sets within them.  Let us open one file, and take a look at a summary of its data sets.  We will show the data set name, its dimensions, its data type, its shape, and the 'units' attribute that these all happen to have.  In general, attributes may have any names, but NASA has conventions about which to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "h5fname = ('data/earthdata/OMI-Aura_ANC-OMVFPITMET'\n",
    "           '_2020m0216t225854-o82929_v003'\n",
    "           '-2020m0217t090311.nc4')\n",
    "\n",
    "data = h5py.File(h5fname, mode='r')\n",
    "\n",
    "for name, arr in data.items():\n",
    "    print(f\"{name:6s} | {str(arr.shape):14s} | \"\n",
    "          f\"{str(arr.dtype):7s} | {arr.attrs['units'][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can lazily create a memory view into only part of one of the dataset arrays.  In the example, we have opened in read-only mode, but if we had opened using the `'r+'` or `'a'` modes we could change the file.  Use the `'w'` mode with extreme caution since it will overwrite an existing file.  If the mode allows modification on disk, calling `data.flush()` or `data.close()` will write any changes back to the HDF5 source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a view of only a small section of the 3-dimensional V dataset.  We are not particularly concerned here with understanding the domain of the data, but just demonstrating the APIs.  In particular, notice that we have used a stride in one dimension to show that the general NumPy style of complex memory views is available.  Only the data referenced is actually put into main memory while the rest stays on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 3-D block from middle of DELP array\n",
    "middle = data['V'][::500, 10:12, :3]\n",
    "middle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we modify the data in the view `middle`, it will be written back when we flush or close the handle (if not in read-only mode).  We might also use our data slice for other computations or data science purposes.  For example, perhaps such a selection acts as tensors that are input into a neural network.  In a simpler case, perhaps we simply want to find some statistics or reduction/abstraction on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Working with HDF5 files in R—or most any other language—is generally similar to doing so from Python. Let us take a look with the R library **rhdf5**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i h5fname\n",
    "library(rhdf5)\n",
    "h5ls(h5fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that the order of dimensions is transposed in R versus Python, so we have to account for that in our selection of a region of interest.  However, generally the operation of slicing in R is very similar to that in NumPy.  The function `h5save()` is used to write data that was modified back to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i h5fname\n",
    "V = h5read(h5fname, 'V')\n",
    "V[1:2, 10:12, 10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The NASA data shown does not use group hierarchies, only top-level datasets.  Let us look at a toy data collection that nests groups and datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_h5_hierarchy()  # initialize the HDF5 file\n",
    "f = h5py.File('data/hierarchy.h5', 'r+')\n",
    "dset = f['/deeply/nested/group/my_data']\n",
    "print(dset.shape, dset.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have a 4-dimensional array of integer data.  Perhaps some metadata description was attached to it as well.  Let us also view—and then modify—some section of the data since we have opened in `'r+'` mode.  After we change the data, we can write it back to disk.  We could similarly change or add attributes in a regular dictionary style; for instance:\n",
    "\n",
    "```python\n",
    "dset.attrs[mykey] = myvalue\n",
    "```\n",
    "\n",
    "Let us show a slice from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in dset.attrs.items():\n",
    "    print(key, \"→\", val)\n",
    "print()\n",
    "print(\"Data block:\\n\", dset[5, 3, 2:4, 8:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we modify the same slice of data we displayed, then close the file handle to write it back to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset[5, 3, 2:4, 8:] = np.random.randint(-99, 99, (2, 2))\n",
    "print(dset[5, 3, 2:4, 8:])\n",
    "f.close()                   # write change to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can walk the hierarchy in Python's `h5py` package, but it is somewhat manual to loop through paths.  R's `rhdf5` provides a nice utility function `h5ls()` that lets us see more of the structure of this test file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "library(rhdf5)\n",
    "h5ls('data/hierarchy.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQLite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In essence, SQLite is simply another RDBMS from the point of view of a data scientist.  For a developer or systems engineer, it has some special properties, but for readers of this book, you will get data from an SQLite file via SQL queries.  Somewhat similarly to HDF5, an SQLite file—often given extensions `.sqlite`, `.db`, or `.db3` (but not as standardized as with some file types)—can contain many tables.  In SQL, we automatically get joins and subqueries to combine data from multiple tables, whereas there is no similar standard about combining data from multiple HDF5 datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SQLite3 data format and server is extremely efficient, and queries are usually fast.  As with other SQL databases, it operates with *atomic transactions* that succeed or fail in their entirety.  This prevents a database from reaching a logically inconsistent state. However, it does not have a concurrent access model.  Or rather, it does not allow multiple simultaneous writers to a common database in the way that server-based RDBMSs do.  Many reader clients may open the same file simultaneously without difficulty; it only bogs down when many clients wish to perform write transactions.  There are ways to address this situation, but they are outside the scope of this particular book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important advantage of SQLite over other RDBMS's is that distributing the single file that makes up the database is dead simple.  With other systems, you need to add credentials, and firewall rules, and the like, to give new users access; or alternately you need to export the  needed data to another format, typically CSV, that is both slow and somewhat lossy (i.e. data types)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data typing in SQLite is something of a chimera.  There are few basic data types, which we will discuss.  However, unlike nearly every other SQL database, SQLite carries data types per value, not per column.  This would seem to run into the same fragility that was discussed around spreadsheets, but in practice it is far less of a problem than with those.  One reason the types-per-value is not as much of a concern is because of the interface used to populate them; it is highly unusual to edit individual values in SQLite interactively, and far more common to issue programmatic SQL commands to INSERT or UPDATE many rows with data from a common source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, apart from the data types, SQLite has a concept called *type affinity*.  Each column is given a preferred type that does not *prevent* other data types from occurring, but does nudge the preference toward the affinity of the column.  We can run the tool `sqlite` from the command line to get to the interactive SQLite prompt. For example (adapted from SQLite documentation):\n",
    "\n",
    "```sql\n",
    "sqlite> CREATE TABLE mytable(a SMALLINT, b VARCHAR(10), c REAL);\n",
    "sqlite> INSERT INTO mytable(a, b, c) VALUES('123', 456, 789);\n",
    "```\n",
    "\n",
    "Here a row will be inserted with an integer in the `a` column, TEXT in the `b` column, and a floating-point in the `c` column.  SQL syntax itself is loosely typed, but the underlying database makes type/casting decisions.  This is true of other RDBMS's too, but those are stricter about column data types.  So we can also run this in SQLite, which will fail with other databases:\n",
    "\n",
    "```sql\n",
    "sqlite> INSERT INTO mytable(a, b, c) VALUES('xyz', 3.14, '2.71');\n",
    "```\n",
    "\n",
    "Let us see what results:\n",
    "\n",
    "```sql\n",
    "sqlite> SELECT * FROM mytable;\n",
    "123|456|789.0\n",
    "xyz|3.14|2.71\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SQLite interactive shell does not make data types entirely obvious, but running a query in Python will do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "db = sqlite3.connect('data/affinity.sqlite')\n",
    "cur = db.cursor()\n",
    "cur.execute(\"SELECT a, b, c FROM t1\")\n",
    "for row in cur:\n",
    "    print([f\"{x.__class__.__name__} {x}\" for x in row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column `a` prefers to hold an integer if it is set with something it can interpret as an integer, but will fall back to a more general data type if required.  Likewise, column `c` prefers a float, and it can interpret either an unquoted integer or a float-like string as such."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual data types in SQLite are *exclusively* NULL, INTEGER, REAL, TEXT, and BLOB.  However, most of the type names in other SQL databases are aliases for these simple types.  We see that in the example, where `VARCHAR(10)` is an alias for `TEXT` and `SMALLINT` is an alias for `INTEGER`.  REAL values are always represented as 64-bit floating-point numbers.  Within INTEGER values, bit lengths of 1, 2, 3, 4, 6, or 8 are chosen for storage efficiency.  There is no datetime type in SQLite storage, but time-oriented SQL functions are happy to accept any of TEXT (ISO-8601 strings), REAL (days since November 24, 4714 B.C), or INTEGER (seconds since 1970-01-01T00:00:00)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall takeaway for working with SQLite databases is that possibly a little extra care is needed in double checking your data types when reading data, but for the most part you can pretend it is strongly typed per column.  Truncation, clipping, and wrap-around issues will not occur.  There is no actual decimal data type, but only aliases; for data science—versus accounting or finance—this is rarely a concern.  But usual caveats about floating-point rounding issues will apply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apache Parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Parquet format grew out of the **Hadoop** ecosystem, but at heart is simply an optimized, column-oriented file format for storing table-like data.  Parquet has a type system that focuses on numeric types.  It is not quite as simplified as SQLite, but also eschews providing every possible bit length, as NumPy or C/C++ do,  for example.  All integer types are signed. Everything that is not numeric is a byte-array that is cast for the needed purpose at the application level (i.e. not the storage format level)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having grown out of Hadoop tools, Parquet is especially well optimized for parallel computation.  A Parquet \"file\" is actually a directory containing a number of data files, with a `_metadata` file in that directory describing the layout and other details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls -x data/multicsv.parq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the file system is a parallel and distributed system such as Hadoop File System (**HDS**) that further supports computational efficiency on large data sets.  In such case, Parquet does various clever sharding of data, efficient compression (using varying strategies), optimization of contiguous reads, and has been analyzed and revised to improve its typical use cases, for both speed and storage size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the tools or libraries supporting Parquet are **Apache Hive**, **Cloudera Impala**, **Apache Pig**, and **Apache Spark**, all of which live in the parallel computation space.  However, there are available interfaces for Python and R as well (and other languages).  Many of the higher level tools address Parquet data with an SQL layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Python, the libraries **pyarrow** and **fastparquet** provide a direct interface to the file format.  While these libraries are general, they are designed primarily to translate Parquet data into data frames (usually Pandas, sometimes Dask, Vaex, or others).  Within the R world, **sparklyr** is an interface into Spark, but requires a running Spark instance (a local installation is fine).  The **arrow** package is a direct reader, similar to the Python libraries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, if you are working with genuinely big data, the Hadoop or Spark tools—accompanied by appropriate computing clusters—are a good choice.  Dask is an approach to parallelism on Python, which is very good; other approaches like MPI are available for R, Python, and many other languages.  However, Hadoop and Spark are the tools to which the most attention has been paid in regard to efficient and large scale parallel computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if you only need to worry about medium sized data (hundred of thousands to millions of rows) rather than big data (hundreds of millions to billions of rows), Parquet is still a fast format to work with.  Moreover, it has the generally desirable property of typing data by column that makes data at least one small step closer to being clean and tidy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let us read the medium sized data set we generated earlier with Dask.  Both Pandas and Dask will use either pyarrow or fastparquet, depending on what is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_parquet('data/multicsv.parq/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could distribute the below read using `dask.dataframe` and just the same syntax, i.e. `dd.read_parquet(...)`.  For large data sets the this could keep the inactive segments out of core and distribute work over all the cores on the local machine.  However, for medium to small data like this, Pandas is faster in avoiding the coordination overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we have utilized the concept of data frames already, using both Python with Pandas and R with tibbles, it is worth looking at just what the underlying abstraction consists of.  We will briefly look at a number of different data frame implementations in varying programming languages to understand what they have in common (with is a lot)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Whenever you set out to do something, something else must be done first.<br/>—Murphy's (First) Corollary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concepts**:\n",
    "\n",
    "* Filter/transform/group/aggregate\n",
    "* Spark data frames\n",
    "* Pandas and derivatives\n",
    "* Other Python data frames\n",
    "* R Tidyverse\n",
    "* R data.tables\n",
    "* The Unix philosophy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A large number of libraries across almost as many programming languages support the data frame abstraction.  Most data scientists find this abstraction to be powerful, and even their preferred way of processing data.  Data frames allow an easy expression of many of the same fundamental concepts or operations as does SQL, but within the particular programming language and memory space of the rest of their program.  SQL—even when it actually addresses a purely local database such as SQLite—is always more of a \"remote fetch\" than interactive exploration that data frames allow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These operations consist, in the main, of filtering, grouping, aggregation, sorting, and vectorized function application.  Generally, all data frame libraries allow for a \"fluent\" programming style that chains together these operations in some order to produce a final result; that final (or at least working) result is usually itself either a data frame or a scalar value.  Sometimes a visualization is relevant for such a processed result, and most data frame tools integrate seamlessly with visualization libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal, of course, of these fluent chained operations is to describe a reproducible work flow.  Exploration of various data modifications can be built up step by step, with intermediate results often providing hints that you might have gone wrong or a degree of reassurance that your path is correct.  At the end of that exploration, you will have an expression of a composite transformation of data that can be reused with new data from the domain and problem you are addressing.  Comments in code and accompanying these chains, or pipelines, always make life easier for both you and other readers of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those libraries that are distributed and/or out-of-core allow working with large data sets rather seamlessly.  Which is to say that the data frame abstraction scales almost unboundedly, even if particular libraries have some rough limits.  In this section, I will present similar code using a number of data frame libraries, commenting briefly on the strengths, weaknesses, and differences among them.  This book generally utilizes Python with Pandas, and to a somewhat lesser extent R with tibbles.  We will see the conceptual and usage similarity of those libraries with other libraries in Python/R (Vaex, data.table), and even with other programming languages such as Scala/Spark or bash with **coreutils**.  Many data scientists use Spark, in particular; whatever specific tools you use, the concepts throughout should translate easily, especially where data frame approaches are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the code in this book will use Pandas.  Python is, as of this writing, the most widely used language for data science, and Pandas is, by a large margin, its most widely used data frame library.  In fact, several of the \"competing\" libraries themselves utilize Pandas as an internal component.  However, in this section, I would like to illustrate and emphasize how similar all of these libraries are.  For that purpose, I am going to perform the same task using a number of these libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a great many operations and pipelines, many quite complex, that can be accomplished with data frames.  This brief section is not a tutorial on any of the specific libraries, but only a glimpse into the shared style of expressing data manipulation and the smaller differences among the different tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With each data frame library, we will do the following:\n",
    "\n",
    "1. Filter based on a comparison of two columns, `x` and `y`\n",
    "2. Vectorize derived value from one column of the comparison, `y`\n",
    "3. Group data having common value in another column, `name`\n",
    "4. Aggregate data in a grouped column, `x`\n",
    "5. Sort data based on a computed column, `Mean_x`\n",
    "6. For illustration, display the first 5 rows of result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark/Scala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a starting point, I would like to illustrate a pipeline of steps using the distributed computing framework, Spark, and its native programming language, Scala.  Bindings into Spark from Python, R, and other languages also exist, but incur a certain degree of translation overhead that slow operations.  This pipeline takes the sample Dask data set shown in other examples in this chapter, and performs all of the basic operations mentioned on the data set.<sup><i>setup</i></sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"setup\"\n",
    "     style=\"display: inline-block; margin: 0 5% 0 5%; border-style: solid; border-width: 1px\">\n",
    "    <i>setup</i><br/>\n",
    "Configuring and replicating the environment used by this book for the Python and R code is described in the accompanying repository.  However, configuring Hadoop and Spark are separate steps that are not quite so easy to encapsulate in a few configuration files.  The steps are not <i>difficult</i>, but you will need to follow the official documentation accompanying these tools, or other tutorials available online.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few lines were run inside the Spark shell.  For composition of this book, a local instance of Hadoop and Spark were running, but this could as easily be a connection to a remote cluster.  Upon launch you will see something similar to this:\n",
    "\n",
    "```\n",
    "Spark context Web UI available at http://popkdm:4040\n",
    "Spark context available as 'sc' (master = local[*], app id = local-1582775303458).\n",
    "Spark session available as 'spark'.\n",
    "Welcome to\n",
    "      ____              __\n",
    "     / __/__  ___ _____/ /__\n",
    "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
    "   /___/ .__/\\_,_/_/ /_/\\_\\   version 2.4.5\n",
    "      /_/\n",
    "\n",
    "Using Scala version 2.11.12 (OpenJDK 64-Bit Server VM, Java 11.0.6)\n",
    "Type in expressions to have them evaluated.\n",
    "Type :help for more information.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the shell, we can read in the collection of CSV files in a common directory.  Many other data sources are likewise available under a similar interface.  We allow inference of data types and use of the column headers to name fields.  The pipe symbols (`|`) are simply part of the Spark shell interface to indicate a continuation line; they are not themselves the Scala code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```scala\n",
    "scala> val df = spark.read.       // Local file or Hadoop resource\n",
    "     |     options(Map(\"inferSchema\"->\"true\",\"header\"->\"true\")).\n",
    "     |     csv(\"data/multicsv/\")  // Directory of multiple CSVs\n",
    "df: org.apache.spark.sql.DataFrame = [\n",
    "    timestamp: timestamp, id: int ... 3 more fields]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fluent code below simply performs the intended steps in order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "scala> df.  // Working with loaded DataFrame\n",
    "     | filter($\"x\" > ($\"y\" + 1)).  // x more than y+1 (per row)\n",
    "     | groupBy($\"name\").           // group together same name\n",
    "     | agg(avg($\"x\") as \"Mean_x\"). // mean within each group\n",
    "     | sort($\"Mean_x\").            // order data by new column\n",
    "     | show(5)\n",
    "     \n",
    "+------+------------------+\n",
    "|  name|            Mean_x|\n",
    "+------+------------------+\n",
    "|   Ray|0.6625697073245446|\n",
    "|Ursula|0.6628107271270461|\n",
    "|Xavier|0.6641165295855926|\n",
    "| Wendy|0.6642381725604264|\n",
    "| Kevin| 0.664836301676443|\n",
    "+------+------------------+\n",
    "only showing top 5 rows\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas and Derived Wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of libraries either emulate the Pandas API or directly utilize it as a dependency.  Dask and **Modin** both directly wrap Pandas, and partition one native DataFrame into many separate Pandas DataFrames.  A method on the native DataFrame is usually dispatched to the underlying corresponding Pandas method per-DataFrame.  Although Modin can use either Dask or **Ray** as its parallel/cluster execution back-end, Modin differs from Dask in being *eager* in its execution model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask is a general purpose execution back-end, with its `dask.dataframe` subpackage being only one component.  Much of what Dask does is similar to the library Ray, which Modin may also use if desired (benchmarks as of this writing mildly favor Ray, depending on use-case).  Most Pandas API method calls in Dask initially only build a directed-acyclic graph (DAG) of the required operations.  Computation is only performed when the `.compute()` method of a built DAG is called.  The example below uses Dask, but it would look exactly the same with Modin except for the final `.compute()` and an initial `import modin.pandas as pd`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cuDF** is another library that follows Pandas' API very closely, but it executes methods on CUDA GPUs.  Since the underlying execution is on an entirely different kind of chip architecture, cuDF does not share code with Pandas, nor wrap Pandas.  But almost all API calls will be identical, but often vastly faster if you have a recent CUDA GPU on your system.  Like Pandas and Modin, cuDF is eager in its execution model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "dfd = dd.read_csv('data/multicsv/*.csv', parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operations in the Pandas style below look very similar to those in Spark.  The accessor `.loc` overloads several selection styles, but a predicate filter is such a permitted one.  Another is used on the same line to select columns, i.e. a sequence of names.  Grouping is nearly identical, other than the capitalization of the method name.  Pandas even has an `.agg()` method to which we could pass a mean function or the string `'mean'`; we just chose the shortcut.  Columns are not automatically renamed in aggregation, so we do that to match more precisely.  Instead of sorting and showing, we take the 5 smallest in a single method.  In effect, the conceptual elements are identical, and spelling varies only mildly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dfd\n",
    "   .loc[dfd.x > dfd.y+1,            # Row predicate\n",
    "        ['name', 'x']]              # Column list\n",
    "   .groupby(\"name\")                 # Grouping column(s)\n",
    "   .mean()                          # Aggregation\n",
    "   .rename(columns={'x': 'Mean_x'}) # Naming\n",
    "   .nsmallest(5, 'Mean_x')          # Selection by order\n",
    ").compute()                         # Concretize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vaex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaex is a Python library completely independent of Pandas, but that uses a largely similar API.  A fair amount of code will just work identically with either style of data frame, but enough will not that you cannot simply drop in one for the other.  The philosophy of Vaex is somewhat different from Pandas.  On the one hand, Vaex emphasizes lazy computation and implicit parallelism; expressions are eagerly evaluated, but with attention to not touching those portions of data that are not needed for a given operation.  This goes hand-in-hand with the mostly out-of-core operation.  Rather than read data into memory, Vaex memory maps the data on disk, only loading those parts required for an operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaex consistently avoids making data copies, in effect expressing selections as views.  It has a concept of *expressions* and of *virtual columns*.  For example, a computation on several columns, even if assigned to a new column, does not use any significant new memory since only the functional form is stored rather than the data.  Only when that data is needed is the computation performed, and only for those rows affected.  The overall result is that Vaex can be very fast on large data sets; however, Vaex parallelizes only over multiple cores on one machine, not over clusters of machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of its memory-mapped approach, Vaex does not really want to deal directly with CSV files internally.  Unlike serialized Feather or HDF5, which put each datum at a predictable location on disk, CSV is inherently ragged in layout on disk.  While a `.read_csv()` method will read a single file into memory, for working with a family of CSVs in a directory, you will want to convert them to a corresponding family of HDF5 files.  Fortunately, the method `.read_csv_and_convert()` does this automatically for you.  The result is that the first time you read such a collection, the conversion takes a while, but subsequent opens utilize the existing HDF5 files and open instantly (no actual read into memory, just memory maps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vaex\n",
    "dfv = vaex.read_csv_and_convert('data/multicsv/*.csv', copy_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaex.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another difference from Pandas is that Vaex data frames are *tidy* (as described at the start of this chapter).  Many operations on Pandas rely on their row index, which might even be a hierarchical index comprising multiple nested columns.  The \"index,\" such as it is, in Vaex is simply the row number.  You can do filtering, and grouping, and sorting, and so on, but always based on regular columns.  This philosophy is shared with tibble and data.table in R, both of which reject that aspect of the older data.frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "dfv\n",
    "   [dfv.x > dfv.y + 1]  # Predicate selection of rows\n",
    "   [['name', 'x']]      # List selection of columns\n",
    "   .groupby('name')     # Grouping\n",
    "   .agg({'x': 'mean'})  # Aggregation\n",
    "   .sort('x')           # Sort (Vaex does not have .nsmallest() method)\n",
    "   .head(5)             # First 5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us remove those temporary HDF5 files for discussion of libraries other than Vaex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -f data/multicsv/*.hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now turn to analogous data frame options within R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Frames in R (Tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Tidyverse, tibbles are the preferred data frame objects, and **dplyr** is an associated library for—often chained—pipelined data manipulations.  The way that dplyr achieves a fluent style is not based on chained method calls. Indeed, object-oriented programming is rarely used in R in general.  Instead, dplyr relies on the \"pipe\" operator (`%>%`) which treats the result of the prior expression as the first argument to the next function called.  This allows for rewriting compact but deeply nested expressions, such as the following:\n",
    "\n",
    "```R\n",
    "round(exp(diff(log(x))), 1)\n",
    "```\n",
    "\n",
    "In fluent style this becomes:\n",
    "\n",
    "```R\n",
    "x %>% \n",
    "  log() %>%\n",
    "  diff() %>%\n",
    "  exp() %>%\n",
    "  round(1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we can read in the collection of CSV files that was generated earlier.  The 2.5 million total rows in this data are still medium sized data, but the patterns in the below code could be applied to big data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "files <- dir(path = \"data/multicsv/\", pattern = \"*.csv\", full.names = TRUE)\n",
    "read_csv_quiet <- function(file) { \n",
    "    read_csv(file, col_types = cols(\"T\", \"n\", \"f\", \"n\", \"n\"), progress = FALSE) }\n",
    "\n",
    "data <- files   %>%\n",
    "  # read_csv() on each file, reduce to one DF with rbind\n",
    "  map(read_csv_quiet) %>%  \n",
    "  # If this were genuinely large data, we would process each file individually\n",
    "  reduce(rbind)  \n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dplyr pipes into functions that filter, modify, group, and aggregate data look nearly identical to the chained methods used in other data frame libraries.  A few function names are slightly different than in other libraries, but the steps performed are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "info <- capture.output( \n",
    "# --- hide nonsense on STDERR\n",
    "summary <- data   %>% \n",
    "  filter(x > y+1) %>%   # Predicate selection of rows\n",
    "  select(name, x) %>%   # Selection of columns\n",
    "  group_by(name)  %>%   # Grouping\n",
    "                        # Aggregation and naming\n",
    "  summarize(Mean_x = mean(x)) %>% \n",
    "  arrange(Mean_x) %>%   # Sort data\n",
    "  head(5)               # First 5\n",
    "# --- end of block for capture.output\n",
    ",type = \"message\")   \n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Frames in R (data.table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outside the Tidyverse, the main approach to working with tabular data in modern R is data.table.  This is a replacement for the older, but standard, R data.frame.  I do not separately discuss data.frame in this book since new code should always prefer either tibbles or data.tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike most other approaches to data frames, data.table does not use a fluent or chained style.  Instead, it uses an extremely compact *general form* of `DT[i, j, by]` that captures a great many of the manipulations possible.  Not every collection of operation can be expressed in a single general form, but a great many of them can.  Moreover, because data.table is able to optimize over the entire general form, it can often be significantly faster on large data sets than those libraries performing operations in a sequenced manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element of the general form may be omitted to mean \"everything.\"  If used, the `i` is an expression describing the rows of interest; often this `i` will consist of several clauses joined by logic connectors `&` (and), `|` (or), and `!` (not).  Row ordering may also be imposed within this expression (but not on derived columns).  For example:\n",
    "\n",
    "```R\n",
    "dt[(id > 999 | date > '2020-03-01') & !(name == \"Lee\")]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column selector `j` can refer to columns, including derived columns.\n",
    "\n",
    "\n",
    "```R\n",
    "dt[ , .(id, pay_level = round(log(salary), 1)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the `by` form is a grouping description that allows for calculations per row subset.  Groups can follow either categorical values or computed cuts.\n",
    "\n",
    "```R\n",
    "dt[, mean(salary), cut(age, quantile(age, seq(0,100,10)))]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting those forms together, we can produce the same summary as with other data frame libraries.  However, the final ordering has to be performed as a second step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "info <- capture.output( \n",
    "# --- hide nonsense on STDERR\n",
    "library(data.table)\n",
    "# --- end of block for capture.output\n",
    ",type = \"message\")   \n",
    "\n",
    "dt <- data.table(data)\n",
    "summary <- dt[\n",
    "    i = x > y + 1,      # Predicate selection of rows\n",
    "                        # Aggregation and naming\n",
    "    j = .(Mean_x = mean(x)), \n",
    "    by = .(name)]       # Grouping\n",
    "\n",
    "# Sort data and first 5\n",
    "summary[order(Mean_x), .SD[1:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bash for Fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For readers who are accustomed to performing pipelined filtering and aggregation at the command line, the piped or fluent style used by data frames will seem very familiar.  In fact, it is not difficult to replicate our example using command-line tools.  The heavy lifter here is **awk**, but the code it uses is very simple.  Conceptually, these steps exactly match those we used in data frame libraries.  The small tools that combine, using pipes, under the Unix philosophy, can naturally replicate the same basic operations used in data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "COND='{if ($4 > $5+1) print}'\n",
    "SHOW='{for(j in count) print j,sum[j]/count[j]}'\n",
    "AGG='{ count[$1]++; sum[$1]+=$2 }'\" END $SHOW\"\n",
    "\n",
    "cat data/multicsv/*.csv | # Create the \"data frame\"\n",
    "  grep -v ^timestamp    | # Remove the headers\n",
    "  awk -F, \"$COND\"       | # Predicate selection\n",
    "  cut -d, -f3,4         | # Select columns\n",
    "  awk -F, \"$AGG\"        | # Aggregate by group\n",
    "  sort -k2              | # Sort data\n",
    "  head -5                 # First 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeroen Janssens wrote a delightful book entitled <u>[Data Science at the Command Line](https://www.datascienceatthecommandline.com/)</u> that is both wonderfully written and freely available online.  You should also buy the printed or ebook edition to support his work.  In this subsection, and at various places in this book, I make only small gestures in the direction of the types of techniques that book talks about in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data frame and fluent programming style is a powerful idiom, and is especially widely used in data science.  Every one of the specific libraries I discuss are excellent choices with equivalent power.  Which fits you best is largely a matter of taste, and perhaps of what your colleagues use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Putting together much of what we have learned in this chapter, the below exercises should allow you to utilize the techniques and idioms you have read about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidy Data from Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Excel spreadsheet with some brief information on awards given to movies is available at:\n",
    "\n",
    "> https://www.gnosis.cx/cleaning/Film_Awards.xlsx\n",
    "\n",
    "In a more fleshed out case, we might have data for many more years, more types of awards, more associations that grant awards, and so on.  While the organization of this spreadsheet is much like a great many you will encounter \"in the wild,\" it is very little like the tidy data we would rather work with.  In the simple example, only 63 data values occur, and you could probably enter them into the desired structure by hand as quickly as coding the transformations.  However, the point of this exercise is to write programming code that could generalize to larger data sets of similar structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/Film_Awards.png\" alt=\"Film Awards\"/>\n",
    "\n",
    "__Image: Film Awards Spreadsheet__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task in this exercise is to read this data into a single well-normalized data frame, using whichever language and library you are most comfortable with.  Along the way, you will need to remediate whatever data integrity problems you detect.  As examples of issues to look out for:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The film _1917_ was stored as a number not a string when naïvely entered into a cell.\n",
    "* The spelling of some values is inconsistent.  Olivia Colman's name is incorrectly transcribed as 'Coleman' in one occurrence.  There is a spacing issue in one value you will need to identify.\n",
    "* Structurally, an apparent parallel is not really so.  Person names are sometimes listed under the name of the association, but elsewhere under another column.  Film names are sometimes listed under association, other times elsewhere.\n",
    "* Some column names occur multiple times in the same tabular area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In thinking about a good data frame organization, think of what the independent and dependent variables are.  In each year, each association awards for each category. These are independent dimensions.  A person name and a film name are slightly tricky since they are not exactly independent, but at the same time some awards are to a film and others to a person.  Moreover, one actor might appear in multiple films in a year (not in this sample data; but do not rule it out).  Likewise, at times multiple films have used the same name at times in film history. Some persons are both director and actor (in either the same or different films)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have a useful data frame, use it to answer these questions in summary reports:\n",
    "\n",
    "* For each film involved in multiple awards, list the award and year it is associated with.\n",
    "* For each actor/actress winning multiple awards, list the film and award they are associated with.\n",
    "* While not occurring in this small data set, sometimes actors/actresses win awards for multiple films (usually in different years).  Make sure your code will handle that situation.\n",
    "* It is manual work, but you may want to research and add awards given in other years; in particular, adding some data will show actors with awards for multiple films.  Do your other reports correctly summarize the larger data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidy Data from SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An SQLite database with roughly the same brief information as in the prior spreadsheet is available at:\n",
    "\n",
    "> https://www.gnosis.cx/cleaning/Film_Awards.sqlite\n",
    "\n",
    "However, the information in the database version is relatively well normalized and typed.  Also, additional information has been included on a variety of entities included in the spreadsheet.  Only slightly more information is included in this schema than in the spreadsheet, but it should be able to accommodate a large amount of data on films, actors, directors, and awards, and the relationships among those data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> .tables\n",
    "actor     award     director  org_name\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As was mentioned in the prior exercise, the same name for a film can be used more than once, even by the same director.  For example  Abel Gance, used the title _J'accuse!_ for both his 1919 and 1938 films with connected subject matter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "sqlite> SELECT * FROM director WHERE year < 1950;\n",
    "Abel Gance|J'accuse!|1919\n",
    "Abel Gance|J'accuse!|1938\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at a selection from the `actor` table, for example.  In this table we have a column `gender` to differentiate beyond name. As of this writing, no transgender actor has been nominated for a major award both before and after a change in gender identity, but this schema allows for that possibility.  In any case, we can use this field to differentiate the \"actor\" versus \"actress\" awards that many organizations grant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> .schema actor\n",
    "CREATE TABLE actor (name TEXT, film TEXT, year INTEGER, gender CHAR(1));\n",
    "\n",
    "sqlite> SELECT * FROM actor WHERE name=\"Joaquin Phoenix\";\n",
    "Joaquin Phoenix|Joker|2019|M\n",
    "Joaquin Phoenix|Walk the Line|2006|M\n",
    "Joaquin Phoenix|Hotel Rwanda|2004|M\n",
    "Joaquin Phoenix|Her|2013|M\n",
    "Joaquin Phoenix|The Master|2013|M\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal in this exercise is to create the same tidy data frame that you created in the prior exercise, and answer the same questions that were asked there.  If some questions can be answered directly with SQL, feel free to take that approach instead.  For this exercise, only consider awards for the years 2017, 2018, and 2019.  Some others are included in an incomplete way, but your reports are for those years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "sqlite> SELECT * FROM award WHERE winner=\"Frances McDormand\";\n",
    "Oscar|Best Actress|2017|Frances McDormand\n",
    "GG|Actress/Drama|2017|Frances McDormand\n",
    "Oscar|Best Actress|1997|Frances McDormand\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denouement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> All models are wrong, but some models are useful.<br/>–George Box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topics**: Delimited Files; Spreadsheet Dangers; RDBMS; HDF5; Data Frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter introduced the data formats that make up the large majority of all the structured data in the world.  While I do not have hard data, exactly, on this breakdown of data volume—nor can anyone, apart perhaps, from some three letter agencies specializing in bulk data acquisition—I still feel like it is a safe assertion.  Between all the scientific data stored in HDF5 and related formats, all the business data stored in spreadsheets, all the transactional data stored in SQL databases, and everything exported from almost everywhere to CSV, this makes up almost everything a working data scientist encounters on a regular basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In presenting formats, we addressed the currently leading tools for ingestion of those data sources in several languages.  The focus throughout this book will remain on Python and R, which are the main programming languages for data science.  Perhaps that will change in the future, and almost certainly some new libraries will arise for addressing this huge bulk of data in faster and more convenient ways.  Even so, most of the conceptual issues about the strengths and limits of formats—concerns largely about data types and storage artifacts—will remain for those new languages and libraries.  Only spelling will change mildly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An extended, but nonetheless dramatically incomplete, discussion looked at the data frame abstraction used in a great many tools.  Here again, new variations may arise, but I am confident that the general abstraction will be the primary one used in data science for several decades after this writing.  In presenting a number of slightly different libraries, I have only scratched the surface of any one of them.  In fact, even if this entire chapter was about just one of the mentioned libraries, it would be incomplete compared with those excellent books that spend their whole length discussing one particular data frame library.  Nonetheless, I hope that this introduction to thinking about data processing problems in terms of the steps of filtering, grouping, aggregation, naming, and ordering will serve readers well in their articulation of many ingestion tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One limit of the data frame abstraction that we used in reading all the formats discussed in this chapter is that none look at data streaming in any meaningful way.  For the most part, data science needs are not streaming needs, but occasionally they overlap.  If your needs lie at that particular edge, check the documentation for streaming protocols like **ActiveMQ**, **RabbitMQ**, and **Kafka** (among others); but your concern will not chiefly be in the data formats themselves, but rather in event processing, and in evolving detection of anomalies and bad data, such as is discussed in later chapters 4 and 5, and perhaps value imputation, discussed in chapter 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next chapter we turn to data formats that are hierarchically organized rather than tabular."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
