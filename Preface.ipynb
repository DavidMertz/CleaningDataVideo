{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Cleaning Data\n",
    "\n",
    "_In order for something to become clean, something else must become dirty._ \n",
    "\n",
    "Imbesi's Law of the Conservation of Filth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "A speaker at a data science conference a few years ago made a joke—perhaps one already widely repeated by the time he told it—about talking with a colleague of his.  The colleague complained of data cleaning taking up half of her time, in response to which the speaker expressed astonishment that it could be so little as 50%.\n",
    "\n",
    "Without worrying too much about assigning a precise percentage, in my experience working as a technologist and data scientist, I have found that the bulk of what I do is preparing my data for the statistical analyses, machine learning models, or nuanced visualizations that I would like to utilize it for.  Although hopeful executives, or technical managers a bit removed from the daily work, tend to have an eternal optimism that the next set of data the organization acquires will be clean and easy to work with, I have yet to find that to be true in my concrete experience.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Doing the Other 80% of the Work\n",
    "\n",
    "It is something of a truism in data science, data analysis, or machine learning that most of the effort needed to achieve your actual purpose lies in cleaning your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "Certainly, some data is better and some is worse.  But *all data is dirty*, at least within a very small margin of error in the tally.  Even data sets that have been published, carefully studied, and that are widely distributed as canonical examples for statistics textbooks or software libraries, generally have a moderate number of data integrity problems.  Even after our best pre-processing, a more attainable goal should be to make our data *less dirty*; making it *clean* remains unduly utopian in aspiration.\n",
    "\n",
    "By all means we should distinguish *data quality* from *data utility*.  These descriptions are roughly orthogonal to each other.  Data can be dirty (up to a point) but still be enormously useful.  Data can be (relatively) clean but have little purpose, or at least not be fit for purpose.  Concerns about the choice of measurements to collect, or about possible selection bias, or other methodological or scientific questions are mostly outside the scope of this book.  However, a fair number of techniques I present can *aid* in evaluating the utility of data, but there is often no mechanical method of remedying systemic issues.  For example, statistics and other analyses may reveal—or at least strongly suggest—the unreliability of a certain data field.  But the techniques in this book cannot generally automatically fix that unreliable data or collect better data.\n",
    "\n",
    "The code shown throughout this book is freely available.  However, the purpose of this book is not learning to use the particular tools used for illustration, but to understand the underlying purpose of data quality.  The concepts presented should be applicable in any programming language used for data processing and machine learning.  I hope it will be easy to adapt the techniques I show to your own favorite collection of tools and programming languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Types of Grime\n",
    "\n",
    "There are two kinds of problems in data sets\n",
    "* Structural problems in the formatting of data\n",
    "* content problems in the actual values recorded."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "A format might \"record values in the wrong place or of the wrong type.\"  Sometimes well formatted data is implausible or wrong because of flawed instruments, transcription errors, numeric overflows, or via other pitfalls.\n",
    "\n",
    "The first lessons discussing \"data ingestion\" are more focused on structural problems.  It is not always cleanly possible to separate these issues, but we begin with an emphasis on format problems. In later lessons, we look at anomalies, data quality, feature engineering, value imputation, and model-based cleaning to direct attention to content issues.\n",
    "\n",
    "In the case of structural problems, we almost always need manual remediation of the data.  Exactly where the bytes that make up the data go wrong can vary enormously, and usually does not follow a pattern that lends itself to a single high-level description.  Often we have a somewhat easier time with the content problems, but at the same time they are more likely to be irremediable even with manual work.\n",
    "\n",
    "Consider a small raw data set about a school class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Student#,Last Name,First Name,Favorite Color,Age\n",
      "1,Johnson,Mia,periwinkle,12\n",
      "2,Lopez,Liam,blue,green,13\n",
      "3,Lee,Isabella,,11\n",
      "4,Fisher,Mason,gray,-1\n",
      "5,Gupta,Olivia,9,102\n",
      "6,,Robinson,,Sophia,,blue,,12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.intro_students import data, cleaned\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "In a friendly way, we have a header line that indicates reasonable field names and provides a hint as to the meaning of each column.  Programmatically, we may not wish to work with the punctuation marks and spaces inside some field names, but that is a matter of tool convenience that we can address with the APIs that data processing tools give us.\n",
    "\n",
    "Let us think about each record in turn.  Mia Johnson, student 1, seems to have a problem-free record.  Her row has five values separated by four commas, and each data value meets our intuitive expectations about the data type and value domain.  The problems start hereafter.\n",
    "\n",
    "Liam Lopez has too many fields in his row.  However, both columns 4 and 5 seem clearly to be in the lexicon of color names.  Perhaps a duplicate entry occurred or the compound color \"blue-green\" was intended.  Structurally the row has issues, but several plausible remediations suggest themselves.\n",
    "\n",
    "Isabella Lee is perhaps no problem at all.  One of her fields is empty, meaning no favorite color is available.  But structurally, this row is perfectly fine for CSV format.  We will need to use some domain or problem knowledge to decide how to handle the missing value.\n",
    "\n",
    "Mason Fisher is perhaps similar to Isabella.  The recorded age of -1 makes no sense in the nature of \"age\" as a data field, at least as we usually understand it (but maybe the encoding intends something different).  On the other hand, -1 is one of several placeholder values used very commonly to represent missing data.  We need to know our specific problem to know whether we can process the data with a missing age, but many times we can handle that.  However, we still need to be careful not to treat the -1 as a plain value; for example, the mean, minimum, or standard deviation of ages might be thrown off by that.\n",
    "\n",
    "Olivia Gupta starts to present a trickier problem.  Structurally her row looks perfect.  But '9' is probably not a string in our lexicon of color names.  And under our understanding of the data concerning a 6th grade class, we don't expect 102 year old students to be in it.  To solve this row, we really need to know more about the collection procedure and the intention of the data.  Perhaps a separate mapping of numbers to colors exists somewhere.  Perhaps an age of 12 was mistranscribed as 102; but also perhaps a 102 year old serves as a teaching assistant in this class and not only students are recorded.\n",
    "\n",
    "Sophia Robinson returns us to what looks like an obvious structural error.  The row, upon visual inspection, contains perfectly good and plausible values, but they are separated by duplicate commas.  Somehow, persumably, a mechanical error resulted in the line being formatted wrongly.  However, most high-level tools are likely to choke on the row in an uninformative way, and we will probably need to remediate the issue more manually.\n",
    "\n",
    "We have a pretty good idea what to do with these six rows of data, and even re-entering them from scratch would not be difficult.  If we had a million rows instead, the difficulty would grow greatly, and would require considerable effort before we arrived at usable data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Nomenclature\n",
    "\n",
    "```\n",
    "| Field-like  | Record-like \n",
    "|-------------|-------------\n",
    "| Feature     | Row\n",
    "| Measurement | Observation\n",
    "| Column      | Sample\n",
    "| Field       | Record\n",
    "| Variable    |\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "In this course the terms *feature*, *field*, *measurement*, *column*, and occasionally *variable* amore-or-less interchangeably.  Likewise, the terms *row*, *record*, *observation*, and *sample* are also near synonyms.  *Tuple* is used for the same concept when discussing databases (especially academically). In different academic or business fields, different ones of these terms are more prominent; and likewise different software tools choose among these. \n",
    "\n",
    "Conceptually, most data can be thought of as a number of occasions on which we measure various attributes of a common underlying *thing*.  In most tools, it is usually convenient to put these observations/samples each in a row; and correspondingly to store each of the measurements/features/fields pertaining to that thing in a column containing corresponding data for other comparable *things*.\n",
    "\n",
    "Inasmuch as I vary the use of these roughly equivalent terms, it is simply better to fit with the domain under discussion and to make readers familiar with all the terms, which they are likely to encounter in various places for a similar intention.  The choice among near synonyms is also guided by the predominant use within the particular tool, library, or programming community that is currently being discussed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "There are many tools which you are fairly likely to encounter during your work. It is valuable for readers to understand the general role of tools they may require in their specific tasks.  When mentioning tools, I try to provide a general conceptual framework for what *kind* of thing that tool is, but you certainly do not need to be familiar with most of the tools mentioned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Visual Rendering\n",
    "\n",
    "Data is often presented with the Polars or Pandas DataFrame libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.13.0 (main, Oct 16 2024, 03:23:02) [Clang 18.1.8 ]\n",
      "Polars 1.16.0\n",
      "Pandas 2.2.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "print(\"Python\", sys.version)\n",
    "print(\"Polars\", pl.__version__)\n",
    "print(\"Pandas\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "Visualizing a particular data set might look like the table shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (6, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Student_No</th><th>Last_Name</th><th>First_Name</th><th>Favorite_Color</th><th>Age</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;Johnson&quot;</td><td>&quot;Mia&quot;</td><td>&quot;periwinkle&quot;</td><td>&quot;12&quot;</td></tr><tr><td>2</td><td>&quot;Lopez&quot;</td><td>&quot;Liam&quot;</td><td>&quot;blue-green&quot;</td><td>&quot;13&quot;</td></tr><tr><td>3</td><td>&quot;Lee&quot;</td><td>&quot;Isabella&quot;</td><td>&quot;&lt;missing&gt;&quot;</td><td>&quot;11&quot;</td></tr><tr><td>4</td><td>&quot;Fisher&quot;</td><td>&quot;Mason&quot;</td><td>&quot;gray&quot;</td><td>&quot;N/A&quot;</td></tr><tr><td>5</td><td>&quot;Gupta&quot;</td><td>&quot;Olivia&quot;</td><td>&quot;sepia&quot;</td><td>&quot;N/A&quot;</td></tr><tr><td>6</td><td>&quot;Robinson&quot;</td><td>&quot;Sophia&quot;</td><td>&quot;blue&quot;</td><td>&quot;12&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (6, 5)\n",
       "┌────────────┬───────────┬────────────┬────────────────┬─────┐\n",
       "│ Student_No ┆ Last_Name ┆ First_Name ┆ Favorite_Color ┆ Age │\n",
       "│ ---        ┆ ---       ┆ ---        ┆ ---            ┆ --- │\n",
       "│ i64        ┆ str       ┆ str        ┆ str            ┆ str │\n",
       "╞════════════╪═══════════╪════════════╪════════════════╪═════╡\n",
       "│ 1          ┆ Johnson   ┆ Mia        ┆ periwinkle     ┆ 12  │\n",
       "│ 2          ┆ Lopez     ┆ Liam       ┆ blue-green     ┆ 13  │\n",
       "│ 3          ┆ Lee       ┆ Isabella   ┆ <missing>      ┆ 11  │\n",
       "│ 4          ┆ Fisher    ┆ Mason      ┆ gray           ┆ N/A │\n",
       "│ 5          ┆ Gupta     ┆ Olivia     ┆ sepia          ┆ N/A │\n",
       "│ 6          ┆ Robinson  ┆ Sophia     ┆ blue           ┆ 12  │\n",
       "└────────────┴───────────┴────────────┴────────────────┴─────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "The data sets and supporting materials for this book are available for download. These extra materials will allow you to try out variations on the code shown and discussed, perhaps using different libraries or programming languages.\n",
    "\n",
    "Throughout this course I am *strongly opinionated* about a number of technical questions.  I do not believe it will be difficult to distinguish my opinions from the *mere facts* I also present.  I have worked in this area for a number of years, and I hope to share with readers the conclusions I have reached.  If you disagree with claims I make, I hope you will benefit both from what you learn anew and what you are able to reformulate in strengthening your own opinions and conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "* <a href=\"https://greenteapress.com/thinkstats2/thinkstats2.pdf\"><u>Think Stats: Exploratory Data Analysis in Python</u></a>, Allen B. Downey, 2014 (O'Reilly Media; available both in free PDF and HTML versions, and as a printed book).\n",
    "* <u>All of Statistics: A Concise Course in Statistical Inference</u>, Larry Wasserman, 2004 (Springer).\n",
    "* <a href=\"https://socviz.co/index.html\"><u>Data Visualization: A practical introduction</u></a>, Kieran Healy, 2018 (Princeton University Press; a non-final draft is available free online).\n",
    "* <a href=\"https://www.edwardtufte.com/tufte/books_be\"><u>The Visual Display of Quantitative Information</u></a>, Edward Tufte, 2001 (Graphics Press; all four of Tufte's visualization books are canonical in the field)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "This course does not use mathematics and statistics heavily, but the references shown are worth exploring.  We also do not focused on the *ethics of data visualization*, but I have tried to be conscientious in using plots, which I use throughout the text.  Some good texts considering these issues are listed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Data Hygiene\n",
    "\n",
    "If a data set is of moderate size, versioning within program flow is a good choice.\n",
    "\n",
    "```python\n",
    "data1 = read_format(raw_data)\n",
    "data2 = transformation_1(data1)\n",
    "data3 = transformation_2(data2)\n",
    "# ... etc ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "When you use any version, anywhere else in a large program, it is clear from the variable name (or lookup key, etc.) which version is involved, and problems can be more easily diagnosed.\n",
    "\n",
    "It is crucial to good practice of data science to *version* data sets as we work with them.  When we draw some conclusion, or even simply when we prepare for the next transformation step, it is important to indicate which version of the data this action is based on.  There are several different ways in which data sets may be versioned.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Large Data\n",
    "\n",
    "```python\n",
    "data = Annotated(read_format(raw_data))\n",
    "inplace_transform_1(data)\n",
    "data.steps += \"Transformed by step 1\"\n",
    "# ... actions on data ...\n",
    "inplace_transform_2(data)\n",
    "data.steps += \"Transformed by step 2\"\n",
    "# ... etc ...\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "If a data set is somewhat larger in size—to the point where keeping a number of near-copies in memory is a resource constraint—it is possible instead to track changes simply as metadata on the working data set.  This does not allow simultaneous access to multiple versions in code, but is still very useful for debugging and analysis. \n",
    "\n",
    "For transformations that you wish to persist longer than the run of a single program, use of version control systems (VCS) is highly desirable.  Most VCSs allow a concept of a *branch* where different versions of files can be maintained in parallel.  Even if your data set versions are strictly linear, it is possible to revert to a particular earlier version if necessary.  Using accurate and descriptive commit messages is a great benefit to data versioning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "toc": {
   "base_numbering": 0
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
